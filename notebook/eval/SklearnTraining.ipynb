{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e75ff701",
   "metadata": {},
   "source": [
    "Sklearn Training (& Testing)\n",
    "===\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c807e1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7b3f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a4fb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import sys\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "import sklearn\n",
    "import sklearn.linear_model\n",
    "import sklearn.preprocessing\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import dateutil.parser\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from datetime import datetime, timedelta\n",
    "import pytz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd59d291",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "git_root_dir = !git rev-parse --show-toplevel\n",
    "git_root_dir = Path(git_root_dir[0].strip())\n",
    "git_root_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad816111",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(os.path.join(git_root_dir, 'src'))\n",
    "import cbrec.genconfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d7c6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = cbrec.genconfig.Config()\n",
    "#config.metadata_filepath += \"_old\"\n",
    "#config.feature_db_filepath += \"_old\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f3e76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cbrec.featuredb\n",
    "import cbrec.utils\n",
    "import cbrec.reccontext\n",
    "import cbrec.evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45d2e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "md_list = cbrec.utils.get_metadata_list(config.metadata_filepath)\n",
    "len(md_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002e0255",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cbrec.utils.create_metadata_dataframe(md_list)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b40540",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(df.type.value_counts().rename(\"Total metadata count by type\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67094034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the md_list\n",
    "md_list = [md for md in md_list if md['type'] != 'ineligible']\n",
    "len(md_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23992de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_triples():\n",
    "    db = cbrec.featuredb.get_db_by_filepath(config.feature_db_filepath)\n",
    "    #triple_metadata = []\n",
    "    arrs = []\n",
    "    ys = []\n",
    "    \n",
    "    try:\n",
    "        for row in cbrec.featuredb.stream_triples(db):\n",
    "            #md = {key: row[key] for key in row.keys() if not key.endswith(\"_arr\")}\n",
    "            #triple_metadata.append(md)\n",
    "            target_feature_arr = np.concatenate([row['target_feature_arr'], row['source_feature_arr'] - row['target_feature_arr'], row['source_target_feature_arr']])\n",
    "            alt_feature_arr = np.concatenate([row['alt_feature_arr'], row['source_feature_arr'] - row['alt_feature_arr'], row['source_alt_feature_arr']])\n",
    "            arrs.append(target_feature_arr)\n",
    "            ys.append(1)\n",
    "            arrs.append(alt_feature_arr)\n",
    "            ys.append(0)\n",
    "        #df = pd.DataFrame(triple_metadata)\n",
    "        #return df\n",
    "    finally:\n",
    "        db.close()\n",
    "    return arrs, ys\n",
    "        \n",
    "feature_arrs, ys = get_triples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe17956",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.vstack(feature_arrs)\n",
    "y_true = np.array(ys)\n",
    "X.shape, y_true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e05583",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Pipeline([\n",
    "    ('scaler', sklearn.preprocessing.StandardScaler()),\n",
    "    ('clf', sklearn.linear_model.SGDClassifier(loss='log')),\n",
    "])\n",
    "clf.fit(X, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92c992d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa565b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "preds = clf.predict_proba(X)[:,1]\n",
    "ax.hist(preds, bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df80b29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "preds = clf.predict_proba(X)[:,1]\n",
    "bins = np.linspace(0, 1, 20)\n",
    "ax.hist(preds[y_true == 1], bins=bins, alpha=0.5)\n",
    "ax.hist(preds[y_true == 0], bins=bins, alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917ca831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy, looking good\n",
    "np.sum(clf.predict(X) == y_true) / len(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088fb566",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef = clf['clf'].coef_\n",
    "print(coef[:,0:12])\n",
    "print(coef[:,12:24])\n",
    "print(coef[:,24:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd642cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_md_list = cbrec.utils.get_test_metadata(md_list)\n",
    "len(test_md_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef23044",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf = df[df.type == 'test']\n",
    "len(tdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ee0267",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_contexts(config, test_md_list, clf):\n",
    "    db = cbrec.featuredb.get_db_by_filepath(config.feature_db_filepath)\n",
    "    \n",
    "    try:\n",
    "        for md in test_md_list:\n",
    "            metadata_id = md['metadata_id']\n",
    "            test_context = cbrec.featuredb.get_test_context_by_metadata_id(db, metadata_id, config)\n",
    "            rc = cbrec.reccontext.RecContext.create_from_test_context(config, md, test_context)\n",
    "            \n",
    "            scorer = cbrec.evaluation.SklearnModelScorer(config, rc, clf, \"PointwiseLogreg\")\n",
    "            metric_dict = scorer.score_proba()\n",
    "            md['baseline_metrics']['PointwiseLogreg'] = metric_dict\n",
    "    finally:\n",
    "        db.close()\n",
    "        \n",
    "get_test_contexts(config, test_md_list, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d60567",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5aaa75",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = test_md_list[0]['baseline_metrics'].keys()\n",
    "print(models)\n",
    "model_df_dict = {}\n",
    "for model in tqdm(models):\n",
    "    metrics_list = []\n",
    "    for md in test_md_list:\n",
    "        metrics = md['baseline_metrics'][model]\n",
    "        metrics['metadata_id'] = md['metadata_id']\n",
    "        metrics_list.append(metrics)\n",
    "    mdf = pd.DataFrame(metrics_list)\n",
    "    mdf['reciprocal_rank'] = 1 / mdf.target_rank\n",
    "    model_df_dict[model] = mdf\n",
    "    print(model, len(mdf))\n",
    "len(model_df_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b4b340",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for model in models:\n",
    "    mdf = model_df_dict[model][['target_raw_score', 'target_rank', 'reciprocal_rank', 'ndcg_1', 'ndcg_5', 'ndcg_10', 'ndcg_50']]\n",
    "    means = mdf.mean()\n",
    "    means = pd.concat([pd.Series([np.sum(mdf.target_rank <= 5) / len(mdf),], index=['% <= rank 5',]), means])\n",
    "    means = pd.concat([pd.Series([model,], index=['model',]), means])\n",
    "    scores.append(means)\n",
    "score_df = pd.DataFrame(scores).rename(columns={'target_rank': 'mean_rank', 'reciprocal_rank': 'mrr', 'target_raw_score': 'mean_raw_score'}).sort_values(by='mean_rank')\n",
    "score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be9970a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c755b499",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bd5066",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b0450e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9ca76a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce954f4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
