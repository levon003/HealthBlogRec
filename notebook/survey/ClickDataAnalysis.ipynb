{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Click Data Analysis\n",
    "===\n",
    "\n",
    " - IRR\n",
    " - Total annotated\n",
    " - Percentage of each category\n",
    " - Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.rcParams['figure.dpi'] = 120\n",
    "matplotlib.rcParams['font.family'] = \"serif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "#import bson\n",
    "#from bson.codec_options import CodecOptions\n",
    "#from bson.raw_bson import RawBSONDocument\n",
    "#from bson import ObjectId\n",
    "import gzip\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from glob import glob\n",
    "\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import dateutil\n",
    "import pytz\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "import sklearn\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "git_root_dir = !git rev-parse --show-toplevel\n",
    "git_root_dir = Path(git_root_dir[0].strip())\n",
    "git_root_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "caringbridge_core_path = \"/home/lana/levon003/repos/caringbridge_core\"\n",
    "sys.path.append(caringbridge_core_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cbcore.data.paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert os.path.exists(cbcore.data.paths.raw_data_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caringbridge_core_path = \"/home/lana/levon003/repos/recsys-peer-match/src\"\n",
    "sys.path.append(caringbridge_core_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cbrec.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figures_dir = os.path.join(git_root_dir, 'figures')\n",
    "os.makedirs(figures_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading previous batch recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_data_dir = os.path.join(cbcore.data.paths.projects_data_dir, 'recsys-peer-match', 'participant')\n",
    "!ls {participant_data_dir}/*.ndjson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in recommendations from previous rounds\n",
    "d = []\n",
    "for batch_id in [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]:\n",
    "    participant_data_filepath = os.path.join(participant_data_dir, f'participant_rec_data_b{batch_id}.ndjson')\n",
    "    with open(participant_data_filepath, 'r') as infile:\n",
    "        for line in infile:\n",
    "            participant = json.loads(line)\n",
    "            del participant['site_scores']\n",
    "            participant['batch_id'] = batch_id\n",
    "            d.append(participant)\n",
    "\n",
    "len(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_df = pd.DataFrame(d)\n",
    "batch_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_df.sse_site_list.iloc[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_recced_site_map = {}\n",
    "for participant_id, group in batch_df.groupby('participant_id'):\n",
    "    recced_site_ids = []\n",
    "    for sse_site_list in group.sse_site_list:\n",
    "        recced_site_ids.extend([site['site_id'] for site in sse_site_list])\n",
    "    assert len(recced_site_ids) == len(set(recced_site_ids)), \"Duplicate rec was given.\"\n",
    "    recced_site_ids = list(set(recced_site_ids))\n",
    "    participant_recced_site_map[participant_id] = recced_site_ids\n",
    "len(participant_recced_site_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recced_usps = [(row.participant_id, site['site_id']) for row in batch_df.itertuples() for site in row.sse_site_list]\n",
    "len(recced_usps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(set(recced_usps)) == len(recced_usps), \"Duplicate rec given.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create rec_df\n",
    "rec_df = []\n",
    "for row in batch_df.itertuples(index=False):\n",
    "    for i, site in enumerate(row.sse_site_list):\n",
    "        rec = row._asdict()\n",
    "        del rec['sse_site_list']\n",
    "        if 'journal_body' in site:\n",
    "            # some of the data were written with different key names for cleaned_journal_{body,title}\n",
    "            # this code normalizes the key names\n",
    "            site = dict(site)\n",
    "            site['cleaned_journal_body'] = site['journal_body']\n",
    "            del site['journal_body']\n",
    "            site['cleaned_journal_title'] = site['journal_title']\n",
    "            del site['journal_title']\n",
    "        rec.update(site)\n",
    "        rec['rank'] = i\n",
    "        rec_df.append(rec)\n",
    "rec_df = pd.DataFrame(rec_df)\n",
    "len(rec_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add alias for participant_id\n",
    "rec_df['user_id'] = rec_df['participant_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_df.sample(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Participant data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get participant data\n",
    "participant_id_filepath = os.path.join(git_root_dir, 'data/email/participant_ids.tsv')\n",
    "participant_df = pd.read_csv(participant_id_filepath, sep='\\t', header=0)\n",
    "print(len(participant_df))\n",
    "participant_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_batch_count_map = batch_df.groupby('participant_id').batch_id.nunique().to_dict()\n",
    "participant_df['n_total_recs'] = participant_df.user_id.map(lambda user_id: participant_batch_count_map[user_id] * 5 if user_id in participant_batch_count_map else 0)\n",
    "participant_df.n_total_recs.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_first_sse_map = batch_df.groupby('participant_id').sse_sent_timestamp.min()\n",
    "participant_df['first_sse_timestamp'] = participant_df.user_id.map(lambda user_id: participant_first_sse_map[user_id] if user_id in participant_first_sse_map else -1)\n",
    "participant_df.first_sse_timestamp.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cloudfront logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the logs as a dataframe\n",
    "s = datetime.now()\n",
    "cloudfront_filepath = os.path.join(git_root_dir, 'data/cloudfront/cloudfront_sse_visits_20220426.csv')\n",
    "cf_df = pd.read_csv(cloudfront_filepath, header=0, sep=',')\n",
    "print(f\"Loaded {len(cf_df)} rows in {datetime.now() - s}.\")\n",
    "cf_df.sample(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps = []\n",
    "for date, time in tqdm(zip(cf_df.date, cf_df.time), total=len(cf_df)):\n",
    "    d = datetime.strptime(date + \" \" + time, '%Y-%m-%d %H:%M:%S').replace(tzinfo=pytz.UTC)\n",
    "    timestamp = int(d.timestamp())\n",
    "    timestamps.append(timestamp)\n",
    "cf_df['timestamp'] = timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_df.method.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scf_df = cf_df[cf_df.method == 'GET'].copy()\n",
    "len(scf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_utm_info(query_string):\n",
    "    tokens = query_string.split(\"&\")\n",
    "    return {token.split(\"=\")[0]: token.split(\"=\")[1] for token in tokens}\n",
    "new_cols = pd.DataFrame(list(scf_df.query_string.map(get_utm_info)), index=scf_df.index)\n",
    "#pd.concat([scf_df, new_cols], axis=1)\n",
    "# add the columns\n",
    "scf_df = scf_df.merge(new_cols, left_index=True, right_index=True)\n",
    "scf_df['participant_id'] = scf_df.participant_id.astype(int)\n",
    "len(scf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch_num(utm_campaign):\n",
    "    tokens = utm_campaign.split(\"+\")\n",
    "    if len(tokens) == 2:\n",
    "        return 0\n",
    "    else:\n",
    "        return int(tokens[-1])\n",
    "\n",
    "scf_df['batch_id'] = scf_df.utm_campaign.map(get_batch_num)\n",
    "scf_df.batch_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_site_name(uri):\n",
    "    assert uri.startswith('/visit/')\n",
    "    return uri.split(\"/\")[2]\n",
    "scf_df['site_name'] = scf_df.uri.map(get_site_name)\n",
    "scf_df.site_name.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scf_df.utm_campaign.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scf_df.groupby('participant_id').batch_id.value_counts().rename('click_count').reset_index().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in how many batches has a participant participated?\n",
    "scf_df.groupby('participant_id').batch_id.nunique().rename(\"batch_participation_count\").sort_values(ascending=False).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scf_df.groupby('participant_id').site_name.nunique().rename(\"unique_site_visit_count\").reset_index().sort_values(by='unique_site_visit_count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scf_df.groupby('participant_id').site_name.nunique().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge in participant data\n",
    "scf_df = scf_df.merge(participant_df, how='left', left_on='participant_id', right_on='user_id', validate='many_to_one')\n",
    "len(scf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify time_to_click in seconds\n",
    "time_to_click = scf_df.timestamp - (scf_df.first_sse_timestamp / 1000)\n",
    "print(f\"{np.sum(time_to_click < 0) / len(time_to_click) * 100:.2f}% ({np.sum(time_to_click < 0)}) of clicks happened before the email was sent (due to Zach's testing); median time {np.median(time_to_click[time_to_click < 0]) / 60:.2f}mins\")\n",
    "#time_to_click = np.maximum(time_to_click, 0)\n",
    "scf_df['time_to_click'] = time_to_click\n",
    "scf_df[['participant_id', 'time_to_click']].sort_values('time_to_click')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scf_df = scf_df[scf_df.time_to_click > 0]\n",
    "len(scf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual exclusion finding\n",
    "sdf = scf_df[(scf_df.participant_id == 0)&(scf_df.batch_id == 1)].copy()\n",
    "sdf['iso'] = sdf.timestamp.map(lambda ts: datetime.utcfromtimestamp(ts).isoformat())\n",
    "sdf[['timestamp', 'iso']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scf_df = scf_df[~((scf_df.participant_id == 0)&(scf_df.batch_id == 1)&(scf_df.timestamp == 1633621589))]\n",
    "len(scf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scf_df.groupby('user_id').time_to_click.count().sort_values(ascending=False).rename(\"total_rec_clicks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_rec_clicks = scf_df.groupby('user_id').time_to_click.count().rename(\"total_rec_clicks\")\n",
    "total_rec_clicks.sum(), total_rec_clicks.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "\n",
    "bins = 100\n",
    "counts, bin_edges = np.histogram(scf_df.timestamp, bins=bins)\n",
    "ax.plot(bin_edges[:-1], counts, label=\"All visits\")\n",
    "\n",
    "bin_width_s = bin_edges[1] - bin_edges[0]\n",
    "ax.set_ylabel(f\"Requests per {bin_width_s / 60:.1f} minutes\")\n",
    "ax.set_xlabel(\"Date (central time)\")\n",
    "ax.set_title(\"Cloudfront site visits from site suggestion emails\")\n",
    "\n",
    "# note this is when the FIRST email was sent in batch 0\n",
    "ax.axvline(1630612646, linestyle='--', color='black', label='batch')\n",
    "print(datetime.utcfromtimestamp(1630612646))\n",
    "\n",
    "ax.xaxis.set_major_formatter(matplotlib.ticker.FuncFormatter(lambda x, y: datetime.utcfromtimestamp(x).replace(tzinfo=pytz.timezone('US/Central')).strftime(\"%m/%d\\n%H:%M\")))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "\n",
    "xs = scf_df.time_to_click / 60 / 60\n",
    "bins = np.arange(xs.min(), xs.max(), 1)\n",
    "counts, bin_edges = np.histogram(xs, bins=bins)\n",
    "ax.plot(bin_edges[:-1], counts, label=\"All visits\", linewidth=1)\n",
    "\n",
    "bin_width_s = bin_edges[1] - bin_edges[0]\n",
    "ax.set_ylabel(f\"Visits per {bin_width_s:.1f} hours\")\n",
    "ax.set_xlabel(\"Time to click (hours)\")\n",
    "ax.set_title(\"Cloudfront site visits from site suggestion emails\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scf_df.utm_content.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scf_df.participant_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total number of participants who clicked a link\n",
    "len(scf_df.participant_id.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scf_df.site_name.value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of unique (participant -> site) visit pairs\n",
    "np.sum(pd.crosstab(scf_df.participant_id, scf_df.site_name).to_numpy() > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of times a site was visited 2 or more times by a participant\n",
    "np.sum(pd.crosstab(scf_df.participant_id, scf_df.site_name).to_numpy() >= 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(scf_df.site_name, scf_df.utm_content, margins=True).sort_values('All', ascending=False).head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scf_df.request_ip.value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visits and Follows\n",
    "\n",
    "From the site_profile diffs, look for:\n",
    " - Visits to the site\n",
    " - Follows of the site\n",
    " - Role changes (specifically to \"Removed\", but anything involving Organizer's is interesting too)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_user_ids = set(participant_df[participant_df.n_total_recs > 0].user_id)\n",
    "len(participant_user_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: I believe this requires running under the default Python conda environment, which is slightly unfortunate\n",
    "should_run = False\n",
    "if should_run:\n",
    "    from cbcore.script.computeCollectionCounts import iterate_collection\n",
    "    # identify site_profiles for participants\n",
    "    site_profiles = []\n",
    "    input_filepath = os.path.join(cbcore.data.paths.raw_data_filepath, 'site_profile.bson.gz')\n",
    "    for doc in tqdm(iterate_collection(input_filepath), desc='Processing documents', total=83000000):\n",
    "        user_id = int(doc['userId']) if 'userId' in doc else -1\n",
    "        if user_id in participant_user_ids:\n",
    "            site_profiles.append(doc)\n",
    "    print(len(site_profiles))\n",
    "    \n",
    "    # save the processed site_profiles to pickle\n",
    "    output_dir = os.path.join(cbcore.data.paths.projects_data_dir, 'recsys-peer-match', 'participant')\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    with open(os.path.join(output_dir, 'site_profile.pkl'), 'wb') as outfile:\n",
    "        pickle.dump(site_profiles, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the site profiles\n",
    "with open(os.path.join(participant_data_dir, 'site_profile.pkl'), 'rb') as infile:\n",
    "    site_profiles = pickle.load(infile)\n",
    "print(len(site_profiles))\n",
    "\n",
    "# create a dataframe from the site profile entires\n",
    "ds = []\n",
    "for sp in site_profiles:\n",
    "    user_id = int(sp['userId'])\n",
    "    site_id = int(sp['siteId']) if 'siteId' in sp else -1\n",
    "    # not capturing: n, nl\n",
    "    d = {\n",
    "        'user_id': user_id,\n",
    "        'site_id': site_id,\n",
    "        'is_creator': sp['isCreator'] if 'isCreator' in sp else None,\n",
    "        'is_primary': sp['isPrimary'] if 'isPrimary' in sp else None,\n",
    "        'role': sp['role'],\n",
    "        'is_profile_deleted': sp['isProfileDeleted'] if 'isProfileDeleted' in sp else None,\n",
    "        'is_site_deleted': sp['isSiteDeleted'] if 'isSiteDeleted' in sp else None,\n",
    "        'is_stub': sp['isStub'] if 'isStub' in sp else None,\n",
    "        'created_at': sp['createdAt'].timestamp() * 1000 if 'createdAt' in sp else 0,\n",
    "        'updated_at': sp['updatedAt'].timestamp() * 1000 if 'updatedAt' in sp else 0,\n",
    "        'n': dict(sp['n']) if 'n' in sp and sp['n'] is not None else {},\n",
    "    }\n",
    "    ds.append(d)\n",
    "\n",
    "ssite_profile_df = pd.DataFrame(ds)\n",
    "ssite_profile_df.sample(n=10, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict(site_profiles[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsite_profile_df = ssite_profile_df.set_index(['user_id', 'site_id']).sort_index()\n",
    "rsite_profile_df = rsite_profile_df.loc[rsite_profile_df.index.intersection(recced_usps)].reset_index()\n",
    "len(rsite_profile_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsite_profile_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime.utcfromtimestamp(rsite_profile_df.created_at.max() / 1000).isoformat(),\\\n",
    "datetime.utcfromtimestamp(rsite_profile_df.updated_at.max() / 1000).isoformat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First clicks analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the site metadata dataframe\n",
    "# this is created in caringbridge_core from the new data\n",
    "site_metadata_working_dir = \"/home/lana/shared/caringbridge/data/derived/site_metadata\"\n",
    "s = datetime.now()\n",
    "site_metadata_filepath = os.path.join(site_metadata_working_dir, \"site_metadata.feather\")\n",
    "site_info_df = pd.read_feather(site_metadata_filepath)\n",
    "assert np.sum(site_info_df.site_id.value_counts() > 1) == 0, \"Site ids are not globally unique.\"\n",
    "print(datetime.now() - s)\n",
    "len(site_info_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_duplicate_names = np.sum(site_info_df.name.value_counts() > 1)\n",
    "print(f\"{n_duplicate_names} ({n_duplicate_names / len(site_info_df):.2%}) duplicate site URL names.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicate site names from the site_info_df\n",
    "# keeping the most recent by created_at date\n",
    "print(len(site_info_df))\n",
    "site_info_df = site_info_df.sort_values(by='created_at').drop_duplicates(subset='name', keep='last', ignore_index=True)\n",
    "print(len(site_info_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add site_id to the cloudfront data\n",
    "scf_df = pd.merge(scf_df, site_info_df[['site_id', 'name']], how='left', left_on='site_name', right_on='name', validate='many_to_one')\n",
    "len(scf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_clicks = scf_df.sort_values(by='timestamp').drop_duplicates(subset=['user_id', 'site_id'], keep='first')\n",
    "len(first_clicks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_clicks_map = {(row.user_id, row.site_id): row.timestamp for row in first_clicks.itertuples()}\n",
    "first_visits_map = {(row.user_id, row.site_id): row.created_at / 1000 for row in rsite_profile_df.itertuples()}\n",
    "len(first_clicks_map), len(first_visits_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicks & logged-in visits are not the same...\n",
    "set(first_clicks_map.keys()) == set(first_visits_map.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_first_click_or_visit_pairs = set(first_clicks_map.keys()) | set(first_visits_map.keys())\n",
    "len(all_first_click_or_visit_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_rec_map = {}\n",
    "for user_id, group in batch_df.groupby('participant_id'):\n",
    "    participant_rec_map[user_id] = []\n",
    "    for sse in group.itertuples():\n",
    "        for site in sse.sse_site_list:\n",
    "            participant_rec_map[user_id].append(site['site_id'])\n",
    "len(participant_rec_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_rec_time_map = {}\n",
    "for user_id, group in batch_df.groupby('participant_id'):\n",
    "    participant_rec_time_map[user_id] = {}\n",
    "    for sse in group.itertuples():\n",
    "        for site in sse.sse_site_list:\n",
    "            participant_rec_time_map[user_id][site['site_id']] = sse.sse_sent_timestamp\n",
    "len(participant_rec_time_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_total = 0\n",
    "n_visit_only = 0\n",
    "n_click_only = 0\n",
    "n_both = 0\n",
    "n_visit_unrelated_to_rec = 0\n",
    "n_visit_pre_rec = 0\n",
    "rec_to_visit_time_diffs = []\n",
    "click_to_visit_time_diffs = []\n",
    "\n",
    "for usp in all_first_click_or_visit_pairs:\n",
    "    if usp in first_clicks_map:\n",
    "        first_click_ts = first_clicks_map[usp]\n",
    "    else:\n",
    "        first_click_ts = None\n",
    "    if usp in first_visits_map:\n",
    "        first_visit_ts = first_visits_map[usp]\n",
    "    else:\n",
    "        first_visit_ts = None\n",
    "    \n",
    "    n_total += 1\n",
    "    if first_visit_ts and first_click_ts:\n",
    "        n_both += 1\n",
    "        click_to_visit_time_diffs.append(first_visit_ts - first_click_ts)\n",
    "    elif first_visit_ts and not first_click_ts:\n",
    "        # didn't register click OR visited pre-study\n",
    "        n_visit_only += 1\n",
    "        \n",
    "        user_id, site_id = usp\n",
    "        # was this site actually recommended?\n",
    "        was_recced = site_id in participant_rec_map[user_id]\n",
    "        if not was_recced:\n",
    "            n_visit_unrelated_to_rec += 1\n",
    "            continue\n",
    "        # did this visit occur before the associated recommendation?\n",
    "        recced_time = participant_rec_time_map[user_id][site_id] / 1000\n",
    "        rec_to_visit_time_diffs.append(first_visit_ts - recced_time)\n",
    "        if first_visit_ts < recced_time:\n",
    "            n_visit_pre_rec += 1\n",
    "        print(datetime.utcfromtimestamp(recced_time).isoformat())\n",
    "        \n",
    "    elif not first_visit_ts and first_click_ts:\n",
    "        # visit while not logged in\n",
    "        n_click_only += 1\n",
    "    elif not first_visit_ts and not first_click_ts:\n",
    "        raise ValueError(\"what?\")\n",
    "    else:\n",
    "        raise ValueError(\"big what.\")\n",
    "n_total, n_visit_only, n_click_only, n_both, n_visit_unrelated_to_rec, n_visit_pre_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "21 / len(scf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time in hours between rec email sent time and the visit\n",
    "# no obvious patterns... seems to approximately mirror the distribution of time_to_click\n",
    "np.array(rec_to_visit_time_diffs) / 60 / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "click_to_visit_time_diffs = np.array(click_to_visit_time_diffs)\n",
    "len(click_to_visit_time_diffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = click_to_visit_time_diffs[(click_to_visit_time_diffs < np.quantile(click_to_visit_time_diffs, 0.95))&(click_to_visit_time_diffs > np.quantile(click_to_visit_time_diffs, 0.05))]\n",
    "plt.hist(s, log=True, bins=50)\n",
    "plt.axvline(np.median(click_to_visit_time_diffs), label=f\"Med={np.median(click_to_visit_time_diffs):.2f}s\", color='black', linestyle='--')\n",
    "plt.axvline(0, label=f\"{np.sum(click_to_visit_time_diffs < 0) / len(click_to_visit_time_diffs):.2%} < 0s\", color='gray', linestyle='-', alpha=0.8)\n",
    "plt.legend()\n",
    "plt.title(\"Distribution of time between Cloudfront click and site_profile visit\")\n",
    "plt.xlabel(\"Time difference in seconds\")\n",
    "plt.ylabel(\"Number of first clicks\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_clicks = scf_df.sort_values(by='timestamp').drop_duplicates(subset=['user_id', 'site_id'], keep='first')\n",
    "first_click_map = {(row.user_id, row.site_id): row.timestamp for row in first_clicks.itertuples()}\n",
    "for row in rsite_profile_df.itertuples():\n",
    "    usp = (row.user_id, row.site_id)\n",
    "    if usp not in first_click_map:\n",
    "        first_click_map[usp] = int(row.created_at / 1000)\n",
    "len(first_click_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_click_timestamps = []\n",
    "for row in rec_df.itertuples():\n",
    "    usp = (row.user_id, row.site_id)\n",
    "    if usp in first_click_map:\n",
    "        first_click_timestamp = first_click_map[usp]\n",
    "    else:\n",
    "        first_click_timestamp = -1\n",
    "    first_click_timestamps.append(first_click_timestamp)\n",
    "# convert to milliseconds\n",
    "rec_df['first_click_timestamp'] = np.array(first_click_timestamps) * 1000\n",
    "rec_df['was_clicked'] = rec_df.first_click_timestamp >= 0\n",
    "rec_df.was_clicked.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f\"{np.sum(rec_df.was_clicked) / len(rec_df):.2%} of site recommendations were clicked\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf = rec_df[rec_df.was_clicked]\n",
    "#assert np.all(sdf.first_click_timestamp > sdf.sse_sent_timestamp)\n",
    "plt.hist((sdf.first_click_timestamp - sdf.sse_sent_timestamp) / 1000 / 60 / 60, bins=np.arange(-5, 100))\n",
    "plt.xlabel(\"Time to click (hours)\")\n",
    "plt.ylabel(\"Distribution of time-to-click\")\n",
    "plt.show()\n",
    "sdf[(sdf.first_click_timestamp - sdf.sse_sent_timestamp) < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the rec_df\n",
    "rec_df.to_feather(os.path.join(participant_data_dir, 'click_rec_df.feather'))\n",
    "print(\"Finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the rec_df with associated click data\n",
    "participant_data_dir = '/home/lana/shared/caringbridge/data/projects/recsys-peer-match/participant'\n",
    "click_rec_df = pd.read_feather(os.path.join(participant_data_dir, 'click_rec_df.feather'))\n",
    "len(click_rec_df), click_rec_df.was_clicked.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of participants who clicked\n",
    "click_counts = click_rec_df.groupby('participant_id').was_clicked.sum()\n",
    "(click_counts > 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of participants who clicked in batch 0\n",
    "click_counts = click_rec_df[click_rec_df.batch_id == 0].groupby('participant_id').was_clicked.sum()\n",
    "(click_counts > 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of clicked sites\n",
    "click_counts = click_rec_df.groupby('site_id').was_clicked.sum()\n",
    "(click_counts > 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_click_df = rec_df[rec_df.was_clicked]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = first_click_df.user_id.value_counts()\n",
    "xs = range(len(ys))\n",
    "plt.bar(xs, ys)\n",
    "plt.title(\"Number of clicks by participant\")\n",
    "plt.xlabel(\"Participant rank by number of clicks\")\n",
    "plt.ylabel(\"Number of unique clicks\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute number of clicks at the batch level\n",
    "batch_clicked_map = {}\n",
    "for sse, group in rec_df.groupby(['participant_id', 'batch_id']):\n",
    "    n_clicked = np.sum(group.was_clicked)\n",
    "    batch_clicked_map[sse] = n_clicked\n",
    "n_batch_clicks_list = []\n",
    "for row in batch_df.itertuples():\n",
    "    n_batch_clicks = batch_clicked_map[(row.participant_id, row.batch_id)]\n",
    "    n_batch_clicks_list.append(n_batch_clicks)\n",
    "batch_df['n_batch_clicks'] = n_batch_clicks_list\n",
    "batch_df.n_batch_clicks.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts, _ = np.histogram(batch_df.n_batch_clicks, bins = np.arange(0, 7))\n",
    "#plt.hist(batch_df.n_batch_clicks, , log=True)\n",
    "plt.bar(range(len(counts)), counts)\n",
    "plt.yscale('log')\n",
    "for i, count in enumerate(counts):\n",
    "    plt.text(i, count, f\"{count}\", ha='center', va='bottom')\n",
    "plt.xlabel(\"Number of clicks\")\n",
    "plt.ylabel(\"Number of batches\")\n",
    "plt.title(\"Distribution of clicks per batch\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# six participants clicked every link in an email\n",
    "batch_df[batch_df.n_batch_clicks == 5].participant_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_click_df.groupby('batch_id').participant_id.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(5.4, 1.4))\n",
    "\n",
    "batch_click_counts = first_click_df.groupby('batch_id').participant_id.count()\n",
    "xs = np.array(batch_click_counts.index)\n",
    "ys = batch_click_counts\n",
    "\n",
    "ax.bar(xs, ys, color=matplotlib.cm.Pastel1(2), width=0.82)\n",
    "for x, y, in zip(xs, ys):\n",
    "    ax.text(x, y, f\"{y}\", ha='center', va='bottom', fontsize=7)\n",
    "\n",
    "ax.set_yticks([0, 30, 60])\n",
    "ax.set_ylabel(\"First clicks\", fontsize=8)\n",
    "\n",
    "batch_sent_timestamps = batch_df.groupby('batch_id').sse_sent_timestamp.mean()\n",
    "batch_sent_timestamp_map = batch_sent_timestamps.to_dict()\n",
    "ax.set_xticks(np.arange(0, len(xs)))\n",
    "ax.set_xticklabels([f\"B{batch_id + 1}\\n{datetime.utcfromtimestamp(batch_sent_timestamp_map[batch_id] / 1000).strftime('%b%d')}\" for batch_id in np.arange(0, len(xs))])\n",
    "ax.tick_params(axis='both', which='major', labelsize=7)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(4.4, 1.4))\n",
    "\n",
    "batch_clicks = rec_df.groupby('batch_id').agg({'participant_id': 'count', 'was_clicked': 'sum'}).rename(columns={'participant_id': 'n_recs','was_clicked': 'n_clicks'}).reset_index()\n",
    "batch_clicks['pct_clicked'] = batch_clicks.n_clicks / batch_clicks.n_recs\n",
    "\n",
    "xs = batch_clicks.batch_id\n",
    "ys = batch_clicks.pct_clicked\n",
    "\n",
    "ax.bar(xs, ys, color=matplotlib.cm.Pastel1(2), width=0.82)\n",
    "for x, y, clicks in zip(xs, ys, batch_clicks.n_clicks):\n",
    "    ax.text(x, y, f\"{clicks}\", ha='center', va='bottom', fontsize=7)\n",
    "\n",
    "m = rec_df.was_clicked.sum() / len(rec_df)\n",
    "ax.axhline(m, color='gray', alpha=0.4, linestyle=\"--\", linewidth=0.7)\n",
    "ax.text(0.99, 0.33, f\"{m:.1%} clicked total\", transform=ax.transAxes, ha='right', va='bottom', color='gray', alpha=0.8, fontsize=8)\n",
    "ax.text(0.99, 0.95, f\"{rec_df.was_clicked.sum()} clicked of {len(rec_df):,} recommendations\", transform=ax.transAxes, ha='right', va='top', fontsize=8)\n",
    "\n",
    "ax.set_yticks([0, 0.05, 0.1, 0.15])\n",
    "ax.set_ylabel(\"% recs clicked\", fontsize=8)\n",
    "def format_yaxis(y, pos=None):\n",
    "    return f\"{y:.0%}\"\n",
    "ax.yaxis.set_major_formatter(format_yaxis)\n",
    "ax.set_ylim((0, 0.16))\n",
    "\n",
    "batch_sent_timestamps = batch_df.groupby('batch_id').sse_sent_timestamp.mean()\n",
    "batch_sent_timestamp_map = batch_sent_timestamps.to_dict()\n",
    "ax.set_xticks(np.arange(0, len(xs)))\n",
    "ax.set_xticklabels([f\"B{batch_id + 1}\\n{datetime.utcfromtimestamp(batch_sent_timestamp_map[batch_id] / 1000).strftime('%b%d')}\" for batch_id in np.arange(0, len(xs))])\n",
    "ax.tick_params(axis='both', which='major', labelsize=6)\n",
    "\n",
    "fig.tight_layout()\n",
    "image_shortfilename = f\"batch_clicks_histogram.pdf\"\n",
    "image_filename = os.path.join(figures_dir, image_shortfilename)\n",
    "fig.savefig(image_filename, format='pdf', dpi=200, pad_inches=0, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(1, 1.1))\n",
    "\n",
    "clicks = rec_df.groupby('participant_id').agg({'site_id': 'count', 'was_clicked': 'sum'}).rename(columns={'site_id': 'n_recs','was_clicked': 'n_clicks'}).reset_index()\n",
    "clicks['pct_clicked'] = clicks.n_clicks / clicks.n_recs\n",
    "\n",
    "ys = clicks.pct_clicked\n",
    "bins = np.arange(0, 1.05, 0.1)\n",
    "#bins = np.arange(0, 27)\n",
    "ax.hist(ys, bins=bins, log=True)\n",
    "\n",
    "ax.set_xticks([0, 0.5, 1])\n",
    "ax.set_xlabel(\"% recs clicked\", fontsize=6, ha='right', labelpad=2, x=1.1)\n",
    "ax.set_xticklabels([\"0\", \"0.5\", \"1\"])\n",
    "#def format_xaxis(x, pos=None):\n",
    "#    return f\"{x:.1f}\"\n",
    "#ax.xaxis.set_major_formatter(format_xaxis)\n",
    "\n",
    "ax.set_ylabel(\"Participants\", fontsize=6, labelpad=0.5)\n",
    "n_zeros = (clicks.n_clicks == 0).sum()\n",
    "print(f\"{n_zeros} participants never clicked\")\n",
    "ax.set_yticks([1, 10, 50])\n",
    "ax.set_yticks([2, 3, 4, 5, 6, 7, 8, 9, 20, 30, 40], minor=True)\n",
    "def format_yaxis(y, pos=None):\n",
    "    return f\"{y:.0f}\"\n",
    "ax.yaxis.set_major_formatter(format_yaxis)\n",
    "\n",
    "ax.tick_params(axis='both', which='major', labelsize=7)\n",
    "ax.tick_params(axis='both', which='major', labelsize=6)\n",
    "\n",
    "fig.tight_layout()\n",
    "image_shortfilename = f\"participant_clicks_histogram.pdf\"\n",
    "image_filename = os.path.join(figures_dir, image_shortfilename)\n",
    "fig.savefig(image_filename, format='pdf', dpi=200, pad_inches=0, bbox_inches='tight')\n",
    "\n",
    "plt.show()\n",
    "clicks.sort_values(by='n_clicks', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Click Annotation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_data_dir = os.path.join(git_root_dir, 'data', 'annotation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1_annotations = pd.read_csv(os.path.join(annotation_data_dir, \"clicked_batch_sse_annotation - v1 Ground Truth.tsv\"), sep='\\t')\n",
    "v2_annotations = pd.read_csv(os.path.join(annotation_data_dir, \"clicked_batch_sse_annotation - v2 Ground Truth.tsv\"), sep='\\t')\n",
    "v3_annotations = pd.read_csv(os.path.join(annotation_data_dir, \"clicked_batch_sse_annotation - v3 Ground Truth.tsv\"), sep='\\t')\n",
    "len(v1_annotations), len(v2_annotations), len(v3_annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1_annotations.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_cols = [\n",
    "    'site_id', 'journal_oid', \n",
    "    'cleaned_journal_title',\n",
    "    'cleaned_journal_body',\n",
    "    'NOT what/how patient is doing?', 'good news?', 'bad news?', 'EOA/gratitude?', 'author visible?', 'expressive writing?'\n",
    "]\n",
    "adf = pd.concat([v1_annotations[good_cols], v2_annotations[good_cols], v3_annotations[good_cols]])\n",
    "len(adf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adf.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name_mapping = {\n",
    "    'NOT what/how patient is doing?': 'health_news',\n",
    "    'good news?': 'pos_news', \n",
    "    'bad news?': 'neg_news', \n",
    "    'EOA/gratitude?': 'eoa', \n",
    "    'author visible?': 'vis', \n",
    "    'expressive writing?': 'ew',\n",
    "}\n",
    "adf = adf.rename(columns=column_name_mapping)\n",
    "adf.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cols = ['health_news', 'pos_news', 'neg_news', 'eoa', 'vis', 'ew']\n",
    "for col in data_cols:\n",
    "    adf[col] = adf[col].notna().astype(int)\n",
    "adf['health_news'] = np.abs(adf.health_news - 1)  # invert health_news due to the way it was annotated\n",
    "adf.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adf[data_cols].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_health_cat(row):\n",
    "    if row.health_news == 0:\n",
    "        return 'none'\n",
    "    if row.pos_news == 1 and row.neg_news == 1:\n",
    "        return 'both'\n",
    "    elif row.pos_news == 1:\n",
    "        return 'pos'\n",
    "    elif row.neg_news == 1:\n",
    "        return 'neg'\n",
    "    else:\n",
    "        return 'neut'\n",
    "adf['health_cat'] = adf.apply(create_health_cat, axis='columns')\n",
    "adf.health_cat.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# consider link prevalence?  Only present in tiny number of journal previews\n",
    "has_link = adf.cleaned_journal_body.map(lambda j: \"http\" in j.lower() or \"[link]\" in j.lower() if pd.notna(j) else False)\n",
    "has_link.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_please = adf.cleaned_journal_body.map(lambda j: \"please\" in j.lower() if pd.notna(j) else False)\n",
    "adf['has_please'] = has_please.astype(int)\n",
    "has_please.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_we = adf.cleaned_journal_body.map(lambda j: \"we \" in j.lower() if pd.notna(j) else False).rename(\"has_we\")\n",
    "has_i = adf.cleaned_journal_body.map(lambda j: \"i \" in j.lower() if pd.notna(j) else False).rename(\"has_i\")\n",
    "adf['has_we'] = has_we.astype(int)\n",
    "adf['has_i'] = has_i.astype(int)\n",
    "def create_pronouns(row):\n",
    "    if row.has_we and row.has_i:\n",
    "        return 'both'\n",
    "    elif row.has_we:\n",
    "        return 'we_only'\n",
    "    elif row.has_i:\n",
    "        return 'i_only'\n",
    "    else:\n",
    "        return 'neither'\n",
    "adf['pronouns'] = adf.apply(create_pronouns, axis='columns')\n",
    "pd.crosstab(has_we, has_i, margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adf.pronouns.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Invisible\" data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invis_df = pd.read_feather(os.path.join(git_root_dir, 'notebook/retention/pre_rec_total_df_20220608.feather'))\n",
    "len(invis_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invis_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invis_df.sample(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_clicks.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invis_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eligible_participants = set([row.participant_id for row in batch_df[batch_df.n_batch_clicks > 0].itertuples()])\n",
    "assert eligible_participants == set(invis_df[invis_df.was_clicked == 1].participant_id)\n",
    "clicking_participant_recs = invis_df[invis_df.participant_id.isin(eligible_participants)]\n",
    "# merge in annotation data\n",
    "clicking_participant_recs = clicking_participant_recs.merge(\n",
    "    adf.drop(columns=['site_id', 'cleaned_journal_title', 'cleaned_journal_body']), \n",
    "    how='left', left_on='rec_journal_oid', right_on='journal_oid'\n",
    ")\n",
    "clicking_participant_recs.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clicking_participant_recs.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conditions:\n",
    "# - recs, participants who clicked only\n",
    "# - recs, but only from batches with 1-4 clicks (not 0 or 5)\n",
    "# - recs, batch 0 only\n",
    "# - batches, but only participants who clicked\n",
    "# - batches, but only those with 1-4 clicks\n",
    "# - batches, but only batch 0\n",
    "\n",
    "#eligible_participants = set([row.participant_id for row in batch_df[batch_df.n_batch_clicks > 0].itertuples()])\n",
    "#assert eligible_participants == set(invis_df[invis_df.was_clicked == 1].participant_id)\n",
    "# merge in annotation data\n",
    "rec_click_df = invis_df.merge(\n",
    "    adf.drop(columns=['site_id', 'cleaned_journal_title', 'cleaned_journal_body']), \n",
    "    how='left', left_on='rec_journal_oid', right_on='journal_oid'\n",
    ")\n",
    "rec_click_df['participant_batch'] = [(row.participant_id, row.batch_id) for row in rec_click_df.itertuples()]\n",
    "rec_click_df = rec_click_df.merge(rec_click_df.groupby('participant_batch').was_clicked.sum().rename('n_batch_clicks').reset_index(), on='participant_batch')\n",
    "#rec_click_df['n_batch_clicks'] = rec_click_df.groupby(['participant_id', 'batch_id']).was_clicked.sum()\n",
    "rec_click_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(rec_click_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_click_df.n_batch_clicks.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sidebar: Creating v3 annotations\n",
    "\n",
    "v1 and v2 were created in `ActivityMonitoring.ipynb`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf = rec_click_df\n",
    "mdf = mdf[mdf.batch_id == 0]\n",
    "b0_missing_site_ids = set(mdf[mdf.eoa.isna()].site_id)\n",
    "len(b0_missing_site_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = ['site_id','journal_oid','site_title','cleaned_journal_title','cleaned_journal_body',\n",
    "          'NOT what/how patient is doing?','good news?','bad news?','EOA/gratitude?','author visible?','expressive writing?']\n",
    "clicked_batch_sse_annotation_filepath = os.path.join(participant_data_dir, 'clicked_batch_sse_annotation_v3.tsv')\n",
    "\n",
    "duplicate_avoided = 0\n",
    "lines_written = 0\n",
    "written_journal_oids = set()\n",
    "with open(clicked_batch_sse_annotation_filepath, 'w') as outfile:\n",
    "    outfile.write('\\t'.join(header) + '\\n')\n",
    "    for row in rec_df[(rec_df.batch_id == 0)&(rec_df.site_id.isin(b0_missing_site_ids))].drop_duplicates(subset='site_id', keep='first').sample(frac=1).itertuples():\n",
    "        if row.journal_oid in written_journal_oids:\n",
    "            duplicate_avoided += 1\n",
    "            continue\n",
    "        written_journal_oids.add(row.journal_oid)\n",
    "        cleaned_journal_title = row.cleaned_journal_title.replace('\\t', '    ').replace('\\n', ' NEWLINE ').replace('\"', '\\\\\"')\n",
    "        cleaned_journal_body = row.cleaned_journal_body.replace('\\t', '    ').replace('\\n', ' NEWLINE ').replace('\"', '\\\\\"')\n",
    "        line = f\"{row.site_id}\\t{row.journal_oid}\\t{row.site_title}\\t\\\"{cleaned_journal_title}\\\"\\t\\\"{cleaned_journal_body}\\\"\\t\\t\\t\\t\\t\\t\\n\"\n",
    "        assert '\\n' not in line[:-1]\n",
    "        outfile.write(line)\n",
    "        lines_written += 1\n",
    "lines_written, duplicate_avoided"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### End of sidebar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import stargazer\n",
    "import sklearn\n",
    "from sklearn.model_selection import KFold\n",
    "import scipy\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eligible batches are those that were clicked at least once\n",
    "eligible_batches = set(rec_click_df[(rec_click_df.n_batch_clicks > 0)&(rec_click_df.n_batch_clicks < 5)].participant_batch)\n",
    "eligible_participants = set(rec_click_df[rec_click_df.was_clicked == 1].participant_id)\n",
    "print(f\"Identified {len(eligible_batches)} eligible batches and {len(eligible_participants)} eligible participants.\")\n",
    "\n",
    "dfs = []\n",
    "for condition in ['rec_selective', 'rec_b0', 'rec_clicked']:\n",
    "    mdf = rec_click_df\n",
    "    if condition == 'rec_selective':  # only recs in batches that were clicked at least once\n",
    "        mdf = mdf[mdf.participant_batch.isin(eligible_batches)]\n",
    "    elif condition == 'rec_b0':  # only recs in batches in batch 0\n",
    "        mdf = mdf[mdf.batch_id == 0]\n",
    "    elif condition == 'rec_clicked':  # only recs in batches sent to participants who clicked at least once\n",
    "        mdf = mdf[mdf.participant_id.isin(eligible_participants)]\n",
    "    assert mdf.eoa.isna().sum() == 0\n",
    "    \n",
    "    cols = ['health_news', 'pos_news', 'neg_news', 'eoa', 'vis', 'ew']\n",
    "    clicked = mdf.loc[mdf.was_clicked == 1, cols]\n",
    "    not_clicked = mdf.loc[mdf.was_clicked == 0, cols]\n",
    "    ds = []\n",
    "    for col in clicked.columns:\n",
    "        t = clicked[col]\n",
    "        c = not_clicked[col]\n",
    "        tstat, p = scipy.stats.ttest_ind(t, c, equal_var=False)\n",
    "        diff = t.mean() - c.mean()\n",
    "        ds.append({'col': col, 'diff': diff, 'p': p})\n",
    "    diffs = pd.DataFrame(ds).set_index('col')\n",
    "    \n",
    "    sdf = pd.concat([\n",
    "        mdf[cols].mean().rename(f'all (cond={condition})'),\n",
    "        mdf.loc[mdf.was_clicked == 1, cols].mean().rename('clicked'),\n",
    "        mdf.loc[mdf.was_clicked == 0, cols].mean().rename('not_clicked'),\n",
    "        diffs\n",
    "    ], axis=1)\n",
    "    dfs.append(sdf)\n",
    "pd.concat(dfs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eligible batches are those that were clicked at least once\n",
    "eligible_batches = set(rec_click_df[(rec_click_df.n_batch_clicks > 0)&(rec_click_df.n_batch_clicks < 5)].participant_batch)\n",
    "eligible_participants = set(rec_click_df[rec_click_df.was_clicked == 1].participant_id)\n",
    "print(f\"Identified {len(eligible_batches)} eligible batches and {len(eligible_participants)} eligible participants.\")\n",
    "\n",
    "condition = 'rec_b0'\n",
    "mdf = rec_click_df\n",
    "mdf = mdf[mdf.batch_id == 0]\n",
    "assert mdf.eoa.isna().sum() == 0\n",
    "\n",
    "print(len(mdf))\n",
    "mdf.health_cat.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eligible_batches = set(rec_click_df[(rec_click_df.n_batch_clicks > 0)&(rec_click_df.n_batch_clicks < 5)].participant_batch)\n",
    "eligible_participants = set(rec_click_df[rec_click_df.was_clicked == 1].participant_id)\n",
    "print(f\"Identified {len(eligible_batches)} eligible batches and {len(eligible_participants)} eligible participants.\")\n",
    "\n",
    "conditions = ['rec_selective', 'rec_b0', 'rec_clicked']\n",
    "results = []\n",
    "batch_results = []\n",
    "for condition in conditions:\n",
    "    mdf = rec_click_df\n",
    "    if condition == 'rec_selective':\n",
    "        mdf = mdf[mdf.participant_batch.isin(eligible_batches)]\n",
    "    elif condition == 'rec_b0':\n",
    "        mdf = mdf[mdf.batch_id == 0]\n",
    "    elif condition == 'rec_clicked':\n",
    "        mdf = mdf[mdf.participant_id.isin(eligible_participants)]\n",
    "    assert mdf.eoa.isna().sum() == 0\n",
    "    print(condition, len(mdf), mdf.eoa.isna().sum(), len(set(mdf[mdf.eoa.isna()].site_id)))\n",
    "    \n",
    "    formula = 'was_clicked ~ rank + eoa + vis + ew + C(health_cat, Treatment(\"none\"))'\n",
    "    #if condition != 'rec_b0':\n",
    "    #    formula += ' + batch_id'\n",
    "    md = smf.logit(formula=formula, data=mdf)\n",
    "    res = md.fit(disp=0)\n",
    "    results.append(res)\n",
    "    \n",
    "    kf = KFold(n_splits=min(len(mdf), 5000))\n",
    "    y_score = np.zeros(len(mdf))\n",
    "    y_true = np.zeros(len(mdf))\n",
    "    for train_index, test_index in tqdm(kf.split(mdf), total=kf.get_n_splits(mdf), desc=condition, disable=True):\n",
    "        md = smf.logit(formula=formula, data=mdf.iloc[train_index])\n",
    "        res = md.fit(disp=0)\n",
    "        preds = res.predict(mdf.iloc[test_index])\n",
    "        y_score[test_index] = preds\n",
    "        y_true[test_index] = mdf.iloc[test_index].was_clicked\n",
    "    auc = sklearn.metrics.roc_auc_score(y_true, y_score)\n",
    "    print(f\"{condition}: n={len(mdf)}; n_clicked={mdf.was_clicked.sum()}; AUC={auc:.3f}\")\n",
    "    \n",
    "    continue  # comment this to fit the batch models\n",
    "    if condition == 'rec_selective':\n",
    "        continue\n",
    "    batch_click_df = []\n",
    "    for key, group in mdf.groupby(['participant_id', 'batch_id']):\n",
    "\n",
    "        n_unique_permutations = len(group.groupby(['eoa', 'vis', 'ew']))  # consider including 'has_health_news' here\n",
    "\n",
    "        batch_click_df.append({\n",
    "            'participant_id': key[0],\n",
    "            'batch_id': key[1],\n",
    "            **{'n_' + col: group[col].sum() for col in ['eoa', 'vis', 'ew', 'health_news', 'pos_news', 'neg_news']},\n",
    "            **{'has_' + col: group[col].max() for col in ['eoa', 'vis', 'ew', 'health_news', 'pos_news', 'neg_news']},\n",
    "            'has_hc_none': int(group.health_cat.map(lambda hc: hc == 'neut').any()),\n",
    "            'has_hc_neutral': int(group.health_cat.map(lambda hc: hc == 'neut').any()),\n",
    "            'has_hc_neg': int(group.health_cat.map(lambda hc: hc == 'neg').any()),\n",
    "            'has_hc_pos': int(group.health_cat.map(lambda hc: hc == 'pos').any()),\n",
    "            'has_hc_both': int(group.health_cat.map(lambda hc: hc == 'both').any()),\n",
    "            'n_unique_permutations': n_unique_permutations,\n",
    "            'n_clicks': group.was_clicked.sum(),\n",
    "            'was_clicked': int(group.was_clicked.sum() > 0),\n",
    "        })\n",
    "    batch_click_df = pd.DataFrame(batch_click_df)\n",
    "    assert batch_click_df.was_clicked.sum() < len(batch_click_df)\n",
    "    print(f\"    batch; n={len(batch_click_df)}; n_clicked={batch_click_df.was_clicked.sum()}\")\n",
    "    \n",
    "    formula = 'was_clicked ~ has_eoa + has_vis + has_ew + has_hc_none' # 'was_clicked ~ has_eoa + has_vis + has_ew + has_hc_none + has_hc_neutral + has_hc_neg + has_hc_pos + has_hc_both'\n",
    "    md = smf.logit(formula=formula, data=batch_click_df)\n",
    "    res = md.fit(disp=0, method='bfgs')\n",
    "    batch_results.append(res)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stargazer.stargazer import Stargazer\n",
    "s = Stargazer(results)\n",
    "s.custom_columns(labels=conditions, separators=[1, 1, 1])\n",
    "s.show_model_numbers(False)\n",
    "s.significance_levels([0.05, 0.01, 0.001])\n",
    "#print(s.render_latex())\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# also report the log-likelihood, and star it accordingly\n",
    "for res in results:\n",
    "    print(res.summary().tables[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(s.render_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stargazer.stargazer import Stargazer\n",
    "s = Stargazer(batch_results)\n",
    "s.custom_columns(labels=['batch_click_b0', 'batch_clicked_participants_only'], separators=[1, 1])\n",
    "s.show_model_numbers(False)\n",
    "s.significance_levels([0.05, 0.01, 0.001])\n",
    "#print(s.render_latex())\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf.health_cat.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_click_df = []\n",
    "for key, group in mdf.groupby(['participant_id', 'batch_id']):\n",
    "    \n",
    "    n_unique_permutations = len(group.groupby(['eoa', 'vis', 'ew']))  # consider including 'has_health_news' here\n",
    "    \n",
    "    batch_click_df.append({\n",
    "        'participant_id': key[0],\n",
    "        'batch_id': key[1],\n",
    "        **{'n_' + col: group[col].sum() for col in ['eoa', 'vis', 'ew', 'health_news', 'pos_news', 'neg_news']},\n",
    "        **{'has_' + col: group[col].max() for col in ['eoa', 'vis', 'ew', 'health_news', 'pos_news', 'neg_news']},\n",
    "        'has_hc_none': int(group.health_cat.map(lambda hc: hc == 'neut').any()),\n",
    "        'has_hc_neutral': int(group.health_cat.map(lambda hc: hc == 'neut').any()),\n",
    "        'has_hc_neg': int(group.health_cat.map(lambda hc: hc == 'neg').any()),\n",
    "        'has_hc_pos': int(group.health_cat.map(lambda hc: hc == 'pos').any()),\n",
    "        'has_hc_both': int(group.health_cat.map(lambda hc: hc == 'both').any()),\n",
    "        'n_unique_permutations': n_unique_permutations,\n",
    "        'n_clicks': group.was_clicked.sum(),\n",
    "        'was_clicked': int(group.was_clicked.sum() > 0),\n",
    "    })\n",
    "batch_click_df = pd.DataFrame(batch_click_df)\n",
    "batch_click_df.sample(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_click_df.n_unique_permutations.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_click_df.was_clicked.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_click_df.has_hc_none.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = 'was_clicked ~ has_eoa + has_vis + has_ew + has_hc_none + has_hc_neutral + has_hc_neg + has_hc_pos + has_hc_both'\n",
    "md = smf.logit(formula=formula, data=batch_click_df)\n",
    "res = md.fit(disp=0, method='bfgs')\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eligible_participants = set([row.participant_id for row in batch_df[batch_df.n_batch_clicks > 0].itertuples()])\n",
    "clicking_participant_recs = rec_df[rec_df.participant_id.isin(eligible_participants)]\n",
    "# merge in annotation data\n",
    "clicking_participant_recs = clicking_participant_recs.merge(\n",
    "    adf.drop(columns=['site_id', 'cleaned_journal_title', 'cleaned_journal_body']), \n",
    "    how='left', on='journal_oid',\n",
    ")\n",
    "clicking_participant_recs.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clicking_participant_recs.was_clicked.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clicking_participant_recs['was_clicked'] = clicking_participant_recs.was_clicked.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# proportion of recommendations that were annotated with each category\n",
    "# compared to unclicked recommendations, clicked recommendations are more likely to have expressive writing, \n",
    "# but less likely to have positive OR negative news OR expressions of appreciation OR author visible\n",
    "# (this analysis includes only recommendations shown to participants who clicked at least once)\n",
    "cols = data_cols + ['has_we', 'has_i', 'has_please', 'time_since_first_journal_update', 'n_updates_total', 'n_users_interactedwith_total', 'n_interactions_total', 'n_authors_total']\n",
    "pd.concat([\n",
    "    clicking_participant_recs[cols].mean().rename('all'),\n",
    "    clicking_participant_recs.loc[clicking_participant_recs.was_clicked == 1, cols].mean().rename('clicked'),\n",
    "    clicking_participant_recs.loc[clicking_participant_recs.was_clicked == 0, cols].mean().rename('not_clicked'),\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(clicking_participant_recs.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intercept only\n",
    "md = smf.logit(formula='was_clicked ~ 1', data=clicking_participant_recs)\n",
    "res = md.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(res.params)  # TODO consider converting this to proability, for sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rank only\n",
    "md = smf.logit(formula='was_clicked ~ rank', data=clicking_participant_recs)\n",
    "res = md.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rank only\n",
    "md = smf.logit(formula='was_clicked ~ C(rank, Treatment(0.0))', data=clicking_participant_recs)\n",
    "res = md.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clicking_participant_recs.groupby('rank').was_clicked.agg(['sum', lambda wc: wc.sum() / len(wc)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# click rate among partcipants who clicked at least once\n",
    "clicking_participant_recs.was_clicked.sum() / len(clicking_participant_recs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = smf.logit(formula='was_clicked ~ batch_id', data=clicking_participant_recs)\n",
    "res = md.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = smf.logit(formula='was_clicked ~ C(batch_id, Treatment(0))', data=clicking_participant_recs)\n",
    "res = md.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = smf.logit(formula='was_clicked ~ C(pronouns, Treatment(\"neither\")) + has_please', data=clicking_participant_recs)\n",
    "res = md.fit()\n",
    "print(res.summary().tables[1])\n",
    "clicking_participant_recs['has_pronoun'] = ((clicking_participant_recs.has_i == 1)|(clicking_participant_recs.has_we == 1)).astype(int)\n",
    "md = smf.logit(formula='was_clicked ~ has_pronoun + has_please', data=clicking_participant_recs)\n",
    "res = md.fit()\n",
    "print(res.summary().tables[1])\n",
    "clicking_participant_recs.has_pronoun.value_counts(), clicking_participant_recs.has_please.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# omnibus\n",
    "md = smf.logit(formula='was_clicked ~ rank + eoa + vis + ew + C(health_cat, Treatment(\"neut\")) + C(pronouns, Treatment(\"neither\")) + has_please + batch_id', data=clicking_participant_recs)\n",
    "res = md.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all annotations, plus rank\n",
    "md = smf.logit(formula='was_clicked ~ rank + eoa + vis + ew + C(health_cat, Treatment(\"neut\"))', data=clicking_participant_recs)\n",
    "res = md.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all annotations, no rank\n",
    "md = smf.logit(formula='was_clicked ~ eoa + vis + ew + C(health_cat, Treatment(\"neut\"))', data=clicking_participant_recs)\n",
    "res = md.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clicking_participant_recs.health_cat.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = smf.logit(formula='was_clicked ~ C(health_cat, Treatment(\"none\"))', data=clicking_participant_recs)\n",
    "res = md.fit()\n",
    "print(res.summary().tables[1])\n",
    "md = smf.logit(formula='was_clicked ~ rank + eoa + vis + ew + C(health_cat, Treatment(\"none\"))', data=clicking_participant_recs)\n",
    "res1 = md.fit()\n",
    "print(res1.summary().tables[1])\n",
    "md = smf.logit(formula='was_clicked ~ rank + eoa + vis + ew + health_news', data=clicking_participant_recs)\n",
    "res1 = md.fit()\n",
    "md = smf.logit(formula='was_clicked ~ rank + eoa + vis + ew + pos_news + neg_news', data=clicking_participant_recs)\n",
    "res2 = md.fit()\n",
    "print(res1.summary().tables[1])\n",
    "print(res2.summary().tables[1])\n",
    "md = smf.logit(formula='was_clicked ~ rank + eoa + vis + ew + pos_news + neg_news + pos_news*neg_news', data=clicking_participant_recs)\n",
    "res = md.fit()\n",
    "print(res.summary().tables[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clicking_participant_recs['health_info_present'] = (clicking_participant_recs.health_cat != 'none').astype(int)\n",
    "md = smf.logit(formula='was_clicked ~ rank + eoa + vis + ew + health_info_present', data=clicking_participant_recs)\n",
    "res = md.fit()\n",
    "print(res.summary().tables[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# omnibus\n",
    "md = smf.logit(formula='was_clicked ~ rank + eoa + vis + ew + C(health_cat, Treatment(\"none\")) + time_since_first_journal_update + n_updates_total + n_users_interactedwith_total + n_interactions_total + n_authors_total', data=clicking_participant_recs)\n",
    "res = md.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invisible only\n",
    "md = smf.logit(formula='was_clicked ~ time_since_first_journal_update + n_updates_total + n_users_interactedwith_total + n_interactions_total + n_authors_total', data=clicking_participant_recs)\n",
    "res = md.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = smf.logit(formula='was_clicked ~ rank + eoa + vis + ew + C(health_cat, Treatment(\"none\")) + np.log(time_since_first_journal_update)', data=clicking_participant_recs)\n",
    "res = md.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = smf.logit(formula='was_clicked ~ rank + eoa + vis + ew + C(health_cat, Treatment(\"none\")) + time_since_first_journal_update', data=clicking_participant_recs)\n",
    "res = md.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# omnibus\n",
    "clicking_participant_recs['has_multiple_authors_pre'] = (clicking_participant_recs.n_authors_pre > 1).astype(int)\n",
    "clicking_participant_recs['has_multiple_authors_total'] = (clicking_participant_recs.n_authors_total > 1).astype(int)\n",
    "md = smf.logit(formula='was_clicked ~ rank + eoa + vis + ew + C(health_cat, Treatment(\"none\")) + time_since_first_journal_update + n_first_visits_pre + n_users_repeat_visited_pre + n_updates_pre + n_authors_pre', data=clicking_participant_recs)\n",
    "res = md.fit()\n",
    "print(res.summary().tables[1])\n",
    "\n",
    "md = smf.logit(formula='was_clicked ~ rank + eoa + vis + ew + C(health_cat, Treatment(\"none\")) + time_since_first_journal_update + n_first_visits_pre + n_users_repeat_visited_pre + n_updates_pre + has_multiple_authors_pre', data=clicking_participant_recs)\n",
    "res = md.fit()\n",
    "print(res.summary().tables[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clicking_participant_recs.has_multiple_authors_pre.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = smf.logit(formula='was_clicked ~ has_multiple_authors_pre + has_multiple_authors_total', data=clicking_participant_recs)\n",
    "res = md.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for was_clicked in [0, 1]:\n",
    "    for has_multiple_authors_pre in [0, 1]:\n",
    "        print(f\"{was_clicked=} {has_multiple_authors_pre=}\")\n",
    "        sdf = clicking_participant_recs[(clicking_participant_recs.was_clicked == was_clicked)&(clicking_participant_recs.has_multiple_authors_pre == has_multiple_authors_pre)].sample(n=2)\n",
    "        print(sdf.iloc[0].cleaned_journal_body)\n",
    "        print(sdf.iloc[1].cleaned_journal_body)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md.exog.shape, md.endog.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y_true = md.exog.shape, md.endog.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "# TODO do k-fold CV on the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eligible_participants = set([row.participant_id for row in batch_df[batch_df.n_batch_clicks > 0].itertuples()])\n",
    "eligible_batches = [(row.participant_id, row.batch_id) for row in batch_df[batch_df.participant_id.isin(eligible_participants)].itertuples()]\n",
    "len(eligible_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IRR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_data_dir = os.path.join(git_root_dir, 'data', 'annotation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1_irr = pd.read_csv(os.path.join(annotation_data_dir, \"clicked_batch_sse_annotation - v1 101+ IRR Discussion.tsv\"), sep='\\t')\n",
    "len(v1_irr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this corresponds to batch 2\n",
    "# (magic number is from the spreadsheet)\n",
    "v1_irr = v1_irr.iloc[99:,:].copy()\n",
    "len(v1_irr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5, 17):\n",
    "    print(v1_irr.iloc[:,i].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = []\n",
    "for a1_ind in range(5, 11):\n",
    "    a2_ind = a1_ind + 6\n",
    "    \n",
    "    a1_raw = v1_irr.iloc[:,a1_ind]\n",
    "    a2_raw = v1_irr.iloc[:,a2_ind]\n",
    "    \n",
    "    a1_y = a1_raw.notna().astype(int)\n",
    "    a2_y = a2_raw.notna().astype(int)\n",
    "    annotations.append((a1_raw.name, a1_y, a2_y))\n",
    "    \n",
    "len(annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1_irr['a1_str'] = v1_irr.iloc[:,5:11].apply(lambda row: \" \".join([str(val) for val in row.notna().astype(int)]), axis='columns')\n",
    "v1_irr['a2_str'] = v1_irr.iloc[:,11:17].apply(lambda row: \" \".join([str(val) for val in row.notna().astype(int)]), axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations.append(('all', v1_irr.a1_str, v1_irr.a2_str))\n",
    "len(annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for annotation in annotations:\n",
    "    name, a1_y, a2_y = annotation\n",
    "    k = sklearn.metrics.cohen_kappa_score(a1_y, a2_y)\n",
    "    agreement = np.sum(a1_y == a2_y) / len(a1_y)\n",
    "    print(f\"{name:>30} {k:.4f} {agreement:.3%} {len(a1_y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1_annotations = annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v2_irr = pd.read_csv(os.path.join(annotation_data_dir, \"clicked_batch_sse_annotation - v2 IRR2 Discussion.tsv\"), sep='\\t')\n",
    "len(v2_irr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = []\n",
    "for a1_ind in range(5, 11):\n",
    "    a2_ind = a1_ind + 6\n",
    "    \n",
    "    a1_raw = v2_irr.iloc[:,a1_ind]\n",
    "    a2_raw = v2_irr.iloc[:,a2_ind]\n",
    "    \n",
    "    a1_y = a1_raw.notna().astype(int)\n",
    "    a2_y = a2_raw.notna().astype(int)\n",
    "    annotations.append((a1_raw.name, a1_y, a2_y))\n",
    "    \n",
    "len(annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v2_irr['a1_str'] = v2_irr.iloc[:,5:11].apply(lambda row: \" \".join([str(val) for val in row.notna().astype(int)]), axis='columns')\n",
    "v2_irr['a2_str'] = v2_irr.iloc[:,11:17].apply(lambda row: \" \".join([str(val) for val in row.notna().astype(int)]), axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations.append(('all', v2_irr.a1_str, v2_irr.a2_str))\n",
    "len(annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for annotation in annotations:\n",
    "    name, a1_y, a2_y = annotation\n",
    "    k = sklearn.metrics.cohen_kappa_score(a1_y, a2_y)\n",
    "    agreement = np.sum(a1_y == a2_y) / len(a1_y)\n",
    "    print(f\"{name:>30} {k:.4f} {agreement:.3%} {len(a1_y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v2_annotations = annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pooled\n",
    "for v1_annotation, v2_annotation in zip(v1_annotations, v2_annotations):\n",
    "    name, v1_a1_y, v1_a2_y = v1_annotation\n",
    "    name2, v2_a1_y, v2_a2_y = v2_annotation\n",
    "    assert name == name2\n",
    "    a1_y = np.concatenate((v1_a1_y, v2_a1_y))\n",
    "    a2_y = np.concatenate((v1_a2_y, v2_a2_y))\n",
    "    k = sklearn.metrics.cohen_kappa_score(a1_y, a2_y)\n",
    "    agreement = np.sum(a1_y == a2_y) / len(a1_y)\n",
    "    print(f\"{name:>30} {k:.4f} {agreement:.3%} {len(a1_y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all\n",
    "pretty_name_map = {\n",
    "    'NOT what/how patient is doing?': 'Reporting Health',\n",
    "    'good news?': 'Positive Disclosures',\n",
    "    'bad news?': 'Negative Disclosures',\n",
    "    'EOA/gratitude?': 'Expression of Appreciation',\n",
    "    'author visible?': 'Managing Audience Relationship',\n",
    "    'expressive writing?': 'Expressive Writing',\n",
    "    'all': 'All',\n",
    "}\n",
    "for v1_annotation, v2_annotation in zip(v1_annotations, v2_annotations):\n",
    "    name, v1_a1_y, v1_a2_y = v1_annotation\n",
    "    name2, v2_a1_y, v2_a2_y = v2_annotation\n",
    "    assert name == name2\n",
    "    pool_a1_y = np.concatenate((v1_a1_y, v2_a1_y))\n",
    "    pool_a2_y = np.concatenate((v1_a2_y, v2_a2_y))\n",
    "    \n",
    "    row = f\"{pretty_name_map[name]}\"\n",
    "    for a1_y, a2_y in [(v1_a1_y, v1_a2_y), (v2_a1_y, v2_a2_y), (pool_a1_y, pool_a2_y)]:\n",
    "        k = sklearn.metrics.cohen_kappa_score(a1_y, a2_y)\n",
    "        agreement = np.sum(a1_y == a2_y) / len(a1_y)\n",
    "        row += f\" & {k:.2f} & {agreement*100:.1f}\\\\%\"\n",
    "    row += ' \\\\\\\\'\n",
    "    print(row)\n",
    "    #print(f\"{name:>30} {k:.4f} {agreement:.3%} {len(a1_y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rounds 2 and 3 only\n",
    "pretty_name_map = {\n",
    "    'NOT what/how patient is doing?': 'Reporting Health',\n",
    "    'good news?': 'Positive Disclosures',\n",
    "    'bad news?': 'Negative Disclosures',\n",
    "    'EOA/gratitude?': 'Expression of Appreciation',\n",
    "    'author visible?': 'Managing Audience Relationship',\n",
    "    'expressive writing?': 'Expressive Writing',\n",
    "    'all': 'All',\n",
    "}\n",
    "for v1_annotation, v2_annotation in zip(v1_annotations, v2_annotations):\n",
    "    name, v1_a1_y, v1_a2_y = v1_annotation\n",
    "    name2, v2_a1_y, v2_a2_y = v2_annotation\n",
    "    assert name == name2\n",
    "    row = f\"{pretty_name_map[name]}\"\n",
    "    for a1_y, a2_y in [(v1_a1_y, v1_a2_y), (v2_a1_y, v2_a2_y)]:\n",
    "        k = sklearn.metrics.cohen_kappa_score(a1_y, a2_y)\n",
    "        agreement = np.sum(a1_y == a2_y) / len(a1_y)\n",
    "        row += f\" & {k:.2f} & {agreement*100:.1f}\\\\%\"\n",
    "    row += ' \\\\\\\\'\n",
    "    print(row)\n",
    "    #print(f\"{name:>30} {k:.4f} {agreement:.3%} {len(a1_y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### v1 annotations\n",
    "\n",
    "Every annotation in a batch that was clicked at least once (but not 5 times)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eligible_batches = [(row.participant_id, row.batch_id) for row in batch_df[(batch_df.n_batch_clicks > 0)&(batch_df.n_batch_clicks < 5)].itertuples()]\n",
    "len(eligible_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = ['site_id','journal_oid','site_title','cleaned_journal_title','cleaned_journal_body',\n",
    "          'NOT what/how patient is doing?','good news?','bad news?','EOA/gratitude?','author visible?','expressive writing?']\n",
    "clicked_batch_sse_annotation_filepath = os.path.join(participant_data_dir, 'clicked_batch_sse_annotation_v1.tsv')\n",
    "\n",
    "duplicate_avoided = 0\n",
    "lines_written = 0\n",
    "written_journal_oids = set()\n",
    "with open(clicked_batch_sse_annotation_filepath, 'w') as outfile:\n",
    "    outfile.write('\\t'.join(header) + '\\n')\n",
    "    for row in rec_df.sample(frac=1).itertuples():\n",
    "        if (row.participant_id, row.batch_id) in eligible_batches:\n",
    "            if row.journal_oid in written_journal_oids:\n",
    "                duplicate_avoided += 1\n",
    "                continue\n",
    "            written_journal_oids.add(row.journal_oid)\n",
    "            cleaned_journal_title = row.cleaned_journal_title.replace('\\t', '    ').replace('\\n', ' NEWLINE ').replace('\"', '\\\\\"')\n",
    "            cleaned_journal_body = row.cleaned_journal_body.replace('\\t', '    ').replace('\\n', ' NEWLINE ').replace('\"', '\\\\\"')\n",
    "            line = f\"{row.site_id}\\t{row.journal_oid}\\t{row.site_title}\\t\\\"{cleaned_journal_title}\\\"\\t\\\"{cleaned_journal_body}\\\"\\t\\t\\t\\t\\t\\t\\n\"\n",
    "            assert '\\n' not in line[:-1]\n",
    "            outfile.write(line)\n",
    "            lines_written += 1\n",
    "lines_written, duplicate_avoided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(clicked_batch_sse_annotation_filepath, 'r') as infile:\n",
    "    for line in infile:\n",
    "        tokens = line.split(\"\\t\")\n",
    "        assert len(tokens) == 11, line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pd.read_csv(clicked_batch_sse_annotation_filepath, sep='\\t', header=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### v2 annotations\n",
    "\n",
    "Every batch from a participant that clicked at least once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1_clicked_batch_sse_annotation_filepath = os.path.join(participant_data_dir, 'clicked_batch_sse_annotation_v1.tsv')\n",
    "v1_journal_oids = set(pd.read_csv(v1_clicked_batch_sse_annotation_filepath, sep='\\t', header=0).journal_oid)\n",
    "len(v1_journal_oids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify every participant who clicked at least once\n",
    "eligible_participants = set([row.participant_id for row in batch_df[batch_df.n_batch_clicks > 0].itertuples()])\n",
    "# identify all batches already present in the v1 annotations\n",
    "v1_eligible_batches = [(row.participant_id, row.batch_id) for row in batch_df[(batch_df.n_batch_clicks > 0)&(batch_df.n_batch_clicks < 5)].itertuples()]\n",
    "# identify all batches NOT in v1 but that are\n",
    "eligible_batches = [(row.participant_id, row.batch_id) for row in batch_df[batch_df.participant_id.isin(eligible_participants)].itertuples()\n",
    "                   if (row.participant_id, row.batch_id) not in v1_eligible_batches]\n",
    "len(eligible_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = ['site_id','journal_oid','site_title','cleaned_journal_title','cleaned_journal_body',\n",
    "          'NOT what/how patient is doing?','good news?','bad news?','EOA/gratitude?','author visible?','expressive writing?']\n",
    "clicked_batch_sse_annotation_filepath = os.path.join(participant_data_dir, 'clicked_batch_sse_annotation_v2.tsv')\n",
    "\n",
    "duplicate_avoided = 0\n",
    "lines_written = 0\n",
    "written_journal_oids = set()\n",
    "with open(clicked_batch_sse_annotation_filepath, 'w') as outfile:\n",
    "    outfile.write('\\t'.join(header) + '\\n')\n",
    "    for row in rec_df.sample(frac=1).itertuples():\n",
    "        if (row.participant_id, row.batch_id) in eligible_batches:\n",
    "            if row.journal_oid in written_journal_oids or row.journal_oid in v1_journal_oids:\n",
    "                duplicate_avoided += 1\n",
    "                continue\n",
    "            written_journal_oids.add(row.journal_oid)\n",
    "            cleaned_journal_title = row.cleaned_journal_title.replace('\\t', '    ').replace('\\n', ' NEWLINE ').replace('\"', '\\\\\"')\n",
    "            cleaned_journal_body = row.cleaned_journal_body.replace('\\t', '    ').replace('\\n', ' NEWLINE ').replace('\"', '\\\\\"')\n",
    "            line = f\"{row.site_id}\\t{row.journal_oid}\\t{row.site_title}\\t\\\"{cleaned_journal_title}\\\"\\t\\\"{cleaned_journal_body}\\\"\\t\\t\\t\\t\\t\\t\\n\"\n",
    "            assert '\\n' not in line[:-1]\n",
    "            outfile.write(line)\n",
    "            lines_written += 1\n",
    "lines_written, duplicate_avoided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pd.read_csv(clicked_batch_sse_annotation_filepath, sep='\\t', header=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### v3 annotations\n",
    "\n",
    "Random sample of some kind. Sensible options:\n",
    " - Random sample of batches (able to answer \"what % of batches contained good news?\")\n",
    " - Random sample of recommended journals (able to answer: \"what % of recommendations contained good news?\")\n",
    " - Random sample of journals, weighted by occurrence (able to answer: \"what % of the recommendations viewed by participants contained good news?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify every participant who clicked at least once\n",
    "eligible_participants = set([row.participant_id for row in batch_df[batch_df.n_batch_clicks > 0].itertuples()])\n",
    "# identify all batches captured in v1 and v2\n",
    "v1_v2_eligible_batches = [(row.participant_id, row.batch_id) for row in batch_df[batch_df.participant_id.isin(eligible_participants)].itertuples()]\n",
    "len(v1_v2_eligible_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO figure out how we want to random sample\n",
    "# keep track of which updates are present in v1_v2_eligible_batches and make sure we don't multiply annotate them...\n",
    "# this will be somewhat complicated code I think, probably need to change how we sample the rec_df\n",
    "len(rec_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utility bash for copying and transferring files\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp {clicked_batch_sse_annotation_filepath} .\n",
    "!pwd\n",
    "!ls ./*.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the site profile diff\n",
    "s = datetime.now()\n",
    "site_profile_diff_filepath = os.path.join(cbcore.data.paths.projects_data_dir, 'caringbridge_core', 'site_profile_diff', 'site_profile_diff.tsv')\n",
    "site_profile_diff_df = pd.read_csv(site_profile_diff_filepath, sep='\\t', header=0)\n",
    "print(f\"Read {len(site_profile_diff_df)} rows in {datetime.now() - s}.\")\n",
    "site_profile_diff_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_counts = site_profile_diff_df.snapshot_date.value_counts().sort_index()\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 3))\n",
    "\n",
    "xs = np.arange(len(daily_counts))\n",
    "ax.plot(xs, daily_counts)\n",
    "nl = '\\n'\n",
    "for x, count in zip(xs, daily_counts):\n",
    "    ax.text(x, count, f\"{count / 1000:,.0f}K\", ha='center', va='bottom' if x % 2 == 0 else 'top')  # {nl if x % 2 == 0 else ''}\n",
    "\n",
    "ax.set_xticks(xs)\n",
    "ax.set_xticklabels([f\"{str(i)[4:6]}\\n{str(i)[6:]}\" for i in daily_counts.index])\n",
    "\n",
    "ax.set_title(\"Daily updates to the site_profile collection, captured via snapshot\")\n",
    "ax.set_xlabel(\"Snapshot date\")\n",
    "ax.set_ylabel(\"Number of updates\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "np.median(daily_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_profile_diff_df.key.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsite_profile_diff_df = site_profile_diff_df.set_index(['user_id', 'site_id']).sort_index()\n",
    "rsite_profile_diff_df = rsite_profile_diff_df.loc[rsite_profile_diff_df.index.intersection(recced_usps)].reset_index()\n",
    "len(rsite_profile_diff_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsite_profile_diff_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many unique user->site updates did we observe?\n",
    "rsite_profile_diff_df.groupby(['user_id', 'site_id']).ngroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_df = rsite_profile_diff_df.merge(rsite_profile_df, how='outer', on=['user_id', 'site_id'])\n",
    "len(sp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_df.key.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visit actions\n",
    "#sdf = sp_df[sp_df.key == 'updatedAt']\n",
    "ds = []\n",
    "for usp, group in sp_df.groupby(['user_id', 'site_id']):\n",
    "    n_potential_missed_visits = 0\n",
    "    prev_visit_timestamp = int(group.iloc[0].created_at)\n",
    "    visit_timestamps = [prev_visit_timestamp,]\n",
    "    for row in group[group.key == 'updatedAt'].sort_values(by='new_value').itertuples():\n",
    "        new_value = int(row.new_value) * 1000\n",
    "        old_value = int(row.old_value) * 1000\n",
    "        assert new_value > old_value\n",
    "        assert new_value > prev_visit_timestamp, f\"{new_value} {prev_visit_timestamp}\"\n",
    "        if old_value != prev_visit_timestamp:\n",
    "            assert old_value > prev_visit_timestamp\n",
    "            n_potential_missed_visits += 1\n",
    "            visit_timestamps.append(old_value)\n",
    "        visit_timestamps.append(new_value)\n",
    "        prev_visit_timestamp = new_value\n",
    "    n_visits = len(visit_timestamps)\n",
    "    ds.append({\n",
    "        'user_id': usp[0],\n",
    "        'site_id': usp[1],\n",
    "        'n_visits': n_visits,\n",
    "        'n_potential_missed_visits': n_potential_missed_visits,\n",
    "        'visit_timestamps': visit_timestamps,\n",
    "    })\n",
    "visit_df = pd.DataFrame(ds)\n",
    "len(visit_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visit_df.sort_values(by='n_visits', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visit_df.groupby('user_id').n_visits.sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visit_df.groupby('user_id').n_visits.sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many \"return visits\" are there?\n",
    "def count_return_visits(visit_timestamps):\n",
    "    if len(visit_timestamps) <= 1:\n",
    "        return 0\n",
    "    return_visit_threshold = 1000 * 60 * 60 * 6  # 6 hours\n",
    "    \n",
    "    n_return_visits = 0\n",
    "    first_timestamp = visit_timestamps[0]\n",
    "    for timestamp in visit_timestamps[1:]:\n",
    "        if timestamp > first_timestamp + return_visit_threshold:\n",
    "            n_return_visits += 1\n",
    "    return n_return_visits\n",
    "visit_df['n_return_visits'] = visit_df.visit_timestamps.map(count_return_visits)\n",
    "visit_df.n_return_visits.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visit_df.n_return_visits.sum(), np.sum(visit_df.n_return_visits > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(visit_df.groupby('user_id').n_return_visits.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO create a visit_df with all of the participants visits, and then compute pre/post comparison?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# follow actions\n",
    "sp_df[sp_df.key == 'n']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# currently, this is a reasonable estimate of number of follow actions\n",
    "sp_df[sp_df.n.map(lambda n: len(n) > 0)].groupby(['user_id', 'site_id']).updated_at.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_df.n.map(lambda n: len(n)).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(sp_df.key, sp_df.n.map(lambda n: len(n)), dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
