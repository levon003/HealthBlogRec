{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "End-of-recruitment site_profile Sampling\n",
    "===\n",
    "\n",
    "Identify a comparison set (\"pseudo-control\") of people who were likely shown the banner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.rcParams['figure.dpi'] = 120\n",
    "matplotlib.rcParams['font.family'] = \"serif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import bson\n",
    "from bson.codec_options import CodecOptions\n",
    "from bson.raw_bson import RawBSONDocument\n",
    "from bson import ObjectId\n",
    "import gzip\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import dateutil\n",
    "import pytz\n",
    "\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "git_root_dir = !git rev-parse --show-toplevel\n",
    "git_root_dir = Path(git_root_dir[0].strip())\n",
    "git_root_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "caringbridge_core_path = \"/home/lana/levon003/repos/caringbridge_core\"\n",
    "sys.path.append(caringbridge_core_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cbcore.data.paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert os.path.exists(cbcore.data.paths.raw_data_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cbcore.bson.decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cbcore.script.computeCollectionCounts import iterate_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_dict(doc):\n",
    "    if type(doc) != RawBSONDocument and type(doc) != dict:\n",
    "        return doc\n",
    "    d = {}\n",
    "    for key, value in doc.items():\n",
    "        value_type = type(value)\n",
    "        if value_type == ObjectId:\n",
    "            value = str(value)\n",
    "        elif value_type == RawBSONDocument:\n",
    "            # note: this is risky if the raw bson document can't self-inflate due to the date bug\n",
    "            value = convert_to_dict(value)\n",
    "        elif value_type == list:\n",
    "            value = [convert_to_dict(v) for v in value]\n",
    "            #for item in value:\n",
    "            #    value_prepr.append\n",
    "        d[key] = value\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the journal metadata\n",
    "s = datetime.now()\n",
    "journal_metadata_dir = \"/home/lana/shared/caringbridge/data/derived/journal_metadata\"\n",
    "journal_metadata_filepath = os.path.join(journal_metadata_dir, \"journal_metadata.feather\")\n",
    "journal_df = pd.read_feather(journal_metadata_filepath)\n",
    "print(datetime.now() - s)\n",
    "len(journal_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "journal_df['usp'] = [(user_id, site_id) for user_id, site_id in zip(journal_df.user_id, journal_df.site_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the site profile diff\n",
    "# rows should be >= 37M+\n",
    "s = datetime.now()\n",
    "site_profile_diff_filepath = os.path.join(cbcore.data.paths.projects_data_dir, 'caringbridge_core', 'site_profile_diff', 'site_profile_diff.tsv')\n",
    "site_profile_diff_df = pd.read_csv(site_profile_diff_filepath, sep='\\t', header=0)\n",
    "print(f\"Read {len(site_profile_diff_df)} rows in {datetime.now() - s}.\")\n",
    "site_profile_diff_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_profile_diff_df.key.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get participant data\n",
    "participant_id_filepath = os.path.join(git_root_dir, 'data/email/participant_ids.tsv')\n",
    "participant_df = pd.read_csv(participant_id_filepath, sep='\\t', header=0)\n",
    "print(len(participant_df))\n",
    "participant_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_user_ids = set(participant_df.user_id)\n",
    "len(participant_user_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify users who were likely shown the banner\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is every person who ever authored a journal update\n",
    "author_ids = set(journal_df.user_id)\n",
    "len(author_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "central_time = pytz.timezone('US/Central')\n",
    "banner_live_time = datetime.fromisoformat('2021-08-02 12:11:00').astimezone(central_time)\n",
    "banner_end_time = datetime.fromisoformat('2021-08-23 11:59:59').astimezone(central_time)\n",
    "start_date = banner_live_time\n",
    "end_date = banner_end_time\n",
    "\n",
    "with open(os.path.join(cbcore.data.paths.projects_data_dir, 'recsys-peer-match', 'participant', 'all_author_visits.ndjson'), 'w') as outfile:\n",
    "    # note: we need to use SPECIFICALLY the August 24th, 2021 site_profile snapshot to compute this, since we are relying on the updatedAt date...\n",
    "    input_filepath = os.path.join(cbcore.data.paths.raw_data_root_dir, '20210824', 'site_profile.bson.gz')\n",
    "    for sp in tqdm(iterate_collection(input_filepath), desc='Processing documents', total=82379880):\n",
    "        user_id = int(sp['userId'])\n",
    "        site_id = int(sp['siteId']) if 'siteId' in sp else -1\n",
    "        role = sp['role']\n",
    "        is_creator = sp['isCreator'] if 'isCreator' in sp else None\n",
    "        is_primary = sp['isPrimary'] if 'isPrimary' in sp else None\n",
    "        # two conditions\n",
    "        #  - Organizer/site creator (including is or will be an author)\n",
    "        #  - During opt-in recruitment period\n",
    "        could_have_seen_banner = (user_id in author_ids or role == 'Organizer' or is_creator == '1' or is_primary == '1') \\\n",
    "            and (\n",
    "                ('updatedAt' in sp and sp['updatedAt'] >= start_date and sp['updatedAt'] <= end_date) \\\n",
    "                or ('createdAt' in sp and sp['createdAt'] >= start_date and sp['createdAt'] <= end_date)\n",
    "            )\n",
    "        if could_have_seen_banner:\n",
    "            d = {\n",
    "                'user_id': user_id,\n",
    "                'site_id': site_id,\n",
    "                'role': role,\n",
    "                'is_creator': is_creator,\n",
    "                'is_primary': is_primary,\n",
    "                'is_profile_deleted': sp['isProfileDeleted'] if 'isProfileDeleted' in sp else None,\n",
    "                'is_site_deleted': sp['isSiteDeleted'] if 'isSiteDeleted' in sp else None,\n",
    "                'is_stub': sp['isStub'] if 'isStub' in sp else None,\n",
    "                'created_at': int(sp['createdAt'].timestamp() * 1000) if 'createdAt' in sp else 0,\n",
    "                'updated_at': int(sp['updatedAt'].timestamp() * 1000) if 'updatedAt' in sp else 0,\n",
    "                'n': convert_to_dict(sp['n']) if 'n' in sp else {},\n",
    "                'nl': [convert_to_dict(n) for n in sp['nl']] if 'nl' in sp else [],\n",
    "            }\n",
    "            outfile.write(json.dumps(d) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load static site_profile data\n",
    "\n",
    "Collected from an explicit snapshot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_list = []\n",
    "with open(os.path.join(cbcore.data.paths.projects_data_dir, 'recsys-peer-match', 'participant', 'all_author_visits.ndjson'), 'r') as infile:\n",
    "    for line in tqdm(infile, total=81928):\n",
    "        sp = json.loads(line)\n",
    "        sp_list.append(sp)\n",
    "len(sp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_df = pd.DataFrame(sp_list)\n",
    "sp_df.sample(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_df['usp'] = [(user_id, site_id) for user_id, site_id in zip(sp_df.user_id, sp_df.site_id)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subset by time and authorship status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many users wrote journal updates during the period when the profile was active?\n",
    "central_time = pytz.timezone('US/Central')\n",
    "banner_live_time = datetime.fromisoformat('2021-08-02 12:11:00').astimezone(central_time)\n",
    "banner_end_time = datetime.fromisoformat('2021-08-23 11:59:59').astimezone(central_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restrict the site_profile diffs to updatedAt changes during the recruitment window\n",
    "site_profile_diff_df = site_profile_diff_df[site_profile_diff_df.key == 'updatedAt'].astype({'old_value': int, 'new_value': int})\n",
    "len(site_profile_diff_df)\n",
    "site_profile_diff_df = site_profile_diff_df[((site_profile_diff_df.old_value >= banner_live_time.timestamp())&(site_profile_diff_df.old_value <= banner_end_time.timestamp()))|((site_profile_diff_df.new_value >= banner_live_time.timestamp())&(site_profile_diff_df.new_value <= banner_end_time.timestamp()))]\n",
    "len(site_profile_diff_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_profile_diff_df['usp'] = [(user_id, site_id) for user_id, site_id in zip(site_profile_diff_df.user_id, site_profile_diff_df.site_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# journals published or created during the recruitment period\n",
    "sjournal_df = journal_df[((journal_df.published_at >= banner_live_time.timestamp() * 1000)|(journal_df.created_at >= banner_live_time.timestamp() * 1000))&((journal_df.published_at <= banner_end_time.timestamp() * 1000)|(journal_df.created_at <= banner_end_time.timestamp() * 1000))]\n",
    "len(sjournal_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selfvisit_diff_df = site_profile_diff_df[site_profile_diff_df.usp.isin(set(journal_df.usp))]\n",
    "len(selfvisit_diff_df), len(set(selfvisit_diff_df.user_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_ids = set(selfvisit_diff_df.user_id)\n",
    "sp_ids = set(sp_df[sp_df.role == 'Organizer'].user_id)\n",
    "journal_ids = set(sjournal_df.user_id)\n",
    "len(diff_ids), len(sp_ids), len(journal_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib_venn import venn3, venn3_circles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "venn3([diff_ids, sp_ids, journal_ids], ('SP Diff', 'SP Static', 'Journals'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given the lack of overlap, how many are we plausibly missing?\n",
    "# can use the participants (who we KNOW saw and clicked the banner as a comparison point\n",
    "# note: actually, we notably don't know that they saw and clicked the banner, since they may have provided the email address associated with a different CaringBridge account\n",
    "print(f\"{len(participant_user_ids - diff_ids)} participants not captured in site_profile diff updates\")\n",
    "print(f\"{len(participant_user_ids - sp_ids)} participants not captured in site_profile static snapshot\")\n",
    "print(f\"{len(participant_user_ids - journal_ids)} participants not captured in journal publications\")\n",
    "print(f\"{len(participant_user_ids - (diff_ids | sp_ids | journal_ids))} participants not captured in any of the above\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonparticipant_user_ids = (diff_ids | sp_ids | journal_ids) - participant_user_ids\n",
    "len(nonparticipant_user_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the user_id for matched users to a file\n",
    "with open(os.path.join(cbcore.data.paths.projects_data_dir, 'recsys-peer-match', 'participant', 'nonparticipant_user_ids.txt'), 'w') as outfile:\n",
    "    for user_id in nonparticipant_user_ids:\n",
    "        outfile.write(f\"{user_id}\\n\")\n",
    "print(\"Finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Participant validation\n",
    "\n",
    "Quickly confirming that the observed issues above occur for later snapshots as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_data_dir = os.path.join(cbcore.data.paths.projects_data_dir, 'recsys-peer-match', 'participant')\n",
    "with open(os.path.join(participant_data_dir, 'site_profile.pkl'), 'rb') as infile:\n",
    "    site_profiles = pickle.load(infile)\n",
    "print(len(site_profiles))\n",
    "\n",
    "# create a dataframe from the site profile entires\n",
    "ds = []\n",
    "for sp in site_profiles:\n",
    "    user_id = int(sp['userId'])\n",
    "    site_id = int(sp['siteId']) if 'siteId' in sp else -1\n",
    "    # not capturing: n, nl\n",
    "    d = {\n",
    "        'user_id': user_id,\n",
    "        'site_id': site_id,\n",
    "        'is_creator': sp['isCreator'] if 'isCreator' in sp else None,\n",
    "        'is_primary': sp['isPrimary'] if 'isPrimary' in sp else None,\n",
    "        'role': sp['role'],\n",
    "        'is_profile_deleted': sp['isProfileDeleted'] if 'isProfileDeleted' in sp else None,\n",
    "        'is_site_deleted': sp['isSiteDeleted'] if 'isSiteDeleted' in sp else None,\n",
    "        'is_stub': sp['isStub'] if 'isStub' in sp else None,\n",
    "        'created_at': sp['createdAt'].timestamp() * 1000 if 'createdAt' in sp else 0,\n",
    "        'updated_at': sp['updatedAt'].timestamp() * 1000 if 'updatedAt' in sp else 0,\n",
    "        'n': dict(sp['n']) if 'n' in sp and sp['n'] is not None else {},\n",
    "    }\n",
    "    ds.append(d)\n",
    "\n",
    "ssite_profile_df = pd.DataFrame(ds)\n",
    "ssite_profile_df.sample(n=10, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13 of our participants don't appear in the site_profile records at all...\n",
    "len(participant_user_ids - set(ssite_profile_df.user_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### site_profile extraction for the pseudo-control group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the nonparticipant / pseudo-control user ids\n",
    "nonparticipant_user_ids = set()\n",
    "with open(os.path.join(cbcore.data.paths.projects_data_dir, 'recsys-peer-match', 'participant', 'nonparticipant_user_ids.txt'), 'r') as infile:\n",
    "    for line in infile:\n",
    "        if line.strip() == \"\":\n",
    "            continue\n",
    "        user_id = int(line.strip())\n",
    "        nonparticipant_user_ids.add(user_id)\n",
    "len(nonparticipant_user_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# originally: 920 site_profiles\n",
    "from cbcore.script.computeCollectionCounts import iterate_collection\n",
    "# identify site_profiles for participants\n",
    "site_profiles = []\n",
    "input_filepath = os.path.join(cbcore.data.paths.raw_data_filepath, 'site_profile.bson.gz')\n",
    "for doc in tqdm(iterate_collection(input_filepath), desc='Processing documents', total=85713352):\n",
    "    user_id = int(doc['userId']) if 'userId' in doc else -1\n",
    "    if user_id in nonparticipant_user_ids:\n",
    "        site_profiles.append(doc)\n",
    "len(site_profiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the processed site_profiles to pickle\n",
    "output_dir = os.path.join(cbcore.data.paths.projects_data_dir, 'recsys-peer-match', 'nonparticipant')\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "with open(os.path.join(output_dir, 'site_profile.pkl'), 'wb') as outfile:\n",
    "    pickle.dump(site_profiles, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!du -h {output_dir}/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the site profiles\n",
    "nonparticipant_data_dir = os.path.join(cbcore.data.paths.projects_data_dir, 'recsys-peer-match', 'nonparticipant')\n",
    "with open(os.path.join(nonparticipant_data_dir, 'site_profile.pkl'), 'rb') as infile:\n",
    "    site_profiles = pickle.load(infile)\n",
    "print(len(site_profiles))\n",
    "\n",
    "# create a dataframe from the site profile entires\n",
    "ds = []\n",
    "for sp in site_profiles:\n",
    "    user_id = int(sp['userId'])\n",
    "    site_id = int(sp['siteId']) if 'siteId' in sp else -1\n",
    "    # not capturing: nl\n",
    "    d = {\n",
    "        'user_id': user_id,\n",
    "        'site_id': site_id,\n",
    "        'is_creator': sp['isCreator'] if 'isCreator' in sp else None,\n",
    "        'is_primary': sp['isPrimary'] if 'isPrimary' in sp else None,\n",
    "        'role': sp['role'],\n",
    "        'is_profile_deleted': sp['isProfileDeleted'] if 'isProfileDeleted' in sp else None,\n",
    "        'is_site_deleted': sp['isSiteDeleted'] if 'isSiteDeleted' in sp else None,\n",
    "        'is_stub': sp['isStub'] if 'isStub' in sp else None,\n",
    "        'created_at': sp['createdAt'].timestamp() * 1000 if 'createdAt' in sp else 0,\n",
    "        'updated_at': sp['updatedAt'].timestamp() * 1000 if 'updatedAt' in sp else 0,\n",
    "        'n': dict(sp['n']) if 'n' in sp and sp['n'] is not None else {},\n",
    "    }\n",
    "    ds.append(d)\n",
    "\n",
    "nonp_ssite_profile_df = pd.DataFrame(ds)\n",
    "nonp_ssite_profile_df.sample(n=10, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (shared-conda)",
   "language": "python",
   "name": "shared-conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
