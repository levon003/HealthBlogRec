{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Activity Monitoring\n",
    "===\n",
    "\n",
    " - Cloudfront logs\n",
    " - Data dumps\n",
    "\n",
    "### Cloudfront logs\n",
    "\n",
    "\n",
    "Query: `SELECT * FROM cloudfront_logs WHERE date >= DATE('2021-09-02') AND uri LIKE '/visit/%' AND query_string LIKE 'utm_source=SSE%';`\n",
    "\n",
    "### Email batches\n",
    "\n",
    "In batch 0, email_sent_timestamp is incorrect. First send was at `2021-09-02 14:57:24,997`. Last send was at `2021-09-02 14:59:30,662`.\n",
    "\n",
    "### Purpose of this notebook\n",
    "\n",
    "Originally, this notebook was used to explore and produce summary counts.\n",
    "\n",
    "Now the purpose is to produce three dataframes:\n",
    " - batch_df\n",
    " - rec_df\n",
    " - activity_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.rcParams['figure.dpi'] = 120\n",
    "matplotlib.rcParams['font.family'] = \"serif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import bson\n",
    "from bson.codec_options import CodecOptions\n",
    "from bson.raw_bson import RawBSONDocument\n",
    "from bson import ObjectId\n",
    "import gzip\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from glob import glob\n",
    "\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import dateutil\n",
    "import pytz\n",
    "\n",
    "import logging\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "git_root_dir = !git rev-parse --show-toplevel\n",
    "git_root_dir = Path(git_root_dir[0].strip())\n",
    "git_root_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "caringbridge_core_path = \"/home/lana/levon003/repos/caringbridge_core\"\n",
    "sys.path.append(caringbridge_core_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cbcore.data.paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert os.path.exists(cbcore.data.paths.raw_data_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caringbridge_core_path = \"/home/lana/levon003/repos/recsys-peer-match/src\"\n",
    "sys.path.append(caringbridge_core_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cbrec.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading previous batch recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_data_dir = os.path.join(cbcore.data.paths.projects_data_dir, 'recsys-peer-match', 'participant')\n",
    "!wc -l {participant_data_dir}/*.ndjson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in recommendations from previous rounds\n",
    "d = []\n",
    "for batch_id in [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]:\n",
    "    participant_data_filepath = os.path.join(participant_data_dir, f'participant_rec_data_b{batch_id}.ndjson')\n",
    "    with open(participant_data_filepath, 'r') as infile:\n",
    "        for line in infile:\n",
    "            participant = json.loads(line)\n",
    "            del participant['site_scores']\n",
    "            participant['batch_id'] = batch_id\n",
    "            d.append(participant)\n",
    "len(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_df = pd.DataFrame(d)\n",
    "batch_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(batch_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_df.sse_site_list.iloc[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_recced_site_map = {}\n",
    "for participant_id, group in batch_df.groupby('participant_id'):\n",
    "    recced_site_ids = []\n",
    "    for sse_site_list in group.sse_site_list:\n",
    "        recced_site_ids.extend([site['site_id'] for site in sse_site_list])\n",
    "    assert len(recced_site_ids) == len(set(recced_site_ids)), \"Duplicate rec was given.\"\n",
    "    recced_site_ids = list(set(recced_site_ids))\n",
    "    participant_recced_site_map[participant_id] = recced_site_ids\n",
    "len(participant_recced_site_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_recced_site_map[54217]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recced_usps = [(row.participant_id, site['site_id']) for row in batch_df.itertuples() for site in row.sse_site_list]\n",
    "len(recced_usps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(set(recced_usps)) == len(recced_usps), \"Duplicate rec given.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create rec_df\n",
    "rec_df = []\n",
    "for row in batch_df.itertuples(index=False):\n",
    "    for i, site in enumerate(row.sse_site_list):\n",
    "        rec = row._asdict()\n",
    "        del rec['sse_site_list']\n",
    "        if 'journal_body' in site:\n",
    "            # some of the data were written with different key names for cleaned_journal_{body,title}\n",
    "            # this code normalizes the key names\n",
    "            site = dict(site)\n",
    "            site['cleaned_journal_body'] = site['journal_body']\n",
    "            del site['journal_body']\n",
    "            site['cleaned_journal_title'] = site['journal_title']\n",
    "            del site['journal_title']\n",
    "        rec.update(site)\n",
    "        rec['rank'] = i\n",
    "        rec_df.append(rec)\n",
    "rec_df = pd.DataFrame(rec_df)\n",
    "len(rec_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add alias for participant_id\n",
    "rec_df['user_id'] = rec_df['participant_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_df.sample(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_recs = len(rec_df)\n",
    "total_recced_sites = len(set(rec_df.site_id))\n",
    "total_participants = len(set(rec_df.user_id))\n",
    "total_recs, total_recced_sites, total_participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Participant data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get participant data\n",
    "participant_id_filepath = os.path.join(git_root_dir, 'data/email/participant_ids.tsv')\n",
    "participant_df = pd.read_csv(participant_id_filepath, sep='\\t', header=0)\n",
    "print(len(participant_df))\n",
    "participant_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_batch_count_map = batch_df.groupby('participant_id').batch_id.nunique().to_dict()\n",
    "participant_df['n_total_recs'] = participant_df.user_id.map(lambda user_id: participant_batch_count_map[user_id] * 5 if user_id in participant_batch_count_map else 0)\n",
    "participant_df.n_total_recs.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_first_sse_map = batch_df.groupby('participant_id').sse_sent_timestamp.min()\n",
    "participant_df['first_sse_timestamp'] = participant_df.user_id.map(lambda user_id: participant_first_sse_map[user_id] if user_id in participant_first_sse_map else -1)\n",
    "participant_df.first_sse_timestamp.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cloudfront logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the logs as a dataframe\n",
    "s = datetime.now()\n",
    "cloudfront_filepath = os.path.join(git_root_dir, 'data/cloudfront/cloudfront_sse_visits_20220426.csv')\n",
    "cf_df = pd.read_csv(cloudfront_filepath, header=0, sep=',')\n",
    "print(f\"Loaded {len(cf_df)} rows in {datetime.now() - s}.\")\n",
    "cf_df.sample(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps = []\n",
    "for date, time in tqdm(zip(cf_df.date, cf_df.time), total=len(cf_df)):\n",
    "    d = datetime.strptime(date + \" \" + time, '%Y-%m-%d %H:%M:%S').replace(tzinfo=pytz.UTC)\n",
    "    timestamp = int(d.timestamp())\n",
    "    timestamps.append(timestamp)\n",
    "cf_df['timestamp'] = timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_df.method.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scf_df = cf_df[cf_df.method == 'GET'].copy()\n",
    "len(scf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_utm_info(query_string):\n",
    "    tokens = query_string.split(\"&\")\n",
    "    return {token.split(\"=\")[0]: token.split(\"=\")[1] for token in tokens}\n",
    "new_cols = pd.DataFrame(list(scf_df.query_string.map(get_utm_info)), index=scf_df.index)\n",
    "#pd.concat([scf_df, new_cols], axis=1)\n",
    "# add the columns\n",
    "scf_df = scf_df.merge(new_cols, left_index=True, right_index=True)\n",
    "scf_df['participant_id'] = scf_df.participant_id.astype(int)\n",
    "len(scf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch_num(utm_campaign):\n",
    "    tokens = utm_campaign.split(\"+\")\n",
    "    if len(tokens) == 2:\n",
    "        return 0\n",
    "    else:\n",
    "        return int(tokens[-1])\n",
    "\n",
    "scf_df['batch_id'] = scf_df.utm_campaign.map(get_batch_num)\n",
    "scf_df.batch_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_site_name(uri):\n",
    "    assert uri.startswith('/visit/')\n",
    "    return uri.split(\"/\")[2]\n",
    "scf_df['site_name'] = scf_df.uri.map(get_site_name)\n",
    "scf_df.site_name.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scf_df.utm_campaign.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scf_df.groupby('participant_id').batch_id.value_counts().rename('click_count').reset_index().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in how many batches has a participant participated?\n",
    "scf_df.groupby('participant_id').batch_id.nunique().rename(\"batch_participation_count\").sort_values(ascending=False).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scf_df.groupby('participant_id').site_name.nunique().rename(\"unique_site_visit_count\").reset_index().sort_values(by='unique_site_visit_count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scf_df.groupby('participant_id').site_name.nunique().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge in participant data\n",
    "scf_df = scf_df.merge(participant_df, how='left', left_on='participant_id', right_on='user_id', validate='many_to_one')\n",
    "len(scf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify time_to_click in seconds\n",
    "time_to_click = scf_df.timestamp - (scf_df.first_sse_timestamp / 1000)\n",
    "print(f\"{np.sum(time_to_click < 0) / len(time_to_click) * 100:.2f}% ({np.sum(time_to_click < 0)}) of clicks happened before the email was sent (due to Zach's testing); median time {np.median(time_to_click[time_to_click < 0]) / 60:.2f}mins\")\n",
    "#time_to_click = np.maximum(time_to_click, 0)\n",
    "scf_df['time_to_click'] = time_to_click\n",
    "scf_df[['participant_id', 'time_to_click']].sort_values('time_to_click')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scf_df = scf_df[scf_df.time_to_click > 0]\n",
    "len(scf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual exclusion finding\n",
    "sdf = scf_df[(scf_df.participant_id == 0)&(scf_df.batch_id == 1)].copy()\n",
    "sdf['iso'] = sdf.timestamp.map(lambda ts: datetime.utcfromtimestamp(ts).isoformat())\n",
    "sdf[['timestamp', 'iso']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scf_df = scf_df[~((scf_df.participant_id == 0)&(scf_df.batch_id == 1)&(scf_df.timestamp == 1633621589))]\n",
    "len(scf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scf_df.groupby('user_id').time_to_click.count().sort_values(ascending=False).rename(\"total_rec_clicks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_rec_clicks = scf_df.groupby('user_id').time_to_click.count().rename(\"total_rec_clicks\")\n",
    "total_rec_clicks.sum(), total_rec_clicks.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(14, 2))\n",
    "\n",
    "bins = 100\n",
    "counts, bin_edges = np.histogram(scf_df.timestamp, bins=bins)\n",
    "ax.plot(bin_edges[:-1], counts, label=\"All visits\")\n",
    "\n",
    "bin_width_s = bin_edges[1] - bin_edges[0]\n",
    "ax.set_ylabel(f\"Requests per {bin_width_s / 60 / 60:.1f} hours\")\n",
    "ax.set_xlabel(\"Date (central time)\")\n",
    "ax.set_title(\"Cloudfront site visits from site suggestion emails\")\n",
    "\n",
    "# note this is when the FIRST email was sent in batch 0\n",
    "ax.axvline(1630612646, linestyle='--', color='black', label='batch')\n",
    "print(datetime.utcfromtimestamp(1630612646))\n",
    "\n",
    "ax.xaxis.set_major_locator(matplotlib.ticker.MaxNLocator(20)) \n",
    "ax.xaxis.set_major_formatter(matplotlib.ticker.FuncFormatter(lambda x, y: datetime.utcfromtimestamp(x).replace(tzinfo=pytz.timezone('US/Central')).strftime(\"%m/%d\\n%H:%M\")))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "\n",
    "xs = scf_df.time_to_click / 60 / 60 / 24\n",
    "bins = np.arange(xs.min(), xs.max(), 1)\n",
    "counts, bin_edges = np.histogram(xs, bins=bins)\n",
    "ax.plot(bin_edges[:-1], counts, label=\"All visits\", linewidth=1)\n",
    "\n",
    "bin_width_s = bin_edges[1] - bin_edges[0]\n",
    "ax.set_ylabel(f\"Visits per {bin_width_s:.1f} days\")\n",
    "ax.set_xlabel(\"Time to click (hours)\")\n",
    "ax.set_title(\"Cloudfront site visits from site suggestion emails\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scf_df.utm_content.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scf_df.participant_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total number of participants who clicked a link\n",
    "len(scf_df.participant_id.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scf_df.site_name.value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of unique (participant -> site) visit pairs\n",
    "np.sum(pd.crosstab(scf_df.participant_id, scf_df.site_name).to_numpy() > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of times a site was visited 2 or more times by a participant\n",
    "np.sum(pd.crosstab(scf_df.participant_id, scf_df.site_name).to_numpy() >= 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(scf_df.site_name, scf_df.utm_content, margins=True).sort_values('All', ascending=False).head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scf_df.request_ip.value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visits and Follows\n",
    "\n",
    "From the site_profile diffs, look for:\n",
    " - Visits to the site\n",
    " - Follows of the site\n",
    " - Role changes (specifically to \"Removed\", but anything involving Organizer's is interesting too)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_user_ids = set(participant_df[participant_df.n_total_recs > 0].user_id)\n",
    "len(participant_user_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# originally: 920 site_profiles\n",
    "from cbcore.script.computeCollectionCounts import iterate_collection\n",
    "# identify site_profiles for participants\n",
    "site_profiles = []\n",
    "input_filepath = os.path.join(cbcore.data.paths.raw_data_filepath, 'site_profile.bson.gz')\n",
    "for doc in tqdm(iterate_collection(input_filepath), desc='Processing documents', total=85713352):\n",
    "    user_id = int(doc['userId']) if 'userId' in doc else -1\n",
    "    if user_id in participant_user_ids:\n",
    "        site_profiles.append(doc)\n",
    "len(site_profiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the processed site_profiles to pickle\n",
    "output_dir = os.path.join(cbcore.data.paths.projects_data_dir, 'recsys-peer-match', 'participant')\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "with open(os.path.join(output_dir, 'site_profile.pkl'), 'wb') as outfile:\n",
    "    pickle.dump(site_profiles, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the site profiles\n",
    "with open(os.path.join(participant_data_dir, 'site_profile.pkl'), 'rb') as infile:\n",
    "    site_profiles = pickle.load(infile)\n",
    "print(len(site_profiles))\n",
    "\n",
    "# create a dataframe from the site profile entires\n",
    "ds = []\n",
    "for sp in site_profiles:\n",
    "    user_id = int(sp['userId'])\n",
    "    site_id = int(sp['siteId']) if 'siteId' in sp else -1\n",
    "    # not capturing: n, nl\n",
    "    d = {\n",
    "        'user_id': user_id,\n",
    "        'site_id': site_id,\n",
    "        'is_creator': sp['isCreator'] if 'isCreator' in sp else None,\n",
    "        'is_primary': sp['isPrimary'] if 'isPrimary' in sp else None,\n",
    "        'role': sp['role'],\n",
    "        'is_profile_deleted': sp['isProfileDeleted'] if 'isProfileDeleted' in sp else None,\n",
    "        'is_site_deleted': sp['isSiteDeleted'] if 'isSiteDeleted' in sp else None,\n",
    "        'is_stub': sp['isStub'] if 'isStub' in sp else None,\n",
    "        'created_at': sp['createdAt'].timestamp() * 1000 if 'createdAt' in sp else 0,\n",
    "        'updated_at': sp['updatedAt'].timestamp() * 1000 if 'updatedAt' in sp else 0,\n",
    "        'n': dict(sp['n']) if 'n' in sp and sp['n'] is not None else {},\n",
    "    }\n",
    "    ds.append(d)\n",
    "\n",
    "ssite_profile_df = pd.DataFrame(ds)\n",
    "ssite_profile_df.sample(n=10, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssite_profile_df.role.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict(site_profiles[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsite_profile_df = ssite_profile_df.set_index(['user_id', 'site_id']).sort_index()\n",
    "rsite_profile_df = rsite_profile_df.loc[rsite_profile_df.index.intersection(recced_usps)].reset_index()\n",
    "len(rsite_profile_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsite_profile_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First clicks analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the site metadata dataframe\n",
    "# this is created in caringbridge_core from the new data\n",
    "site_metadata_working_dir = \"/home/lana/shared/caringbridge/data/derived/site_metadata\"\n",
    "s = datetime.now()\n",
    "site_metadata_filepath = os.path.join(site_metadata_working_dir, \"site_metadata.feather\")\n",
    "site_info_df = pd.read_feather(site_metadata_filepath)\n",
    "assert np.sum(site_info_df.site_id.value_counts() > 1) == 0, \"Site ids are not globally unique.\"\n",
    "print(datetime.now() - s)\n",
    "len(site_info_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_duplicate_names = np.sum(site_info_df.name.value_counts() > 1)\n",
    "print(f\"{n_duplicate_names} ({n_duplicate_names / len(site_info_df):.2%} duplicate site URL names.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicate site names from the site_info_df\n",
    "# keeping the most recent by created_at date\n",
    "print(len(site_info_df))\n",
    "site_info_df = site_info_df.sort_values(by='created_at').drop_duplicates(subset='name', keep='last', ignore_index=True)\n",
    "print(len(site_info_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add site_id to the cloudfront data\n",
    "scf_df = pd.merge(scf_df, site_info_df[['site_id', 'name']], how='left', left_on='site_name', right_on='name', validate='many_to_one')\n",
    "len(scf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_clicks = scf_df.sort_values(by='timestamp').drop_duplicates(subset=['user_id', 'site_id'], keep='first')\n",
    "len(first_clicks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_clicks_map = {(row.user_id, row.site_id): row.timestamp for row in first_clicks.itertuples()}\n",
    "first_visits_map = {(row.user_id, row.site_id): row.created_at / 1000 for row in rsite_profile_df.itertuples()}\n",
    "len(first_clicks_map), len(first_visits_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicks & logged-in visits are not the same...\n",
    "set(first_clicks_map.keys()) == set(first_visits_map.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_first_click_or_visit_pairs = set(first_clicks_map.keys()) | set(first_visits_map.keys())\n",
    "len(all_first_click_or_visit_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_rec_map = {}\n",
    "for user_id, group in batch_df.groupby('participant_id'):\n",
    "    participant_rec_map[user_id] = []\n",
    "    for sse in group.itertuples():\n",
    "        for site in sse.sse_site_list:\n",
    "            participant_rec_map[user_id].append(site['site_id'])\n",
    "len(participant_rec_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_rec_time_map = {}\n",
    "for user_id, group in batch_df.groupby('participant_id'):\n",
    "    participant_rec_time_map[user_id] = {}\n",
    "    for sse in group.itertuples():\n",
    "        for site in sse.sse_site_list:\n",
    "            participant_rec_time_map[user_id][site['site_id']] = sse.sse_sent_timestamp\n",
    "len(participant_rec_time_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_total = 0\n",
    "n_visit_only = 0\n",
    "n_click_only = 0\n",
    "n_both = 0\n",
    "n_visit_unrelated_to_rec = 0\n",
    "n_visit_pre_rec = 0\n",
    "rec_to_visit_time_diffs = []\n",
    "click_to_visit_time_diffs = []\n",
    "\n",
    "for usp in all_first_click_or_visit_pairs:\n",
    "    if usp in first_clicks_map:\n",
    "        first_click_ts = first_clicks_map[usp]\n",
    "    else:\n",
    "        first_click_ts = None\n",
    "    if usp in first_visits_map:\n",
    "        first_visit_ts = first_visits_map[usp]\n",
    "    else:\n",
    "        first_visit_ts = None\n",
    "    \n",
    "    n_total += 1\n",
    "    if first_visit_ts and first_click_ts:\n",
    "        n_both += 1\n",
    "        click_to_visit_time_diffs.append(first_visit_ts - first_click_ts)\n",
    "    elif first_visit_ts and not first_click_ts:\n",
    "        # didn't register click OR visited pre-study\n",
    "        n_visit_only += 1\n",
    "        \n",
    "        user_id, site_id = usp\n",
    "        # was this site actually recommended?\n",
    "        was_recced = site_id in participant_rec_map[user_id]\n",
    "        if not was_recced:\n",
    "            n_visit_unrelated_to_rec += 1\n",
    "            continue\n",
    "        # did this visit occur before the associated recommendation?\n",
    "        recced_time = participant_rec_time_map[user_id][site_id] / 1000\n",
    "        rec_to_visit_time_diffs.append(first_visit_ts - recced_time)\n",
    "        if first_visit_ts < recced_time:\n",
    "            n_visit_pre_rec += 1\n",
    "        print(datetime.utcfromtimestamp(recced_time).isoformat())\n",
    "        \n",
    "    elif not first_visit_ts and first_click_ts:\n",
    "        # visit while not logged in\n",
    "        n_click_only += 1\n",
    "    elif not first_visit_ts and not first_click_ts:\n",
    "        raise ValueError(\"what?\")\n",
    "    else:\n",
    "        raise ValueError(\"big what.\")\n",
    "n_total, n_visit_only, n_click_only, n_both, n_visit_unrelated_to_rec, n_visit_pre_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "24 / len(scf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time in hours between rec email sent time and the visit\n",
    "# no obvious patterns... seems to approximately mirror the distribution of time_to_click\n",
    "np.array(rec_to_visit_time_diffs) / 60 / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "click_to_visit_time_diffs = np.array(click_to_visit_time_diffs)\n",
    "len(click_to_visit_time_diffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.minimum(click_to_visit_time_diffs, 100), log=True, bins=50)\n",
    "plt.axvline(np.median(click_to_visit_time_diffs), label=f\"median={np.median(click_to_visit_time_diffs):.2f}s\", color='black', linestyle='--')\n",
    "plt.legend()\n",
    "plt.title(\"Distribution of time between Cloudfront click and site_profile visit\")\n",
    "plt.xlabel(\"Time difference in seconds\")\n",
    "plt.ylabel(\"Number of first clicks\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine cloudfront and site_profile data into the first_click_map\n",
    "first_clicks = scf_df.sort_values(by='timestamp').drop_duplicates(subset=['user_id', 'site_id'], keep='first')\n",
    "first_click_map = {(row.user_id, row.site_id): row.timestamp for row in first_clicks.itertuples()}\n",
    "for row in rsite_profile_df.itertuples():\n",
    "    usp = (row.user_id, row.site_id)\n",
    "    if usp not in first_click_map:\n",
    "        first_click_map[usp] = int(row.created_at / 1000)\n",
    "len(first_click_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_click_timestamps = []\n",
    "for row in rec_df.itertuples():\n",
    "    usp = (row.user_id, row.site_id)\n",
    "    if usp in first_click_map:\n",
    "        first_click_timestamp = first_click_map[usp]\n",
    "    else:\n",
    "        first_click_timestamp = -1\n",
    "    first_click_timestamps.append(first_click_timestamp)\n",
    "# convert to milliseconds\n",
    "rec_df['first_click_timestamp'] = np.array(first_click_timestamps) * 1000\n",
    "rec_df['was_clicked'] = rec_df.first_click_timestamp >= 0\n",
    "rec_df.was_clicked.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f\"{np.sum(rec_df.was_clicked) / len(rec_df):.2%} of site recommendations were clicked\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf = rec_df[rec_df.was_clicked]\n",
    "#assert np.all(sdf.first_click_timestamp > sdf.sse_sent_timestamp)\n",
    "plt.hist((sdf.first_click_timestamp - sdf.sse_sent_timestamp) / 1000 / 60 / 60, bins=np.arange(-5, 100))\n",
    "plt.xlabel(\"Time to click (hours)\")\n",
    "plt.ylabel(\"Distribution of time-to-click\")\n",
    "plt.show()\n",
    "sdf[(sdf.first_click_timestamp - sdf.sse_sent_timestamp) < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_click_df = rec_df[rec_df.was_clicked]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = first_click_df.user_id.value_counts()\n",
    "xs = range(len(ys))\n",
    "plt.bar(xs, ys)\n",
    "plt.title(\"Number of clicks by participant\")\n",
    "plt.xlabel(\"Participant rank by number of clicks\")\n",
    "plt.ylabel(\"Number of unique clicks\")\n",
    "plt.show()\n",
    "print(np.sum(ys > 0), len(first_click_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute number of clicks at the batch level\n",
    "batch_clicked_map = {}\n",
    "for sse, group in rec_df.groupby(['participant_id', 'batch_id']):\n",
    "    n_clicked = np.sum(group.was_clicked)\n",
    "    batch_clicked_map[sse] = n_clicked\n",
    "n_batch_clicks_list = []\n",
    "for row in batch_df.itertuples():\n",
    "    n_batch_clicks = batch_clicked_map[(row.participant_id, row.batch_id)]\n",
    "    n_batch_clicks_list.append(n_batch_clicks)\n",
    "batch_df['n_batch_clicks'] = n_batch_clicks_list\n",
    "batch_df.n_batch_clicks.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts, _ = np.histogram(batch_df.n_batch_clicks, bins = np.arange(0, 7))\n",
    "#plt.hist(batch_df.n_batch_clicks, , log=True)\n",
    "plt.bar(range(len(counts)), counts)\n",
    "plt.yscale('log')\n",
    "for i, count in enumerate(counts):\n",
    "    plt.text(i, count, f\"{count}\", ha='center', va='bottom')\n",
    "plt.xlabel(\"Number of clicks\")\n",
    "plt.ylabel(\"Number of batches\")\n",
    "plt.title(\"Distribution of clicks per batch\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# six participants clicked every link in an email\n",
    "batch_df[batch_df.n_batch_clicks == 5].participant_id.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### v1 annotations\n",
    "\n",
    "Every annotation in a batch that was clicked at least once (but not 5 times)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eligible_batches = [(row.participant_id, row.batch_id) for row in batch_df[(batch_df.n_batch_clicks > 0)&(batch_df.n_batch_clicks < 5)].itertuples()]\n",
    "len(eligible_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = ['site_id','journal_oid','site_title','cleaned_journal_title','cleaned_journal_body',\n",
    "          'NOT what/how patient is doing?','good news?','bad news?','EOA/gratitude?','author visible?','expressive writing?']\n",
    "clicked_batch_sse_annotation_filepath = os.path.join(participant_data_dir, 'clicked_batch_sse_annotation_v1.tsv')\n",
    "\n",
    "duplicate_avoided = 0\n",
    "lines_written = 0\n",
    "written_journal_oids = set()\n",
    "with open(clicked_batch_sse_annotation_filepath, 'w') as outfile:\n",
    "    outfile.write('\\t'.join(header) + '\\n')\n",
    "    for row in rec_df.sample(frac=1).itertuples():\n",
    "        if (row.participant_id, row.batch_id) in eligible_batches:\n",
    "            if row.journal_oid in written_journal_oids:\n",
    "                duplicate_avoided += 1\n",
    "                continue\n",
    "            written_journal_oids.add(row.journal_oid)\n",
    "            cleaned_journal_title = row.cleaned_journal_title.replace('\\t', '    ').replace('\\n', ' NEWLINE ').replace('\"', '\\\\\"')\n",
    "            cleaned_journal_body = row.cleaned_journal_body.replace('\\t', '    ').replace('\\n', ' NEWLINE ').replace('\"', '\\\\\"')\n",
    "            line = f\"{row.site_id}\\t{row.journal_oid}\\t{row.site_title}\\t\\\"{cleaned_journal_title}\\\"\\t\\\"{cleaned_journal_body}\\\"\\t\\t\\t\\t\\t\\t\\n\"\n",
    "            assert '\\n' not in line[:-1]\n",
    "            outfile.write(line)\n",
    "            lines_written += 1\n",
    "lines_written, duplicate_avoided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(clicked_batch_sse_annotation_filepath, 'r') as infile:\n",
    "    for line in infile:\n",
    "        tokens = line.split(\"\\t\")\n",
    "        assert len(tokens) == 11, line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pd.read_csv(clicked_batch_sse_annotation_filepath, sep='\\t', header=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### v2 annotations\n",
    "\n",
    "Every batch from a participant that clicked at least once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1_clicked_batch_sse_annotation_filepath = os.path.join(participant_data_dir, 'clicked_batch_sse_annotation_v1.tsv')\n",
    "v1_journal_oids = set(pd.read_csv(v1_clicked_batch_sse_annotation_filepath, sep='\\t', header=0).journal_oid)\n",
    "len(v1_journal_oids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify every participant who clicked at least once\n",
    "eligible_participants = set([row.participant_id for row in batch_df[batch_df.n_batch_clicks > 0].itertuples()])\n",
    "# identify all batches already present in the v1 annotations\n",
    "v1_eligible_batches = [(row.participant_id, row.batch_id) for row in batch_df[(batch_df.n_batch_clicks > 0)&(batch_df.n_batch_clicks < 5)].itertuples()]\n",
    "# identify all batches NOT in v1 but that are\n",
    "eligible_batches = [(row.participant_id, row.batch_id) for row in batch_df[batch_df.participant_id.isin(eligible_participants)].itertuples()\n",
    "                   if (row.participant_id, row.batch_id) not in v1_eligible_batches]\n",
    "len(eligible_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = ['site_id','journal_oid','site_title','cleaned_journal_title','cleaned_journal_body',\n",
    "          'NOT what/how patient is doing?','good news?','bad news?','EOA/gratitude?','author visible?','expressive writing?']\n",
    "clicked_batch_sse_annotation_filepath = os.path.join(participant_data_dir, 'clicked_batch_sse_annotation_v2.tsv')\n",
    "\n",
    "duplicate_avoided = 0\n",
    "lines_written = 0\n",
    "written_journal_oids = set()\n",
    "with open(clicked_batch_sse_annotation_filepath, 'w') as outfile:\n",
    "    outfile.write('\\t'.join(header) + '\\n')\n",
    "    for row in rec_df.sample(frac=1).itertuples():\n",
    "        if (row.participant_id, row.batch_id) in eligible_batches:\n",
    "            if row.journal_oid in written_journal_oids or row.journal_oid in v1_journal_oids:\n",
    "                duplicate_avoided += 1\n",
    "                continue\n",
    "            written_journal_oids.add(row.journal_oid)\n",
    "            cleaned_journal_title = row.cleaned_journal_title.replace('\\t', '    ').replace('\\n', ' NEWLINE ').replace('\"', '\\\\\"')\n",
    "            cleaned_journal_body = row.cleaned_journal_body.replace('\\t', '    ').replace('\\n', ' NEWLINE ').replace('\"', '\\\\\"')\n",
    "            line = f\"{row.site_id}\\t{row.journal_oid}\\t{row.site_title}\\t\\\"{cleaned_journal_title}\\\"\\t\\\"{cleaned_journal_body}\\\"\\t\\t\\t\\t\\t\\t\\n\"\n",
    "            assert '\\n' not in line[:-1]\n",
    "            outfile.write(line)\n",
    "            lines_written += 1\n",
    "lines_written, duplicate_avoided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pd.read_csv(clicked_batch_sse_annotation_filepath, sep='\\t', header=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### v3 annotations\n",
    "\n",
    "Random sample of some kind. Sensible options:\n",
    " - Random sample of batches (able to answer \"what % of batches contained good news?\")\n",
    " - Random sample of recommended journals (able to answer: \"what % of recommendations contained good news?\")\n",
    " - Random sample of journals, weighted by occurrence (able to answer: \"what % of the recommendations viewed by participants contained good news?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify every participant who clicked at least once\n",
    "eligible_participants = set([row.participant_id for row in batch_df[batch_df.n_batch_clicks > 0].itertuples()])\n",
    "# identify all batches captured in v1 and v2\n",
    "v1_v2_eligible_batches = [(row.participant_id, row.batch_id) for row in batch_df[batch_df.participant_id.isin(eligible_participants)].itertuples()]\n",
    "len(v1_v2_eligible_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO figure out how we want to random sample\n",
    "# keep track of which updates are present in v1_v2_eligible_batches and make sure we don't multiply annotate them...\n",
    "# this will be somewhat complicated code I think, probably need to change how we sample the rec_df\n",
    "len(rec_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utility bash for copying and transferring files\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp {clicked_batch_sse_annotation_filepath} .\n",
    "!pwd\n",
    "!ls ./*.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visits, but better and more in depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the journal dataframe with the index\n",
    "s = datetime.now()\n",
    "journal_metadata_dir = \"/home/lana/shared/caringbridge/data/derived/journal_metadata\"\n",
    "journal_metadata_filepath = os.path.join(journal_metadata_dir, \"journal_metadata.feather\")\n",
    "journal_df = pd.read_feather(journal_metadata_filepath)\n",
    "print(datetime.now() - s)\n",
    "len(journal_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = datetime.now()\n",
    "journal_df['usp'] = [(row.user_id, row.site_id) for row in journal_df.itertuples()]\n",
    "print(datetime.now() - s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the site profile diff'\n",
    "# rows should be >= 37M+\n",
    "s = datetime.now()\n",
    "site_profile_diff_filepath = os.path.join(cbcore.data.paths.projects_data_dir, 'caringbridge_core', 'site_profile_diff', 'site_profile_diff.tsv')\n",
    "site_profile_diff_df = pd.read_csv(site_profile_diff_filepath, sep='\\t', header=0)\n",
    "print(f\"Read {len(site_profile_diff_df)} rows in {datetime.now() - s}.\")\n",
    "site_profile_diff_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = datetime.now()\n",
    "site_profile_diff_df['usp'] = [(row.user_id, row.site_id) for row in site_profile_diff_df.itertuples()]\n",
    "print(datetime.now() - s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_counts = site_profile_diff_df.snapshot_date.value_counts().sort_index()\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 3))\n",
    "\n",
    "xs = np.arange(len(daily_counts))\n",
    "ax.plot(xs, daily_counts)\n",
    "nl = '\\n'\n",
    "for x, count in zip(xs, daily_counts):\n",
    "    ax.text(x, count, f\"{count / 1000:,.0f}K\", ha='center', va='bottom' if x % 2 == 0 else 'top', fontsize='xx-small')  # {nl if x % 2 == 0 else ''}\n",
    "\n",
    "ax.set_xticks(xs)\n",
    "ax.set_xticklabels([f\"{str(i)[4:6] + '/' + str(i)[6:8] + nl + str(i)[0:4] if ind % 12 == 0 else ''}\" for ind, i in enumerate(daily_counts.index)])\n",
    "\n",
    "ax.set_title(\"Daily updates to the site_profile collection, captured via snapshot\")\n",
    "ax.set_xlabel(\"Snapshot date\")\n",
    "ax.set_ylabel(\"Number of updates\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "np.median(daily_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_profile_diff_df.key.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: this is computationally expensive\n",
    "s = datetime.now()\n",
    "rsite_profile_diff_df = site_profile_diff_df.set_index(['user_id', 'site_id']).sort_index()\n",
    "rsite_profile_diff_df = rsite_profile_diff_df.loc[rsite_profile_diff_df.index.intersection(recced_usps)].reset_index()\n",
    "print(datetime.now() - s)\n",
    "len(rsite_profile_diff_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsite_profile_diff_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New implementation\n",
    "\n",
    "First and subsequent visits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssite_profile_df['usp'] = [(row.user_id, row.site_id) for row in ssite_profile_df.itertuples()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssite_profile_df['is_self_author'] = (ssite_profile_df.is_creator == 1)|(ssite_profile_df.is_primary == 1)|(ssite_profile_df.role == 'Organizer')\n",
    "ssite_profile_df.is_self_author.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sjournal_df = journal_df[journal_df.user_id.isin(set(ssite_profile_df.user_id))]\n",
    "len(sjournal_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "journal_usp_set = set([(row.user_id, row.site_id) for row in sjournal_df.itertuples()])\n",
    "len(journal_usp_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unlike in the pseudo-control group, no issues with authors not being marked as authors but having written journal updates\n",
    "# however, there are 4 USPs on which a participant is an author but they haven't written any journal updates\n",
    "pd.crosstab(ssite_profile_df.is_self_author, ssite_profile_df.usp.isin(journal_usp_set).rename(\"is_journal_author\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# redundant with above\n",
    "ssite_profile_df.loc[ssite_profile_df.usp.isin(journal_usp_set), 'is_self_author'] = True\n",
    "ssite_profile_df.is_self_author.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the first_visit_df for others' sites only\n",
    "# I think this is not used here?\n",
    "#first_visit_df = ssite_profile_df[~ssite_profile_df.is_self_author]\n",
    "#len(first_visit_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on journal authors and first visits, identify the set of author USPs (where the user_id is an author of site_id)\n",
    "author_usp_set = set(ssite_profile_df[ssite_profile_df.is_self_author].usp) | set(journal_df.usp)\n",
    "len(author_usp_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_user_id_set = set(ssite_profile_df[ssite_profile_df.is_self_author].user_id) | set(journal_df.user_id)\n",
    "len(author_user_id_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# author-to-author site visits\n",
    "# excludes all non-authors\n",
    "# excludes all self-visits\n",
    "site_visits = site_profile_diff_df[(site_profile_diff_df.key == 'updatedAt')&(site_profile_diff_df.user_id.isin(author_user_id_set)&(~site_profile_diff_df.usp.isin(author_usp_set)))].copy()\n",
    "site_visits.key = 'site_profile_diff'\n",
    "site_visits.new_value = site_visits.new_value.astype(float)\n",
    "len(site_visits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_visits.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: adding the cloudfront data means a given USP is no longer unique within a snapshot\n",
    "cloudfront_clicks_df = pd.DataFrame([{\n",
    "    'user_id': row.user_id,\n",
    "    'site_id': row.site_id,\n",
    "    'snapshot_date': int((datetime.utcfromtimestamp(row.timestamp) + relativedelta(days=1)).strftime(\"%Y%m%d\")),\n",
    "    'key': 'cloudfront',\n",
    "    'old_value': 0,\n",
    "    'new_value': row.timestamp,\n",
    "    'usp': (row.user_id, row.site_id),\n",
    "} for row in scf_df.itertuples()])\n",
    "print(len(cloudfront_clicks_df))\n",
    "site_visits = pd.concat([site_visits, cloudfront_clicks_df]).sort_values(by=['new_value'])\n",
    "len(site_visits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bisect\n",
    "TOLERANCE = 1000 * 60 * 60 * 7  # 7 hours, chosen so that if there's a bug with UTC (5 hours) and DST (1 hour) we still have an hour to treat them as essentially the same time\n",
    "\n",
    "# instantiate\n",
    "user_site_interactions = {\n",
    "    (row.user_id, row.site_id): [row.created_at,] for row in ssite_profile_df[~ssite_profile_df.is_self_author].itertuples()\n",
    "}\n",
    "len(user_site_interactions)\n",
    "\n",
    "n_missing_site_profiles = 0\n",
    "n_potential_missed_visits = 0\n",
    "n_empty_curr_values = 0\n",
    "n_outoforder_inserts = 0\n",
    "for row in tqdm(site_visits.itertuples(), total=len(site_visits)):\n",
    "    usp = (row.user_id, row.site_id)\n",
    "    if usp not in user_site_interactions:\n",
    "        # these are author interactions, but the author in question is not a participant\n",
    "        n_missing_site_profiles += 1\n",
    "        user_site_interactions[usp] = [] #[float(row.old_value) * 1000,] if float(row.old_value) > 0 else [float(row.new_value) * 1000,]\n",
    "    visit_list = user_site_interactions[usp]\n",
    "    last_visit = float(row.old_value) * 1000\n",
    "    curr_visit = float(row.new_value) * 1000\n",
    "    \n",
    "    if last_visit > 0 and last_visit not in visit_list:\n",
    "        bisect.insort_left(visit_list, last_visit)\n",
    "    assert curr_visit > 0\n",
    "    if curr_visit not in visit_list:\n",
    "        bisect.insort_left(visit_list, curr_visit)\n",
    "    continue\n",
    "    \n",
    "    assert curr_visit > 0\n",
    "    if curr_visit in visit_list:\n",
    "        continue\n",
    "    if last_visit == 0:\n",
    "        n_empty_curr_values += 1\n",
    "    elif last_visit < visit_list[-1] - TOLERANCE and last_visit not in visit_list:\n",
    "        logging.warning(\"updatedAt's old value was before the creation date of the site_profile or before the value from the previous snapshot.\")\n",
    "        print(last_visit, visit_list, curr_visit)\n",
    "        break\n",
    "    elif last_visit > visit_list[-1] + 5000:\n",
    "        n_potential_missed_visits += 1\n",
    "        visit_list.append(last_visit)\n",
    "    #assert curr_visit >= visit_list[-1], f\"{curr_visit - np.array(visit_list).min()} {np.array(visit_list) - np.array(visit_list).min()}\"\n",
    "    if curr_visit < visit_list[-1]:\n",
    "        # determine where to insert into the sorted list\n",
    "        bisect.insort_left(visit_list, curr_visit)\n",
    "        n_outoforder_inserts += 1\n",
    "        #visit_list.insert(0, curr_visit)\n",
    "    else:\n",
    "        visit_list.append(curr_visit)\n",
    "n_missing_site_profiles, n_potential_missed_visits, n_outoforder_inserts, len(user_site_interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visits_df = pd.DataFrame([{'usp': usp, 'visit_timestamp': visit_timestamp} for usp, visit_list in user_site_interactions.items() for visit_timestamp in visit_list])\n",
    "visits_df['user_id'] = visits_df.usp.map(lambda usp: usp[0])\n",
    "visits_df['site_id'] = visits_df.usp.map(lambda usp: usp[1])\n",
    "len(visits_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I believe this will result in bucketing by CENTRAL TIME dates\n",
    "visits_df['visit_date'] = visits_df.visit_timestamp.map(lambda ts: int(datetime.utcfromtimestamp(int(ts / 1000)).strftime('%Y%m%d')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 1.2))\n",
    "\n",
    "start_date = 20210701\n",
    "daily_visits = visits_df[visits_df.visit_date >= start_date].groupby('visit_date').usp.nunique()\n",
    "\n",
    "ax.plot(np.arange(len(daily_visits)), daily_visits)\n",
    "ax.set_title(\"Daily visits by authors to peer sites\", fontsize=10)\n",
    "def format_date(x, pos=None):\n",
    "    return f\"{(datetime.strptime(str(start_date), '%Y%m%d') + relativedelta(days=int(x))).strftime('%Y-%m-%d')}\"\n",
    "ax.xaxis.set_major_formatter(format_date)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svisits_df = visits_df[visits_df.usp.isin(recced_usps)]\n",
    "len(svisits_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many \"return visits\" are there?\n",
    "def count_return_visits(visit_timestamps, hour_threshold=7):\n",
    "    if len(visit_timestamps) <= 1:\n",
    "        return 0\n",
    "    return_visit_threshold = 1000 * 60 * 60 * hour_threshold  # hour_threshold hours\n",
    "    \n",
    "    n_return_visits = 0\n",
    "    first_timestamp = visit_timestamps[0]\n",
    "    for timestamp in visit_timestamps[1:]:\n",
    "        if timestamp > first_timestamp + return_visit_threshold:\n",
    "            n_return_visits += 1\n",
    "    return n_return_visits\n",
    "ds = []\n",
    "for usp, visit_timestamps in user_site_interactions.items():\n",
    "    ds.append({\n",
    "        'usp': usp,\n",
    "        'n_repeat_visits_7hr': count_return_visits(visit_timestamps, hour_threshold=7),\n",
    "        'n_days_visited': count_return_visits(visit_timestamps, hour_threshold=24),\n",
    "    })\n",
    "repeat_visit_df = pd.DataFrame(ds)\n",
    "repeat_visit_df = repeat_visit_df[repeat_visit_df.usp.isin(recced_usps)]\n",
    "repeat_visit_df['user_id'] = [usp[0] for usp in repeat_visit_df.usp]\n",
    "repeat_visit_df['site_id'] = [usp[1] for usp in repeat_visit_df.usp]\n",
    "len(repeat_visit_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeat_visit_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "ax = axes[0]\n",
    "xs = repeat_visit_df.n_days_visited\n",
    "ax.hist(xs, bins=np.arange(0, xs.max()), log=True)\n",
    "ax.set_title(f\"Days visited (M={xs.mean():.2f})\")\n",
    "\n",
    "ax = axes[1]\n",
    "xs = repeat_visit_df.n_repeat_visits_7hr\n",
    "ax.hist(xs, bins=np.arange(0, xs.max()), log=True)\n",
    "ax.set_title(f\"Repeat visits (M={xs.mean():.2f})\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeat_visit_df.n_repeat_visits_7hr.sum()  # collectively, participants made 589 repeat visits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = (repeat_visit_df.n_repeat_visits_7hr > 0).sum()\n",
    "c, c / total_recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = len(set(repeat_visit_df[repeat_visit_df.n_repeat_visits_7hr > 0].user_id))\n",
    "c, c / total_participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = len(repeat_visit_df[repeat_visit_df.n_repeat_visits_7hr > 0].groupby('site_id').user_id.count())\n",
    "c, c / total_recced_sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute counts for first clicks as well\n",
    "c = len(repeat_visit_df)\n",
    "c, c / total_recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = len(set(repeat_visit_df.user_id))\n",
    "c, c / total_participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = len(set(repeat_visit_df.site_id))\n",
    "c, c / total_recced_sites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Old implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many unique user->site updates did we observe?\n",
    "rsite_profile_diff_df.groupby(['user_id', 'site_id']).ngroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_df = rsite_profile_diff_df.merge(rsite_profile_df, how='outer', on=['user_id', 'site_id'])\n",
    "len(sp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_df.key.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NA values... need to deal with this better\n",
    "sp_df.snapshot_date.isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visit actions\n",
    "#sdf = sp_df[sp_df.key == 'updatedAt']\n",
    "ds = []\n",
    "for usp, group in sp_df.groupby(['user_id', 'site_id']):\n",
    "    n_potential_missed_visits = 0\n",
    "    prev_visit_timestamp = int(group.iloc[0].created_at)\n",
    "    visit_timestamps = [prev_visit_timestamp,]\n",
    "    for row in group[group.key == 'updatedAt'].sort_values(by='new_value').itertuples():\n",
    "        new_value = int(row.new_value) * 1000\n",
    "        old_value = int(row.old_value) * 1000\n",
    "        assert new_value > old_value\n",
    "        assert new_value > prev_visit_timestamp, f\"{new_value} {prev_visit_timestamp}\"\n",
    "        if old_value != prev_visit_timestamp:\n",
    "            if old_value < prev_visit_timestamp:  # TODO what does this case mean? updatedAt < createdAt, but why?\n",
    "                continue\n",
    "            assert old_value > prev_visit_timestamp, f\"{old_value} {prev_visit_timestamp}\"\n",
    "            n_potential_missed_visits += 1\n",
    "            visit_timestamps.append(old_value)\n",
    "        visit_timestamps.append(new_value)\n",
    "        prev_visit_timestamp = new_value\n",
    "    n_visits = len(visit_timestamps)\n",
    "    ds.append({\n",
    "        'user_id': usp[0],\n",
    "        'site_id': usp[1],\n",
    "        'n_visits': n_visits,\n",
    "        'n_potential_missed_visits': n_potential_missed_visits,\n",
    "        'visit_timestamps': visit_timestamps,\n",
    "    })\n",
    "visit_df = pd.DataFrame(ds)\n",
    "len(visit_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visit_df.sort_values(by='n_visits', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visit_df.groupby('user_id').n_visits.sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visit_df.groupby('user_id').n_visits.sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many \"return visits\" are there?\n",
    "def count_return_visits(visit_timestamps):\n",
    "    if len(visit_timestamps) <= 1:\n",
    "        return 0\n",
    "    return_visit_threshold = 1000 * 60 * 60 * 6  # 6 hours\n",
    "    \n",
    "    n_return_visits = 0\n",
    "    first_timestamp = visit_timestamps[0]\n",
    "    for timestamp in visit_timestamps[1:]:\n",
    "        if timestamp > first_timestamp + return_visit_threshold:\n",
    "            n_return_visits += 1\n",
    "    return n_return_visits\n",
    "visit_df['n_return_visits'] = visit_df.visit_timestamps.map(count_return_visits)\n",
    "visit_df.n_return_visits.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visit_df.n_return_visits.sum(), np.sum(visit_df.n_return_visits > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(visit_df.groupby('user_id').n_return_visits.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO create a visit_df with all of the participants visits, and then compute pre/post comparison?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Follow actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# follow actions\n",
    "sp_df[sp_df.key == 'n']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notification_updates = site_profile_diff_df[(site_profile_diff_df.key == 'n')&(site_profile_diff_df.user_id.isin(participant_user_ids))].copy()\n",
    "notification_updates['usp'] = [(row.user_id, row.site_id) for row in notification_updates.itertuples()]\n",
    "notification_updates = notification_updates[notification_updates.usp.isin(recced_usps)].copy()\n",
    "len(notification_updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "follow_actions = []\n",
    "for row in notification_updates.itertuples():\n",
    "    #print(row.old_value)\n",
    "    assert pd.isna(row.old_value)\n",
    "    print(row.new_value)\n",
    "    follow_actions.append((row.user_id, row.site_id))\n",
    "len(follow_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# currently, this is a reasonable estimate of number of follow actions\n",
    "sp_df[sp_df.n.map(lambda n: len(n) > 0)].groupby(['user_id', 'site_id']).updated_at.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "follow_df = sp_df[sp_df.n.map(lambda n: len(n) > 0)].groupby(['user_id', 'site_id']).updated_at.nunique().reset_index()\n",
    "follow_df['usp'] = [(row.user_id, row.site_id) for row in follow_df.itertuples()]\n",
    "assert len(set(follow_actions) - set(follow_df.usp)) == 0, \"Additional follow actions not captured in the site_profile collection\"\n",
    "#len(follow_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(follow_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "follow_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute counts for follows\n",
    "c = len(follow_df)\n",
    "c, c / total_recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = len(set(follow_df.user_id))\n",
    "c, c / total_participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = len(set(follow_df.site_id))\n",
    "c, c / total_recced_sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 1\n",
    "c / total_recs, c / total_participants, c / total_recced_sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_df.n.map(lambda n: len(n)).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(sp_df.key, sp_df.n.map(lambda n: len(n)), dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del site_profile_diff_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "central_time = pytz.timezone('US/Central')\n",
    "banner_live_time = datetime.fromisoformat('2021-08-02 12:11:00').astimezone(central_time)\n",
    "banner_end_time = datetime.fromisoformat('2021-08-23 11:59:59').astimezone(central_time)\n",
    "print(f\"Banner live: {banner_live_time}\")\n",
    "print(f\"Banner end: {banner_end_time}\")\n",
    "\n",
    "first_sse_timestamp = batch_df.sse_sent_timestamp.min()\n",
    "first_sse_time = datetime.utcfromtimestamp(first_sse_timestamp / 1000)\n",
    "print(f\"First SSE sent: {first_sse_time}\")\n",
    "\n",
    "last_sse_timestamp = batch_df.sse_sent_timestamp.max()\n",
    "last_sse_time = datetime.utcfromtimestamp(last_sse_timestamp / 1000)\n",
    "print(f\"Last SSE sent: {last_sse_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactions and journals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# journals used to be loaded here, now loaded above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read interactions dataframe\n",
    "s = datetime.now()\n",
    "model_data_dir = '/home/lana/shared/caringbridge/data/projects/recsys-peer-match/model_data'\n",
    "ints_df = pd.read_feather(os.path.join(model_data_dir, 'ints_df.feather'))\n",
    "print(f\"Read {len(ints_df)} rows ({len(set(ints_df.user_id))} unique users) in {datetime.now() - s}.\")\n",
    "ints_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_user_ids = set(participant_df[participant_df.n_total_recs > 0].user_id)\n",
    "len(participant_user_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pints_df = ints_df[ints_df.user_id.isin(participant_user_ids)].copy()\n",
    "pints_df['usp'] = [(row.user_id, row.site_id) for row in pints_df.itertuples()]\n",
    "len(pints_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_rec_ints_df = pints_df[pints_df.usp.isin(recced_usps)]\n",
    "len(p_rec_ints_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute counts for initiations\n",
    "rec_c = len(set(p_rec_ints_df.usp))\n",
    "user_c = len(set(p_rec_ints_df.user_id))\n",
    "site_c = len(set(p_rec_ints_df.site_id))\n",
    "print(f\"{rec_c} & {rec_c / total_recs:.1%} & {user_c} & {user_c / total_participants:.1%} & {site_c} & {site_c / total_recced_sites:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute counts for interactions\n",
    "rec_c = len(p_rec_ints_df)\n",
    "user_c = len(set(p_rec_ints_df.user_id))\n",
    "site_c = len(set(p_rec_ints_df.site_id))\n",
    "print(f\"{rec_c} & n/a & {user_c} & {user_c / total_participants:.1%} & {site_c} & {site_c / total_recced_sites:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute counts for text interactions\n",
    "sdf = p_rec_ints_df[~p_rec_ints_df.interaction_type.str.startswith('amp')]\n",
    "rec_c = len(sdf)\n",
    "user_c = len(set(sdf.user_id))\n",
    "site_c = len(set(sdf.site_id))\n",
    "print(f\"{rec_c} & n/a & {user_c} & {user_c / total_participants:.1%} & {site_c} & {site_c / total_recced_sites:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_int_counts = p_rec_ints_df.groupby('site_id').user_id.count().rename(\"int_counts\")\n",
    "print(f\"Sites received Median={site_int_counts.median()} and Mean={site_int_counts.mean():.2f} (SD={site_int_counts.std():.2f}) interactions\")\n",
    "site_int_counts.sort_values(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_rec_ints_df.groupby(['user_id', 'site_id']).interaction_oid.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_rec_ints_ids = p_rec_ints_df.user_id.unique()\n",
    "p_rec_ints_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# also need to load the participant and non-participant site profile data\n",
    "\n",
    "nonparticipant_data_dir = os.path.join(cbcore.data.paths.projects_data_dir, 'recsys-peer-match', 'nonparticipant')\n",
    "with open(os.path.join(nonparticipant_data_dir, 'site_profile.pkl'), 'rb') as infile:\n",
    "    nonp_site_profiles = pickle.load(infile)\n",
    "print(len(nonp_site_profiles))\n",
    "\n",
    "with open(os.path.join(participant_data_dir, 'site_profile.pkl'), 'rb') as infile:\n",
    "    p_site_profiles = pickle.load(infile)\n",
    "print(len(p_site_profiles))\n",
    "\n",
    "site_profiles = nonp_site_profiles + p_site_profiles\n",
    "\n",
    "# create a dataframe from the site profile entires\n",
    "ds = []\n",
    "for sp in site_profiles:\n",
    "    user_id = int(sp['userId'])\n",
    "    site_id = int(sp['siteId']) if 'siteId' in sp else -1\n",
    "    # not capturing: nl\n",
    "    d = {\n",
    "        'user_id': user_id,\n",
    "        'site_id': site_id,\n",
    "        'is_creator': sp['isCreator'] if 'isCreator' in sp else None,\n",
    "        'is_primary': sp['isPrimary'] if 'isPrimary' in sp else None,\n",
    "        'role': sp['role'],\n",
    "        'is_profile_deleted': sp['isProfileDeleted'] if 'isProfileDeleted' in sp else None,\n",
    "        'is_site_deleted': sp['isSiteDeleted'] if 'isSiteDeleted' in sp else None,\n",
    "        'is_stub': sp['isStub'] if 'isStub' in sp else None,\n",
    "        'created_at': sp['createdAt'].timestamp() * 1000 if 'createdAt' in sp else 0,\n",
    "        'updated_at': sp['updatedAt'].timestamp() * 1000 if 'updatedAt' in sp else 0,\n",
    "        'n': dict(sp['n']) if 'n' in sp and sp['n'] is not None else {},\n",
    "    }\n",
    "    ds.append(d)\n",
    "\n",
    "ssite_profile_df = pd.DataFrame(ds)\n",
    "ssite_profile_df['is_participant'] = ssite_profile_df.user_id.isin(participant_user_ids)\n",
    "ssite_profile_df['usp'] = [(row.user_id, row.site_id) for row in ssite_profile_df.itertuples()]\n",
    "ssite_profile_df.sample(n=3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssite_profile_df['is_self_author'] = (ssite_profile_df.is_creator == 1)|(ssite_profile_df.is_primary == 1)|(ssite_profile_df.role == 'Organizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the journal metadata\n",
    "s = datetime.now()\n",
    "journal_metadata_dir = \"/home/lana/shared/caringbridge/data/derived/journal_metadata\"\n",
    "journal_metadata_filepath = os.path.join(journal_metadata_dir, \"journal_metadata.feather\")\n",
    "journal_df = pd.read_feather(journal_metadata_filepath)\n",
    "print(datetime.now() - s)\n",
    "len(journal_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "journal_df['usp'] = [(user_id, site_id) for user_id, site_id in zip(journal_df.user_id, journal_df.site_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on journal authors and first visits, identify the set of author USPs (where the user_id is an author of site_id)\n",
    "author_usp_set = set(ssite_profile_df[ssite_profile_df.is_self_author].usp) | set(journal_df.usp)\n",
    "len(author_usp_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_ints_df = pints_df[~pints_df.usp.isin(recced_usps)]\n",
    "len(p_ints_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_ints_df = p_ints_df[~p_ints_df.usp.isin(author_usp_set)]\n",
    "len(p_ints_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_ints_df = p_ints_df[p_ints_df.created_at > first_sse_timestamp]\n",
    "#p_ints_df = p_ints_df[p_ints_df.created_at < last_sse_timestamp]\n",
    "len(p_ints_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p_ints_df.groupby(['user_id', 'site_id']).interaction_oid.count()\n",
    "# Participants who interacted in study with recs, interactions with non-recs\n",
    "p_ints_df[p_ints_df.user_id.isin(p_rec_ints_ids)].groupby(['user_id', 'site_id']).interaction_oid.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Participants who interacted in study with recommendations: Recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute counts for initiations\n",
    "rec_c = len(set(p_rec_ints_df.usp))\n",
    "user_c = len(set(p_rec_ints_df.user_id))\n",
    "site_c = len(set(p_rec_ints_df.site_id))\n",
    "print(f\"{rec_c} & {rec_c / total_recs:.1%} & {user_c} & {user_c / total_participants:.1%} & {site_c} & {site_c / total_recced_sites:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute counts for text interactions\n",
    "sdf = p_rec_ints_df[~p_rec_ints_df.interaction_type.str.startswith('amp')]\n",
    "rec_c = len(sdf)\n",
    "user_c = len(set(sdf.user_id))\n",
    "print(set(sdf.user_id))\n",
    "site_c = len(set(sdf.site_id))\n",
    "print(f\"{rec_c} & n/a & {user_c} & {user_c / total_participants:.1%} & {site_c} & {site_c / total_recced_sites:.1%}\")\n",
    "\n",
    "n_rec_text_ints = rec_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute counts for interactions\n",
    "rec_c = len(p_rec_ints_df)\n",
    "user_c = len(set(p_rec_ints_df.user_id))\n",
    "print(set(p_rec_ints_df.user_id))\n",
    "site_c = len(set(p_rec_ints_df.site_id))\n",
    "print(f\"{rec_c} & n/a & {user_c} & {user_c / total_participants:.1%} & {site_c} & {site_c / total_recced_sites:.1%}\")\n",
    "\n",
    "n_rec_ints = rec_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{(n_rec_ints-n_rec_text_ints)/n_rec_ints:.1%} of interactions were reactions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Participants who interacted in study with recommendations: Non-Recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute counts for initiations\n",
    "sdf = p_ints_df[p_ints_df.user_id.isin(p_rec_ints_ids)]\n",
    "rec_c = len(set(sdf.usp))\n",
    "user_c = len(set(sdf.user_id))\n",
    "site_c = len(set(sdf.site_id))\n",
    "print(f\"{rec_c} & {rec_c / total_recs:.1%} & {user_c} & {user_c / total_participants:.1%} & {site_c} & {site_c / total_recced_sites:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute counts for text interactions\n",
    "sdf = p_ints_df[(p_ints_df.user_id.isin(p_rec_ints_ids))&(~p_ints_df.interaction_type.str.startswith('amp'))]\n",
    "rec_c = len(sdf)\n",
    "user_c = len(set(sdf.user_id))\n",
    "print(set(sdf.user_id))\n",
    "site_c = len(set(sdf.site_id))\n",
    "print(f\"{rec_c} & n/a & {user_c} & {user_c / total_participants:.1%} & {site_c} & {site_c / total_recced_sites:.1%}\")\n",
    "\n",
    "n_rec_text_ints = rec_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute counts for interactions\n",
    "sdf = p_ints_df[p_ints_df.user_id.isin(p_rec_ints_ids)]\n",
    "rec_c = len(sdf)\n",
    "user_c = len(set(sdf.user_id))\n",
    "print(set(sdf.user_id))\n",
    "site_c = len(set(sdf.site_id))\n",
    "print(f\"{rec_c} & n/a & {user_c} & {user_c / total_participants:.1%} & {site_c} & {site_c / total_recced_sites:.1%}\")\n",
    "\n",
    "n_rec_ints = rec_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{(n_rec_ints-n_rec_text_ints)/n_rec_ints:.1%} of interactions were reactions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All participants: Non-Recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute counts for initiations\n",
    "sdf = p_ints_df\n",
    "rec_c = len(set(sdf.usp))\n",
    "user_c = len(set(sdf.user_id))\n",
    "site_c = len(set(sdf.site_id))\n",
    "print(f\"{rec_c} & {rec_c / total_recs:.1%} & {user_c} & {user_c / total_participants:.1%} & {site_c} & {site_c / total_recced_sites:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute counts for text interactions\n",
    "sdf = p_ints_df[(~p_ints_df.interaction_type.str.startswith('amp'))]\n",
    "rec_c = len(sdf)\n",
    "user_c = len(set(sdf.user_id))\n",
    "print(set(sdf.user_id))\n",
    "site_c = len(set(sdf.site_id))\n",
    "print(f\"{rec_c} & n/a & {user_c} & {user_c / total_participants:.1%} & {site_c} & {site_c / total_recced_sites:.1%}\")\n",
    "\n",
    "n_rec_text_ints = rec_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute counts for interactions\n",
    "sdf = p_ints_df\n",
    "rec_c = len(sdf)\n",
    "user_c = len(set(sdf.user_id))\n",
    "site_c = len(set(sdf.site_id))\n",
    "print(f\"{rec_c} & n/a & {user_c} & {user_c / total_participants:.1%} & {site_c} & {site_c / total_recced_sites:.1%}\")\n",
    "\n",
    "n_rec_ints = rec_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{(n_rec_ints-n_rec_text_ints)/n_rec_ints:.1%} of interactions were reactions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_ints_df = ints_df.copy()\n",
    "u_ints_df['usp'] = [(row.user_id, row.site_id) for row in u_ints_df.itertuples()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_ints_df = u_ints_df[~u_ints_df.usp.isin(recced_usps)]\n",
    "len(u_ints_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_ints_df = u_ints_df[~u_ints_df.usp.isin(author_usp_set)]\n",
    "len(u_ints_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_ints_df = u_ints_df[u_ints_df.created_at > first_sse_timestamp]\n",
    "#p_ints_df = p_ints_df[p_ints_df.created_at < last_sse_timestamp]\n",
    "len(u_ints_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute counts for initiations\n",
    "sdf = u_ints_df\n",
    "rec_c = len(set(sdf.usp))\n",
    "user_c = len(set(sdf.user_id))\n",
    "site_c = len(set(sdf.site_id))\n",
    "print(f\"{rec_c} & {rec_c / total_recs:.1%} & {user_c} & {user_c / total_participants:.1%} & {site_c} & {site_c / total_recced_sites:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute counts for text interactions\n",
    "sdf = u_ints_df[(~u_ints_df.interaction_type.str.startswith('amp'))]\n",
    "rec_c = len(sdf)\n",
    "user_c = len(set(sdf.user_id))\n",
    "site_c = len(set(sdf.site_id))\n",
    "print(f\"{rec_c} & n/a & {user_c} & {user_c / total_participants:.1%} & {site_c} & {site_c / total_recced_sites:.1%}\")\n",
    "\n",
    "n_rec_text_ints = rec_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute counts for interactions\n",
    "sdf = u_ints_df\n",
    "rec_c = len(sdf)\n",
    "user_c = len(set(sdf.user_id))\n",
    "site_c = len(set(sdf.site_id))\n",
    "print(f\"{rec_c} & n/a & {user_c} & {user_c / total_participants:.1%} & {site_c} & {site_c / total_recced_sites:.1%}\")\n",
    "\n",
    "n_rec_ints = rec_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{(n_rec_ints-n_rec_text_ints)/n_rec_ints:.1%} of interactions were reactions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_ints_df = ints_df[ints_df.user_id.isin(participant_user_ids)]\n",
    "participant_ints_df = participant_ints_df.set_index(['user_id', 'site_id']).sort_index()\n",
    "print(len(participant_ints_df))\n",
    "participant_ints_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_int_count = participant_ints_df.groupby('user_id').created_at.count().rename('total_int_count').sort_values(ascending=False)\n",
    "plt.plot(range(len(total_int_count)), total_int_count)\n",
    "plt.ylabel(\"Total number of interactions\")\n",
    "plt.xlabel(\"Participant rank\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_ints_df = participant_ints_df.loc[participant_ints_df.index.intersection(recced_usps)].reset_index()\n",
    "len(rec_ints_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_ints_df.groupby('user_id').site_id.count().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(rec_ints_df.user_id, rec_ints_df.interaction_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_ints_df.interaction_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days30 = 1000 * 60 * 60 * 24 * 30\n",
    "first_sse_timestamp_map = participant_df.set_index('user_id').first_sse_timestamp.to_dict()\n",
    "\n",
    "ds = []\n",
    "for user_id, group in participant_ints_df.groupby('user_id'):\n",
    "    if user_id not in first_sse_timestamp_map:\n",
    "        print(\"PANIC\")\n",
    "        continue\n",
    "    first_sse_timestamp = first_sse_timestamp_map[user_id]\n",
    "    if first_sse_timestamp == -1:\n",
    "        continue\n",
    "    n_total = len(group)\n",
    "    n_post = np.sum(group.created_at >= first_sse_timestamp)\n",
    "    n_pre = n_total - n_post\n",
    "    \n",
    "    \n",
    "    n_post_30 = np.sum((group.created_at >= first_sse_timestamp)&(group.created_at <= first_sse_timestamp + days30))\n",
    "    n_pre_30 = np.sum((group.created_at <= first_sse_timestamp)&(group.created_at >= first_sse_timestamp - days30))\n",
    "    d = {\n",
    "        'user_id': user_id,\n",
    "        'n_pre_30': n_pre_30, \n",
    "        'n_post_30': n_post_30,\n",
    "    }\n",
    "    ds.append(d)\n",
    "    \n",
    "int_count_df = pd.DataFrame(ds)\n",
    "len(int_count_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = int_count_df.n_post_30 - int_count_df.n_pre_30\n",
    "print(f\"{np.sum(xs > 0) / len(xs):.2%} greater, {np.sum(xs == 0) / len(xs):.2%} equal, {np.sum(xs < 0) / len(xs):.2%} less interactions, when comparing 30 days post-study-start and 30 days pre-study-start\")\n",
    "plt.hist(xs, bins=20)\n",
    "plt.title(\"Difference in number of interactions post vs pre study\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO compare the pre and post interactions between the participants and the \"pseudo-control\" non-participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
