{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Journal Comparison\n",
    "===\n",
    "\n",
    "Investigating potential date issues, comparing 2021 and 2019 data dumps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "import sqlite3\n",
    "from nltk import word_tokenize\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import pytz\n",
    "from pprint import pprint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as md\n",
    "import matplotlib\n",
    "import pylab as pl\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "import lifelines\n",
    "from lifelines import KaplanMeierFitter\n",
    "from lifelines import CoxPHFitter\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams['figure.dpi'] = 120\n",
    "matplotlib.rcParams['font.family'] = \"serif\"\n",
    "#matplotlib.rcParams['figure.figsize'] = [8, 8]\n",
    "#matplotlib.rcParams['font.size'] = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "caringbridge_core_path = \"/home/lana/levon003/repos/caringbridge_core\"\n",
    "sys.path.append(caringbridge_core_path)\n",
    "import cbcore.data.paths as paths\n",
    "import cbcore.data.dates as dates\n",
    "import cbcore.data.utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "git_root_dir = !git rev-parse --show-toplevel\n",
    "git_root_dir = Path(git_root_dir[0].strip())\n",
    "figures_dir = os.path.join(git_root_dir, 'figures')\n",
    "os.makedirs(figures_dir, exist_ok=True)\n",
    "git_root_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the journal dataframe\n",
    "s = datetime.now()\n",
    "journal_metadata_dir = \"/home/lana/shared/caringbridge/data/derived/journal_metadata\"\n",
    "journal_metadata_filepath = os.path.join(journal_metadata_dir, \"journal_metadata.feather\")\n",
    "jdf_new = pd.read_feather(journal_metadata_filepath)\n",
    "print(f\"Read {len(jdf_new)} journal_df rows in {datetime.now() - s}.\")\n",
    "jdf_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the journal dataframe\n",
    "s = datetime.now()\n",
    "journal_metadata_dir = \"/home/lana/shared/caringbridge/data/derived/journal_metadata\"\n",
    "journal_metadata_filepath = os.path.join(journal_metadata_dir, \"journal_metadata.df\")\n",
    "jdf_old = pd.read_feather(journal_metadata_filepath)\n",
    "print(f\"Read {len(jdf_old)} journal_df rows in {datetime.now() - s}.\")\n",
    "jdf_old.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# almost all oids in the old are also present in the new\n",
    "not_in_new = set(jdf_old.journal_oid) - set(jdf_new.journal_oid)\n",
    "n_not_in_new = len(not_in_new)\n",
    "n_not_in_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13 deleted sites accounts for all of the missing journals...\n",
    "jdf_old[jdf_old.journal_oid.isin(not_in_new)].site_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jdf = pd.merge(jdf_old[['journal_oid', 'created_at', 'updated_at', 'published_at']], jdf_new[['journal_oid', 'created_at', 'updated_at', 'published_at']], \n",
    "         how='inner', left_on='journal_oid', right_on='journal_oid', suffixes=('_old', '_new'))\n",
    "len(jdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(jdf.isna().value_counts().rename(\"NA counts\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# follow the convention of the old dataframe and assign zero to na values\n",
    "jdf.loc[jdf.published_at_new.isna(), 'published_at_new'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_cols = ['created_at', 'updated_at', 'published_at']\n",
    "for date_col in date_cols:\n",
    "    diffs = jdf[date_col+'_old'] - jdf[date_col+'_new']\n",
    "    print(f\"{date_col:>15} {np.sum(diffs == 0) / len(diffs) * 100:.2f}% the same; {np.sum(diffs != 0):,} different\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_col = 'created_at'\n",
    "diffs = jdf[date_col+'_old'] - jdf[date_col+'_new']\n",
    "different = diffs[diffs != 0]\n",
    "different.value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 332 different dates that are \"weird\"\n",
    "np.sum(different != 3600000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3600000 milliseconds is exactly one hour\n",
    "# to me, this implies the date function we were using for the old data was wrong for some period of time around DST or leap years or something\n",
    "3600000 / 1000 / 60 / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_col = 'published_at'\n",
    "diffs = jdf[date_col+'_old'] - jdf[date_col+'_new']\n",
    "different = diffs[diffs != 0]\n",
    "different.value_counts().head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no difference for coluns where published_at is available in the new data\n",
    "np.sum(diffs[jdf[date_col+'_new'] == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nearly all of the difference is due to published_at date not being available in the old data but being available in the new data\n",
    "# which, honestly, is kind of weird and surprising\n",
    "np.sum(diffs[jdf[date_col+'_old'] == 0] != 0) / len(different)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Published At vs Created At\n",
    "\n",
    "What is the lag time between these figures?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jdf = jdf_new\n",
    "jdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the site data\n",
    "s = datetime.now()\n",
    "site_metadata_dir = \"/home/lana/shared/caringbridge/data/derived/site_metadata\"\n",
    "site_metadata_filepath = os.path.join(site_metadata_dir, \"site_metadata.feather\")\n",
    "site_df = pd.read_feather(site_metadata_filepath)\n",
    "print(f\"Read {len(site_df)} site_df rows in {datetime.now() - s}.\")\n",
    "site_df['isDeactivated'] = (site_df.isDeleted == '1')|(site_df.isSpam == 1)\n",
    "site_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_site_ids = set(site_df[~site_df.isDeactivated].site_id)\n",
    "len(valid_site_ids), len(site_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(jdf))\n",
    "jdf = jdf[jdf.site_id.isin(valid_site_ids)]\n",
    "print(len(jdf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jdf.lastEdit.isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "\n",
    "#start_time = datetime.utcfromtimestamp(np.min(jdf.created_at / 1000)).replace(tzinfo=pytz.UTC)\n",
    "start_time = datetime.strptime('2005-01-01', '%Y-%m-%d').replace(tzinfo=pytz.UTC)\n",
    "curr_time = start_time\n",
    "#end_time = datetime.utcfromtimestamp(np.max(jdf.created_at / 1000)).replace(tzinfo=pytz.UTC)\n",
    "end_time = datetime.strptime('2021-07-15', '%Y-%m-%d').replace(tzinfo=pytz.UTC)\n",
    "bins = []\n",
    "while curr_time < end_time:\n",
    "    bins.append(curr_time.timestamp() * 1000)\n",
    "    curr_time += relativedelta(months=1)\n",
    "print(f'{len(bins)} bins from {start_time} to {end_time}')\n",
    "\n",
    "counts, bin_edges = np.histogram(jdf.created_at, bins=bins)\n",
    "ax.plot(bin_edges[:-1], counts, label=f\"Created (M={np.mean(counts):,.2f})\")\n",
    "totals = counts\n",
    "\n",
    "counts, bin_edges = np.histogram(jdf.published_at, bins=bins)\n",
    "ax.plot(bin_edges[:-1], counts, label=f\"Published (M={np.mean(counts):,.2f})\")\n",
    "\n",
    "\n",
    "bin_width_s = bin_edges[1] - bin_edges[0]\n",
    "ax.set_ylabel(f\"New sites per {bin_width_s / 1000 / 60 / 60 / 24:.0f} days\")\n",
    "ax.set_xlabel(\"Date of site creation\")\n",
    "ax.set_title(f\"Creation date for {np.sum(totals):,} journals ({np.sum(totals) / len(jdf) * 100:.2f}% of total)\")\n",
    "\n",
    "#ax.xaxis.set_major_formatter(matplotlib.ticker.FuncFormatter(lambda x, y: datetime.utcfromtimestamp(x / 1000).replace(tzinfo=pytz.timezone('US/Central')).strftime(\"%Y\\n%m/%d\").replace(\" 0\", \" \")))\n",
    "x_dates = [start_time + relativedelta(years=i) for i in range(18)]\n",
    "ax.set_xticks([d.timestamp() * 1000 for d in x_dates])\n",
    "ax.set_xticklabels([f\"Jan\\n\" + d.strftime('%Y')[2:] for i, d in enumerate(x_dates)])\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "ax = axes[0]\n",
    "#start_time = datetime.utcfromtimestamp(np.min(jdf.created_at / 1000)).replace(tzinfo=pytz.UTC)\n",
    "start_time = datetime.strptime('2014-01-01', '%Y-%m-%d').replace(tzinfo=pytz.UTC)\n",
    "curr_time = start_time\n",
    "#end_time = datetime.utcfromtimestamp(np.max(jdf.created_at / 1000)).replace(tzinfo=pytz.UTC)\n",
    "end_time = datetime.strptime('2021-07-15', '%Y-%m-%d').replace(tzinfo=pytz.UTC)\n",
    "bins = []\n",
    "while curr_time < end_time:\n",
    "    bins.append(curr_time.timestamp() * 1000)\n",
    "    curr_time += relativedelta(months=1)\n",
    "print(f'{len(bins)} bins from {start_time} to {end_time}')\n",
    "sdf = jdf[(jdf.created_at>=start_time.timestamp() * 1000)&(jdf.created_at<=end_time.timestamp() * 1000)]\n",
    "print(np.sum(sdf.published_at.isna()), len(sdf))\n",
    "\n",
    "counts, bin_edges = np.histogram(sdf.created_at, bins=bins)\n",
    "ax.plot(bin_edges[:-1], counts, label=f\"Created (M={np.mean(counts):,.2f})\")\n",
    "totals = counts\n",
    "\n",
    "counts, bin_edges = np.histogram(sdf.published_at, bins=bins)\n",
    "ax.plot(bin_edges[:-1], counts, label=f\"Published (M={np.mean(counts):,.2f})\")\n",
    "\n",
    "\n",
    "bin_width_s = bin_edges[1] - bin_edges[0]\n",
    "ax.set_ylabel(f\"New sites per {bin_width_s / 1000 / 60 / 60 / 24:.0f} days\")\n",
    "ax.set_xlabel(\"Date of site creation\")\n",
    "ax.set_title(f\"Creation date for {np.sum(totals):,} journals ({np.sum(totals) / len(sdf) * 100:.2f}% of total)\")\n",
    "\n",
    "#ax.xaxis.set_major_formatter(matplotlib.ticker.FuncFormatter(lambda x, y: datetime.utcfromtimestamp(x / 1000).replace(tzinfo=pytz.timezone('US/Central')).strftime(\"%Y\\n%m/%d\").replace(\" 0\", \" \")))\n",
    "x_dates = [start_time + relativedelta(years=i) for i in range(9)]\n",
    "ax.set_xticks([d.timestamp() * 1000 for d in x_dates])\n",
    "ax.set_xticklabels([f\"Jan\\n\" + d.strftime('%Y')[2:] for i, d in enumerate(x_dates)])\n",
    "ax.legend()\n",
    "\n",
    "ax = axes[1]\n",
    "not_published = sdf.published_at.isna()\n",
    "print(f\"{np.sum(not_published) / len(sdf) * 100:.2f}% ({np.sum(not_published)}) of Journals lack a published at date.\")\n",
    "\n",
    "counts, bin_edges = np.histogram(sdf[not_published].created_at, bins=bins)\n",
    "ax.plot(bin_edges[:-1], counts, label=f\"Published (M={np.mean(counts):,.2f})\")\n",
    "ax.set_title('Unpublished Journal updates over time')\n",
    "ax.set_xticks([d.timestamp() * 1000 for d in x_dates])\n",
    "ax.set_xticklabels([f\"Jan\\n\" + d.strftime('%Y')[2:] for i, d in enumerate(x_dates)])\n",
    "\n",
    "ax = axes[2]\n",
    "diff = sdf[~not_published].published_at - sdf[~not_published].created_at\n",
    "diff = diff / 1000 / 60 / 60  # convert to hours\n",
    "plt.hist(diff, log=True, bins=np.linspace(0, 24 * 7))\n",
    "print(f\"{np.sum(diff >= 24 * 7) /len(diff) * 100:.2f}% of Journals are published more than a week after creation\")\n",
    "print(f\"Median Journal is published {np.median(diff):.2f} hours after creation\")\n",
    "print(f\"{np.sum(diff <= 1) / len(diff) * 100:.2f}% of Journals are published within an hour of creation\")\n",
    "print(f\"{np.sum(diff == 0) / len(diff) * 100:.2f}% of Journals are published at the same time they are created\")\n",
    "print(f\"Journals elapsed time quantiles: [{np.quantile(diff, 0.4):.2f}, {np.quantile(diff, 0.5):.2f}, {np.quantile(diff, 0.90):.2f}, {np.quantile(diff, 0.99):.2f}] hours\")\n",
    "\n",
    "xticks = [24 * i for i in range(8)]\n",
    "ax.set_xticks(xticks)\n",
    "ax.set_xticklabels([f\"{x / 24:.0f}\" for x in xticks])\n",
    "ax.set_xlabel(\"Elapsed time (days)\")\n",
    "\n",
    "#counts, bin_edges = np.histogram(sdf[not_published].created_at, bins=bins)\n",
    "#ax.plot(bin_edges[:-1], counts, label=f\"Published (M={np.mean(counts):,.2f})\")\n",
    "\n",
    "ax.set_title('Time between publication and creation')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_published = sdf.published_at.isna()\n",
    "sdf[(not_published)&(sdf.created_at >= datetime.strptime('2020-01-01', '%Y-%m-%d').replace(tzinfo=pytz.UTC).timestamp() * 1000)].sort_values(by='created_at', ascending=True).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_df[site_df.site_id == 0][['site_id', 'name', 'numJournals', 'title', 'privacy']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf[sdf.journal_oid == '5e0bf3bd431f31f15f949e15']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf[sdf.site_id == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(sdf[sdf.site_id == 0].iloc[4].published_at - sdf[sdf.site_id == 0].iloc[3].published_at) / 1000 / 60 / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
