{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Site Survival Time\n",
    "===\n",
    "\n",
    "How many Journal updates and how long does the average site last on CaringBridge?\n",
    "\n",
    "Related Qs: how long does an author stay active on CaringBridge?\n",
    "\n",
    "Key stats:\n",
    " - What % of sites never have a Journal update?\n",
    " - What % of sites have 1 update?\n",
    " - What % of sites have 2+ updates?\n",
    " \n",
    "Analysis conducted responsive to a request made by Brigid B via Tia N on June 23rd, 2021.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "import sqlite3\n",
    "from nltk import word_tokenize\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import pytz\n",
    "from pprint import pprint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as md\n",
    "import matplotlib\n",
    "import pylab as pl\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "import lifelines\n",
    "from lifelines import KaplanMeierFitter\n",
    "from lifelines import CoxPHFitter\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams['figure.dpi'] = 120\n",
    "matplotlib.rcParams['font.family'] = \"serif\"\n",
    "#matplotlib.rcParams['figure.figsize'] = [8, 8]\n",
    "#matplotlib.rcParams['font.size'] = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "caringbridge_core_path = \"/home/lana/levon003/repos/caringbridge_core\"\n",
    "sys.path.append(caringbridge_core_path)\n",
    "import cbcore.data.paths as paths\n",
    "import cbcore.data.dates as dates\n",
    "import cbcore.data.utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "git_root_dir = !git rev-parse --show-toplevel\n",
    "git_root_dir = Path(git_root_dir[0].strip())\n",
    "figures_dir = os.path.join(git_root_dir, 'figures')\n",
    "os.makedirs(figures_dir, exist_ok=True)\n",
    "git_root_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the journal dataframe\n",
    "s = datetime.now()\n",
    "journal_metadata_dir = \"/home/lana/shared/caringbridge/data/derived/journal_metadata\"\n",
    "journal_metadata_filepath = os.path.join(journal_metadata_dir, \"journal_metadata.feather\")\n",
    "journal_df = pd.read_feather(journal_metadata_filepath)\n",
    "print(f\"Read {len(journal_df)} journal_df rows in {datetime.now() - s}.\")\n",
    "journal_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the site data\n",
    "s = datetime.now()\n",
    "site_metadata_dir = \"/home/lana/shared/caringbridge/data/derived/site_metadata\"\n",
    "site_metadata_filepath = os.path.join(site_metadata_dir, \"site_metadata.feather\")\n",
    "site_df = pd.read_feather(site_metadata_filepath)\n",
    "print(f\"Read {len(site_df)} site_df rows in {datetime.now() - s}.\")\n",
    "site_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_journal_timestamps = journal_df.groupby('site_id').created_at.min().rename('first_journal_timestamp')\n",
    "site_df = site_df.merge(first_journal_timestamps, how='left', left_on='site_id', right_index=True)\n",
    "\n",
    "n_journals = journal_df.groupby('site_id').journal_oid.count().rename('n_journals')\n",
    "site_df = site_df.merge(n_journals, how='left', left_on='site_id', right_index=True)\n",
    "\n",
    "site_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing this was slow, so this was a reasonable fall-back approach\n",
    "site_id_second_journal_timestamp_map = {}\n",
    "site_id_last_journal_timestamp_map = {}\n",
    "\n",
    "curr_site_id = None\n",
    "second_row_processed = False\n",
    "for row in tqdm(journal_df.sort_values(by=['site_id', 'created_at']).itertuples(), total=len(journal_df)):\n",
    "    site_id = row.site_id\n",
    "    if site_id != curr_site_id:\n",
    "        if curr_site_id is not None:\n",
    "            site_id_last_journal_timestamp_map[curr_site_id] = prev_journal_timestamp\n",
    "        curr_site_id = site_id\n",
    "        second_row_processed = False\n",
    "    else:\n",
    "        if not second_row_processed:\n",
    "            second_row_processed = True\n",
    "            second_journal_timestamp = row.created_at  # this is the second journal entry for this site\n",
    "            site_id_second_journal_timestamp_map[curr_site_id] = second_journal_timestamp\n",
    "    prev_journal_timestamp = row.created_at\n",
    "# after the final row, set the last_journal_timestamp for the final site\n",
    "site_id_last_journal_timestamp_map[curr_site_id] = prev_journal_timestamp\n",
    "\n",
    "site_df['second_journal_timestamp'] = site_df.site_id.map(lambda site_id: np.nan if site_id not in site_id_second_journal_timestamp_map else site_id_second_journal_timestamp_map[site_id])\n",
    "site_df['last_journal_timestamp'] = site_df.site_id.map(lambda site_id: np.nan if site_id not in site_id_last_journal_timestamp_map else site_id_last_journal_timestamp_map[site_id])\n",
    "site_df.second_journal_timestamp.notna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validity check\n",
    "assert np.all(site_df[site_df.n_journals==1].first_journal_timestamp == site_df[site_df.n_journals==1].last_journal_timestamp)\n",
    "assert np.all(site_df[site_df.n_journals==2].second_journal_timestamp == site_df[site_df.n_journals==2].last_journal_timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_df.first_journal_timestamp.notna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_df.last_journal_timestamp.notna().value_counts()  # should have identical stats to the first journal timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_df.n_journals.notna().value_counts()  # should have identical stats to the first journal timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_df['isDeactivated'] = (site_df.isDeleted == '1')|(site_df.isSpam == 1)\n",
    "site_df.isDeactivated.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(site_df.first_journal_timestamp.notna().rename(\"hasFirstJournal\"), site_df.isDeactivated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_df.loc[site_df.first_journal_timestamp.isna(),['site_id', 'ip', 'isDeleted', 'privacy', 'isSearchable', 'isGoogleable', 'isDeactivated']].sample(n=10, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_start_date = datetime.fromisoformat('2014-01-01').replace(tzinfo=pytz.UTC)\n",
    "invalid_end_date = datetime.fromisoformat('2020-07-01').replace(tzinfo=pytz.UTC)\n",
    "print(f\"Keeping sites created between {invalid_start_date.isoformat()} and {invalid_end_date.isoformat()}.\")\n",
    "invalid_start_timestamp = invalid_start_date.timestamp() * 1000\n",
    "invalid_end_timestamp = invalid_end_date.timestamp() * 1000\n",
    "sdf = site_df[(site_df.created_at>=invalid_start_timestamp)&(site_df.created_at<=invalid_end_timestamp)]\n",
    "len(sdf), len(site_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf = sdf[~sdf.isDeactivated]\n",
    "len(sdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "\n",
    "bins = []\n",
    "curr_date = invalid_start_date\n",
    "while curr_date <= invalid_end_date:\n",
    "    bins.append(int(curr_date.timestamp() * 1000))\n",
    "    curr_date += relativedelta(months=1)\n",
    "    \n",
    "#days = sdf.created_at.map(lambda ts: datetime.utcfromtimestamp(int(ts / 1000)).day)\n",
    "\n",
    "counts, bin_edges = np.histogram(sdf.created_at, bins=bins)\n",
    "ax.plot(bin_edges[:-1], counts, label=\"All sites\")\n",
    "\n",
    "counts, bin_edges = np.histogram(sdf[sdf.n_journals >= 2].created_at, bins=bins)\n",
    "ax.plot(bin_edges[:-1], counts, label=\"2+ Journal updates\\n(future Used Sites)\")\n",
    "\n",
    "\n",
    "\n",
    "counts, bin_edges = np.histogram(sdf[sdf.n_journals >= 5].created_at, bins=bins)\n",
    "ax.plot(bin_edges[:-1], counts, label=\"5+ Journal updates\")\n",
    "\n",
    "ax.set_ylabel(\"New Site count (by month)\")\n",
    "ax.set_xlabel(\"Date\")\n",
    "ax.set_title(\"New Site counts by month\")\n",
    "ax.legend()\n",
    "#ax.set_xticks([1, 10, 20, 31])\n",
    "#ax.set_xticklabels(['Jan 1', 'Jan 10', 'Jan 20', 'Jan 31'])\n",
    "years = [2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021]\n",
    "ax.set_xticks([int(datetime.fromisoformat(f'{year}-01-01').replace(tzinfo=pytz.UTC).timestamp() * 1000) for year in years])\n",
    "ax.set_xticklabels([datetime.fromisoformat(f'{year}-01-01').replace(tzinfo=pytz.UTC).strftime(\"%Y\") for year in years])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(sdf.privacy, [sdf.isSearchable.map(lambda v: bool(int(v)) if pd.notna(v) else 'None'), sdf.isGoogleable.map(lambda v: bool(int(v)) if pd.notna(v) else 'None')], dropna=False, margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(sdf.isSearchable.map(lambda v: bool(int(v)) if pd.notna(v) else 'None'), sdf.isGoogleable.map(lambda v: bool(int(v)) if pd.notna(v) else 'None'), margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_start_date = datetime.fromisoformat('2019-01-01').replace(tzinfo=pytz.UTC)\n",
    "invalid_end_date = datetime.fromisoformat('2021-02-01').replace(tzinfo=pytz.UTC)\n",
    "print(f\"Keeping sites created between {invalid_start_date.isoformat()} and {invalid_end_date.isoformat()}.\")\n",
    "invalid_start_timestamp = invalid_start_date.timestamp() * 1000\n",
    "invalid_end_timestamp = invalid_end_date.timestamp() * 1000\n",
    "sdf = site_df[(site_df.created_at>=invalid_start_timestamp)&(site_df.created_at<=invalid_end_timestamp)]\n",
    "sdf = sdf[sdf.isSpam.isna()]\n",
    "len(sdf), len(site_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "\n",
    "bins = []\n",
    "curr_date = invalid_start_date\n",
    "while curr_date <= invalid_end_date:\n",
    "    bins.append(int(curr_date.timestamp() * 1000))\n",
    "    curr_date += relativedelta(months=1)\n",
    "    \n",
    "counts, bin_edges = np.histogram(sdf.created_at, bins=bins)\n",
    "ax.plot(bin_edges[:-1], counts, label=\"All sites\")\n",
    "\n",
    "counts, bin_edges = np.histogram(sdf[sdf.n_journals >= 1].created_at, bins=bins)\n",
    "ax.plot(bin_edges[:-1], counts, label=\"1+ Journal updates\")\n",
    "\n",
    "counts, bin_edges = np.histogram(sdf[sdf.n_journals >= 2].created_at, bins=bins)\n",
    "ax.plot(bin_edges[:-1], counts, label=\"2+ Journal updates (Used Sites)\")\n",
    "\n",
    "counts, bin_edges = np.histogram(sdf[sdf.n_journals >= 5].created_at, bins=bins)\n",
    "ax.plot(bin_edges[:-1], counts, label=\"5+ Journal updates\")\n",
    "\n",
    "ax.set_title(\"Monthly New Sites in 2019 and 2020 (until July 2020)\")\n",
    "ax.set_ylabel(\"New Site count (by month)\")\n",
    "ax.set_xlabel(\"Date\")\n",
    "ax.legend()\n",
    "#ax.set_xticks([1, 10, 20, 31])\n",
    "#ax.set_xticklabels(['Jan 1', 'Jan 10', 'Jan 20', 'Jan 31'])\n",
    "years = [2019, 2020, 2021]\n",
    "ax.set_xticks([int(datetime.fromisoformat(f'{year}-01-01').replace(tzinfo=pytz.UTC).timestamp() * 1000) for year in years])\n",
    "ax.set_xticklabels([datetime.fromisoformat(f'{year}-01-01').replace(tzinfo=pytz.UTC).strftime(\"%Y\") for year in years])\n",
    "\n",
    "for year in years:\n",
    "    start_date = datetime.fromisoformat(f'{year}-01-01').replace(tzinfo=pytz.UTC)\n",
    "    end_date = start_date + relativedelta(months=1)\n",
    "    start_timestamp = int(start_date.timestamp() * 1000)\n",
    "    end_timestamp = int(end_date.timestamp() * 1000)\n",
    "    \n",
    "    bump = 40\n",
    "    ssdf = sdf[(sdf.created_at >= start_timestamp)&(sdf.created_at < end_timestamp)]\n",
    "    ax.text(start_date.timestamp() * 1000, len(ssdf) + bump, f'{len(ssdf)}', ha='center', va='bottom')\n",
    "    \n",
    "    ssdf = sdf[(sdf.created_at >= start_timestamp)&(sdf.created_at < end_timestamp)&(sdf.n_journals >= 1)]\n",
    "    ax.text(start_date.timestamp() * 1000, len(ssdf) + bump, f'{len(ssdf)}', ha='center')\n",
    "    \n",
    "    ssdf = sdf[(sdf.created_at >= start_timestamp)&(sdf.created_at < end_timestamp)&(sdf.n_journals >= 2)]\n",
    "    ax.text(start_date.timestamp() * 1000, len(ssdf) + bump, f\"{len(ssdf)}\", ha='center')\n",
    "    \n",
    "    ssdf = sdf[(sdf.created_at >= start_timestamp)&(sdf.created_at < end_timestamp)&(sdf.n_journals >= 5)]\n",
    "    ax.text(start_date.timestamp() * 1000, len(ssdf) + bump, f'{len(ssdf)}', ha='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssdf = sdf[sdf.first_journal_timestamp.notna()]\n",
    "time_to_first_journal = ssdf.first_journal_timestamp - ssdf.created_at\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "\n",
    "bins = [0, 1000 * 60, 1000 * 60 * 60, 1000 * 60 * 60 * 24, 1000 * 60 * 60 * 24 * 7, 1000 * 60 * 60 * 24 * 30, 1000 * 60 * 60 * 24 * 365, np.max(time_to_first_journal) + 1]\n",
    "counts, bin_edges = np.histogram(time_to_first_journal, bins=bins)\n",
    "\n",
    "#ax.hist(time_to_first_journal, bins=bins, log=True)\n",
    "x = np.arange(len(counts)) + 1\n",
    "ax.bar(x, counts, width=0.9, color=matplotlib.cm.viridis(0.2), label=f'1+ Journal updates ({len(ssdf)/len(sdf)*100:.1f}% of sites)')\n",
    "\n",
    "ax.bar(0, np.sum(sdf.first_journal_timestamp.isna()), width=0.9, color=matplotlib.cm.viridis(0.5), label=f'No Journal updates ({np.sum(sdf.first_journal_timestamp.isna())/len(sdf)*100:.1f}% of sites)')\n",
    "ax.axvline(0.5, linestyle='--', color='black', alpha=0.7)\n",
    "\n",
    "ax.legend()\n",
    "ax.set_title(f\"Time between site creation and first Journal update\\n(for {len(sdf):,} sites created in 2019 and 2020)\")\n",
    "\n",
    "ax.set_xticks([0,] + list(x))\n",
    "ax.set_xticklabels(['Never', '<1 min', '<1 hour', '<1 day', '<1 week', '<1 month', '<1 year', '>1 year'])\n",
    "for i, count in enumerate(counts):\n",
    "    ax.text(i+1, count + 50, f'{count / len(ssdf) * 100:.1f}%', ha='center', va='bottom')\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "np.median(time_to_first_journal) / 1000 / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_start_date = datetime.fromisoformat('2019-01-01').replace(tzinfo=pytz.UTC)\n",
    "invalid_end_date = datetime.fromisoformat('2020-01-01').replace(tzinfo=pytz.UTC)\n",
    "print(f\"Keeping sites created between {invalid_start_date.isoformat()} and {invalid_end_date.isoformat()}.\")\n",
    "invalid_start_timestamp = invalid_start_date.timestamp() * 1000\n",
    "invalid_end_timestamp = invalid_end_date.timestamp() * 1000\n",
    "sdf = site_df[(site_df.created_at>=invalid_start_timestamp)&(site_df.created_at<=invalid_end_timestamp)]\n",
    "sdf = sdf[sdf.isSpam.isna()]\n",
    "len(sdf), len(site_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssdf = sdf[sdf.first_journal_timestamp.notna()]\n",
    "time_to_first_journal = ssdf.first_journal_timestamp - ssdf.created_at\n",
    "print(f\"{np.sum(time_to_first_journal < 0)} / {len(time_to_first_journal)} sites have first journal timestamps before the site creation timestamp.\")\n",
    "time_to_first_journal = np.maximum(time_to_first_journal, 0)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "\n",
    "bins = [0, 1000 * 60, 1000 * 60 * 60, 1000 * 60 * 60 * 24, 1000 * 60 * 60 * 24 * 7, 1000 * 60 * 60 * 24 * 30, 1000 * 60 * 60 * 24 * 365, np.iinfo(np.int64).max]\n",
    "counts, bin_edges = np.histogram(time_to_first_journal, bins=bins)\n",
    "assert np.all(np.array(bins) == bin_edges)\n",
    "assert np.sum(counts) == len(ssdf), f'{np.sum(counts)} / {len(ssdf)}'\n",
    "\n",
    "#ax.hist(time_to_first_journal, bins=bins, log=True)\n",
    "x = np.arange(len(counts)) + 1\n",
    "ax.bar(x, counts, width=0.9, color=matplotlib.cm.viridis(0.2), label=f'1+ Journal updates ({len(ssdf)/len(sdf)*100:.1f}% of sites)')\n",
    "\n",
    "ax.bar(0, np.sum(sdf.first_journal_timestamp.isna()), width=0.9, color=matplotlib.cm.viridis(0.5), label=f'No Journal updates ({np.sum(sdf.first_journal_timestamp.isna())/len(sdf)*100:.1f}% of sites)')\n",
    "ax.axvline(0.5, linestyle='--', color='black', alpha=0.7)\n",
    "\n",
    "ax.legend()\n",
    "ax.set_title(f\"Time between site creation and first Journal update\\n(for {len(sdf):,} sites created in 2019)\")\n",
    "ax.set_xlabel(\"Time elapsed between site creation and the first Journal update\")\n",
    "ax.set_ylabel(\"Number of sites\")\n",
    "\n",
    "ax.set_xticks([0,] + list(x))\n",
    "ax.set_xticklabels(['Never', '<1 min', '<1 hour', '<1 day', '<1 week', '<1 month', '<1 year', '>1 year'])\n",
    "for i, count in enumerate(counts):\n",
    "    ax.text(i+1, count + 50, f'{count / len(ssdf) * 100:.1f}%', ha='center', va='bottom')\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "np.median(time_to_first_journal) / 1000 / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssdf = sdf[sdf.second_journal_timestamp.notna()]\n",
    "time_to_second_journal = ssdf.second_journal_timestamp - ssdf.first_journal_timestamp\n",
    "print(f\"{np.sum(time_to_second_journal < 0)} / {len(time_to_second_journal)} sites have second journal timestamps before the first journal timestamp.\")\n",
    "time_to_second_journal = np.maximum(time_to_second_journal, 0)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "\n",
    "bins = [0, 1000 * 60, 1000 * 60 * 60, 1000 * 60 * 60 * 24, 1000 * 60 * 60 * 24 * 7, 1000 * 60 * 60 * 24 * 30, 1000 * 60 * 60 * 24 * 365, np.max(time_to_first_journal) + 1]\n",
    "counts, bin_edges = np.histogram(time_to_second_journal, bins=bins)\n",
    "\n",
    "x = np.arange(len(counts)) + 2\n",
    "ax.bar(x, counts, width=0.9, color=matplotlib.cm.viridis(0.7), label=f'2+ Journal updates ({len(ssdf)/len(sdf)*100:.1f}% of sites)')\n",
    "\n",
    "ax.bar(1, np.sum((sdf.first_journal_timestamp.notna())&(sdf.second_journal_timestamp.isna())), width=0.9, color=matplotlib.cm.viridis(0.2), label=f'1 Journal update ({np.sum((sdf.first_journal_timestamp.notna())&(sdf.second_journal_timestamp.isna()))/len(sdf)*100:.1f}% of sites)')\n",
    "ax.bar(0, np.sum(sdf.first_journal_timestamp.isna()), width=0.9, color=matplotlib.cm.viridis(0.5), label=f'No Journal updates ({np.sum(sdf.first_journal_timestamp.isna())/len(sdf)*100:.1f}% of sites)')\n",
    "\n",
    "ax.axvline(1.5, linestyle='--', color='black', alpha=0.7)\n",
    "\n",
    "ax.legend()\n",
    "ax.set_title(f\"Time between first and second Journal update \\n(for {len(sdf):,} sites created in 2019)\")\n",
    "\n",
    "ax.set_xticks([0,1,] + list(x))\n",
    "ax.set_xticklabels(['Never\\n(No 1st)', 'Never\\n(No 2nd)', '<1 min', '<1 hour', '<1 day', '<1 week\\n(2 or more total Journal updates)', '<1 month', '<1 year', '>1 year'])\n",
    "ax.set_xlabel(\"Time elapsed between the first and second Journal update on a site\")\n",
    "ax.set_ylabel(\"Number of sites\")\n",
    "\n",
    "for i, count in enumerate(counts):\n",
    "    ax.text(i+2, count + 50, f'{count / len(ssdf) * 100:.1f}%', ha='center', va='bottom')\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "np.median(time_to_second_journal) / 1000 / 60 / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "bins = [0, 1, 1000 * 60, 1000 * 60 * 60, 1000 * 60 * 60 * 24, 1000 * 60 * 60 * 24 * 7, 1000 * 60 * 60 * 24 * 30, 1000 * 60 * 60 * 24 * 365, np.iinfo(np.int64).max]\n",
    "\n",
    "\n",
    "ax = axes[0]\n",
    "ssdf = sdf[sdf.first_journal_timestamp.notna()]\n",
    "y = ssdf.last_journal_timestamp - ssdf.first_journal_timestamp\n",
    "counts, bin_edges = np.histogram(y, bins=bins)\n",
    "x = np.arange(len(counts))\n",
    "ax.bar(x, counts, width=0.9, color=matplotlib.cm.viridis(0.2))\n",
    "ax.axvline(5, linestyle='--', color='black', alpha=0.9, label=f'Median ({np.median(y) / 1000 / 60 / 60 / 24:.2f} days)')\n",
    "ax.axvline(5.35, linestyle='--', color='black', alpha=0.4, label=f'Mean ({np.mean(y) / 1000 / 60 / 60 / 24:.2f} days)')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(['None', '<1 min', '<1 hour', '<1 day', '<1 week', '<1 month', '<1 year', '>1 year'])\n",
    "ax.legend()\n",
    "ax.set_title(f'Time between first and last journal update \\n(for {len(ssdf):,} sites started in 2019)')\n",
    "\n",
    "\n",
    "ax = axes[1]\n",
    "ssdf = sdf[sdf.second_journal_timestamp.notna()]\n",
    "y = ssdf.second_journal_timestamp - ssdf.first_journal_timestamp\n",
    "counts, bin_edges = np.histogram(y, bins=bins)\n",
    "x = np.arange(len(counts))\n",
    "ax.bar(x, counts, width=0.9, color=matplotlib.cm.viridis(0.7))\n",
    "ax.axvline(3, linestyle='--', color='black', alpha=0.9, label=f'Median ({np.median(y) / 1000 / 60 / 60 / 24:.2f} days)')\n",
    "ax.axvline(4, linestyle='--', color='black', alpha=0.4, label=f'Mean ({np.mean(y) / 1000 / 60 / 60 / 24:.2f} days)')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(['None', '<1 min', '<1 hour', '<1 day', '<1 week', '<1 month', '<1 year', '>1 year'])\n",
    "ax.legend()\n",
    "ax.set_title(f'Time between first and second journal update \\n(for {len(ssdf):,} sites started in 2019)')\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssdf = sdf[sdf.second_journal_timestamp.notna()]\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "\n",
    "ssdf = sdf[sdf.first_journal_timestamp.notna()]\n",
    "survival_times = ssdf.last_journal_timestamp - ssdf.first_journal_timestamp\n",
    "y = survival_times.value_counts().sort_index()\n",
    "\n",
    "count = len(ssdf)\n",
    "xs = [0,]\n",
    "ys = [count / len(sdf),]\n",
    "for survival_time, site_count in zip(y.index, y):\n",
    "    xs.append(survival_time + 1)\n",
    "    count -= site_count\n",
    "    ys.append(count / len(sdf))\n",
    "    \n",
    "ax.plot(xs, ys)\n",
    "#ax.scatter(xs[::1000], ys[::1000])\n",
    "\n",
    "start_date = datetime.fromisoformat('2019-01-01').replace(tzinfo=pytz.UTC)\n",
    "end_date = datetime.fromisoformat('2020-01-01').replace(tzinfo=pytz.UTC)\n",
    "visualized_range_ms = (end_date.timestamp() - start_date.timestamp()) * 1000\n",
    "\n",
    "xs = []\n",
    "ys = []\n",
    "i = 0\n",
    "for x in [0, 1,] + list(np.linspace(0, visualized_range_ms, num=13))[1:]:  #[1000 * 60 * 60 * 24 * 30 * i for i in range(1, 12)] + [1000 * 60 * 60 * 24 * 365,]:\n",
    "    pct_alive = np.sum(survival_times >= x) / len(sdf)\n",
    "    xs.append(x)\n",
    "    ys.append(pct_alive)\n",
    "    ax.text(x + (1000 * 60 * 60 * 24 * 2), pct_alive, f'{pct_alive*100:.1f}%', va='bottom')\n",
    "    if x == 1:\n",
    "        ax.annotate(f'{pct_alive*100:.1f}% of sites have > 2 updates (and > 0 age)', xy=(1000 * 60 * 60 * 24 * 30, pct_alive),  xycoords='data',\n",
    "            xytext=(1000 * 60 * 60 * 24 * 100, pct_alive), textcoords='data',\n",
    "            arrowprops=dict(facecolor='black', shrink=0.05, width=2, headwidth=10),\n",
    "            horizontalalignment='left', verticalalignment='center',\n",
    "            )\n",
    "    elif i == 7:\n",
    "         ax.annotate(f'{pct_alive*100:.1f}% of sites last longer than 6 months', xy=(x, pct_alive * 0.99),  xycoords='data',\n",
    "            xytext=(x, pct_alive / 2), textcoords='data',\n",
    "            arrowprops=dict(facecolor='black', shrink=0.05, width=2, headwidth=10),\n",
    "            horizontalalignment='center', verticalalignment='top',\n",
    "            )\n",
    "    i += 1\n",
    "ax.scatter(xs, ys, color='black', marker='.', zorder=10)\n",
    "\n",
    "med = np.median(survival_times)\n",
    "print(f\"Among sites with 1+ journal updates, median is {np.median(survival_times) / 1000 / 60 / 60 / 24:.2f} days\")\n",
    "print(f\"Among sites with 2+ journal updates, median is {np.median(survival_times[survival_times > 0]) / 1000 / 60 / 60 / 24:.2f} days\")\n",
    "#ax.vlines(med, 0.55, 0.66, linestyle='--', color='black')\n",
    "\n",
    "#ax.annotate('The median site has 0 Journal updates!', xy=(med, 0.5),  xycoords='data',\n",
    "#            xytext=(1000 * 60 * 60 * 24 * 100, 0.5), textcoords='data',\n",
    "#            arrowprops=dict(facecolor='black', shrink=0.05, width=2, headwidth=10),\n",
    "#            horizontalalignment='left', verticalalignment='center',\n",
    "#            )\n",
    "\n",
    "height = np.sum(survival_times >= med) / len(sdf)\n",
    "ax.annotate(f'For sites with 1+ updates, the median site lasts {med / 1000 / 60 / 60 / 24:.1f} days', xy=(med, height),  xycoords='data',\n",
    "            xytext=(1000 * 60 * 60 * 24 * 100, height), textcoords='data',\n",
    "            arrowprops=dict(facecolor='black', shrink=0.05, width=2, headwidth=10),\n",
    "            horizontalalignment='left', verticalalignment='center',\n",
    "            )\n",
    "\n",
    "\n",
    "x = [0, 1000 * 60 * 60 * 24 * 30, 1000 * 60 * 60 * 24 * 365]\n",
    "x = np.linspace(0, visualized_range_ms, num=13)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(['0mos',] + [f'{i}mo{\"s\" if i > 1 else \"\"}' for i in range(1, 12)] + ['1yr',])\n",
    "#ax.set_xticklabels(['None', '1 month', '1 year'])\n",
    "ax.set_xlim(-1000 * 60 * 60 * 90, 1000 * 60 * 60 * 24 * 400)\n",
    "\n",
    "ax.set_xlabel(\"Site age\")\n",
    "ax.set_ylabel(\"Percent of sites at least this old\")\n",
    "ax.set_title(f\"Site age for {len(sdf):,} sites created in 2019\\n(measured as time between first and last Journal update)\")\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f'{np.sum(sdf.n_journals >= 5) / len(sdf)*100:.1f}% of sites will publish 5 or more updates'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same as above, but breaking down by month\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "\n",
    "prev_date = datetime.fromisoformat('2019-01-01').replace(tzinfo=pytz.UTC)\n",
    "curr_date = datetime.fromisoformat('2019-02-01').replace(tzinfo=pytz.UTC)\n",
    "for j in range(12):\n",
    "    ssdf = sdf[(sdf.first_journal_timestamp.notna())&(sdf.created_at >= prev_date.timestamp() * 1000)&(sdf.created_at <= curr_date.timestamp() * 1000)]\n",
    "    print(f\"{prev_date.strftime('%b')} n={len(ssdf)}\")\n",
    "    survival_times = ssdf.last_journal_timestamp - ssdf.first_journal_timestamp\n",
    "    y = survival_times.value_counts().sort_index()\n",
    "\n",
    "    count = len(ssdf)\n",
    "    xs = [0,]\n",
    "    ys = [count / len(ssdf),]\n",
    "    for survival_time, site_count in zip(y.index, y):\n",
    "        xs.append(survival_time + 1)\n",
    "        count -= site_count\n",
    "        ys.append(count / len(ssdf))\n",
    "\n",
    "    ax.plot(xs, ys, label=f\"{prev_date.strftime('%b')} (n={len(ssdf)}, {np.median(survival_times) / 1000 / 60 / 60 / 24:.1f} days, {np.sum(survival_times > 0) / len(ssdf)*100:.1f}% >2 JU)\", color=matplotlib.cm.viridis(j / 12), alpha=0.6)\n",
    "\n",
    "    start_date = curr_date\n",
    "    end_date = curr_date + relativedelta(years=1)\n",
    "    visualized_range_ms = (end_date.timestamp() - start_date.timestamp()) * 1000\n",
    "\n",
    "    xs = []\n",
    "    ys = []\n",
    "    i = 0\n",
    "    for x in [0, 1,] + list(np.linspace(0, visualized_range_ms, num=13))[1:]:  #[1000 * 60 * 60 * 24 * 30 * i for i in range(1, 12)] + [1000 * 60 * 60 * 24 * 365,]:\n",
    "        pct_alive = np.sum(survival_times >= x) / len(ssdf)\n",
    "        xs.append(x)\n",
    "        ys.append(pct_alive)\n",
    "        #ax.text(x + (1000 * 60 * 60 * 24 * 2), pct_alive, f'{pct_alive*100:.1f}%', va='bottom')\n",
    "        if x == 1:\n",
    "            print(f'{pct_alive*100:.1f}% of sites have > 2 updates')\n",
    "        elif i == 7:\n",
    "             print(f'{pct_alive*100:.1f}% of sites last longer than 6 months')\n",
    "        i += 1\n",
    "    ax.scatter(xs, ys, marker='.', zorder=10+j, color=matplotlib.cm.viridis(j / 12), alpha=0.8)\n",
    "\n",
    "    print(f\"Among sites with 1+ journal updates, median is {np.median(survival_times) / 1000 / 60 / 60 / 24:.2f} days\")\n",
    "    print(f\"Among sites with 2+ journal updates, median is {np.median(survival_times[survival_times > 0]) / 1000 / 60 / 60 / 24:.2f} days\")\n",
    "\n",
    "    prev_date = curr_date\n",
    "    curr_date = curr_date + relativedelta(months=1)\n",
    "\n",
    "\n",
    "x = [0, 1000 * 60 * 60 * 24 * 30, 1000 * 60 * 60 * 24 * 365]\n",
    "x = np.linspace(0, visualized_range_ms, num=13)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(['0mos',] + [f'{i}mo{\"s\" if i > 1 else \"\"}' for i in range(1, 12)] + ['1yr',])\n",
    "#ax.set_xticklabels(['None', '1 month', '1 year'])\n",
    "ax.set_xlim(-1000 * 60 * 60 * 90, 1000 * 60 * 60 * 24 * 400)\n",
    "\n",
    "ax.set_xlabel(\"Site age\")\n",
    "ax.set_ylabel(\"Percent of sites at least this old\")\n",
    "ax.set_title(f\"Site age for {len(sdf):,} sites created in 2019\\n(measured as time between first and last Journal update)\")\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (shared-conda)",
   "language": "python",
   "name": "shared-conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
