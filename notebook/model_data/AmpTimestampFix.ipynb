{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amp Timestamp Fix\n",
    "===\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.rcParams['figure.dpi'] = 120\n",
    "matplotlib.rcParams['font.family'] = \"serif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import bson\n",
    "from bson.codec_options import CodecOptions\n",
    "from bson.raw_bson import RawBSONDocument\n",
    "from bson import ObjectId\n",
    "import gzip\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from glob import glob\n",
    "\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import dateutil\n",
    "import pytz\n",
    "\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "git_root_dir = !git rev-parse --show-toplevel\n",
    "git_root_dir = Path(git_root_dir[0].strip())\n",
    "git_root_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "caringbridge_core_path = \"/home/lana/levon003/repos/caringbridge_core\"\n",
    "sys.path.append(caringbridge_core_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cbcore.data.paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert os.path.exists(cbcore.data.paths.raw_data_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the site data\n",
    "s = datetime.now()\n",
    "site_metadata_dir = \"/home/lana/shared/caringbridge/data/derived/site_metadata\"\n",
    "site_metadata_filepath = os.path.join(site_metadata_dir, \"site_metadata.feather\")\n",
    "site_df = pd.read_feather(site_metadata_filepath)\n",
    "print(f\"Read {len(site_df)} site_df rows in {datetime.now() - s}.\")\n",
    "site_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the journal metadata\n",
    "s = datetime.now()\n",
    "journal_metadata_dir = \"/home/lana/shared/caringbridge/data/derived/journal_metadata\"\n",
    "journal_metadata_filepath = os.path.join(journal_metadata_dir, \"journal_metadata.feather\")\n",
    "journal_df = pd.read_feather(journal_metadata_filepath)\n",
    "print(datetime.now() - s)\n",
    "len(journal_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ints = []\n",
    "interactions_dir = os.path.join(cbcore.data.paths.derived_data_filepath, 'interactions')\n",
    "filename = 'reaction.csv'\n",
    "input_filepath = os.path.join(interactions_dir, filename)\n",
    "reactions_df = pd.read_csv(input_filepath, header=None, names=['user_id', 'site_id', 'interaction_type', 'interaction_oid', 'parent_type', 'parent_id', 'ancestor_type', 'ancestor_id', 'created_at', 'updated_at']).astype({\n",
    "    'user_id': int,\n",
    "    'site_id': int,\n",
    "    'created_at': np.int64,\n",
    "    'updated_at': str,\n",
    "})\n",
    "len(reactions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reactions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_df = reactions_df[reactions_df.parent_type == 'journal']\n",
    "r_df.interaction_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_reactions_launch_date = datetime.utcfromtimestamp(r_df.created_at.min() / 1000).replace(tzinfo=pytz.UTC)\n",
    "str(real_reactions_launch_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reactions_launch_timestamp = real_reactions_launch_date.timestamp() * 1000\n",
    "parent_journal_oids = set(r_df.parent_id)\n",
    "sjournal_df = journal_df[(journal_df.site_id.isin(set(site_df[~site_df.isDeactivated].site_id)))&(journal_df.published_at > reactions_launch_timestamp)&(journal_df.journal_oid.isin(parent_journal_oids))]\n",
    "len(sjournal_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sjournal_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_df = r_df.merge(sjournal_df[['journal_oid', 'published_at']], how='left', left_on='parent_id', right_on='journal_oid', validate='many_to_one')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(r_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_df.published_at.notna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_df = r_df[(r_df.published_at.notna())&(r_df.published_at < datetime.now().timestamp() * 1000)]\n",
    "len(r_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(r_df.published_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_df['time_since_journal'] = np.maximum(r_df.created_at - r_df.published_at, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# was \"4\"\n",
    "np.sum(r_df.time_since_journal < 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maximum of 213 days between journal and reaction\n",
    "r_df.time_since_journal.max() / 1000 / 60 / 60 / 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = r_df.time_since_journal / 1000 / 60  # in minutes\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "\n",
    "bins = np.arange(0, 61)\n",
    "ax.hist(xs, bins=bins)\n",
    "\n",
    "ax.set_xlabel(\"Time in minutes between journal and reaction\")\n",
    "\n",
    "plt.show()\n",
    "xs.min(), xs.max(), xs.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(r_df))\n",
    "for q in [0.0, 0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9,0.95, 0.99, 1.0]:\n",
    "    print(f\"{q:>5.2f} {np.quantile(r_df.time_since_journal, q) / 1000 / 60 / 60:>10.2f} hours\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for hour in np.arange(0, 49):\n",
    "    print(f\"{hour:>5.0f} {np.sum(r_df.time_since_journal <= hour * 1000 * 60 * 60) / len(r_df):>10.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = r_df[r_df.time_since_journal <= 48 * 1000 * 60 * 60].time_since_journal / 1000 / 60 / 60 # in hours\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "\n",
    "y = xs.value_counts().sort_index()\n",
    "\n",
    "count = len(xs)\n",
    "b_xs = []\n",
    "b_ys = []\n",
    "for survival_time, reactions_count in zip(y.index, y):\n",
    "    b_xs.append(survival_time)\n",
    "    count -= reactions_count\n",
    "    b_ys.append(count / len(xs))\n",
    "    \n",
    "ax.plot(b_xs, b_ys)\n",
    "\n",
    "visualized_range_ms = xs.max() - xs.min()\n",
    "\n",
    "p_xs = []\n",
    "p_ys = []\n",
    "for x in np.linspace(0, visualized_range_ms, num=11):\n",
    "    pct_alive = np.sum(xs >= x) / len(xs)\n",
    "    p_xs.append(x)\n",
    "    p_ys.append(pct_alive)\n",
    "    x_shift = 0\n",
    "    ax.text(x + x_shift, pct_alive, f'{pct_alive:.1%}', va='bottom')\n",
    "ax.scatter(p_xs, p_ys, color='black', marker='.', zorder=10)\n",
    "\n",
    "ax.set_xlabel(\"Time between journal and reaction (hours)\")\n",
    "ax.set_ylabel(\"Percent of reactions made at least this long after the journal\")\n",
    "ax.set_title(f\"Time between journal and reaction for {len(xs):,} reactions with time < 48 hours\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "\n",
    "for sdf, label in zip([r_df[r_df.interaction_type == 'amp_happy'], r_df[r_df.interaction_type == 'amp_sad'], r_df[r_df.interaction_type == 'amp_folded_hands']], ['happy', 'sad', 'folded hands']):\n",
    "    xs = sdf[sdf.time_since_journal <= 48 * 1000 * 60 * 60].time_since_journal / 1000 / 60 / 60 # in hours\n",
    "    y = xs.value_counts().sort_index()\n",
    "\n",
    "    count = len(xs)\n",
    "    b_xs = []\n",
    "    b_ys = []\n",
    "    for survival_time, reactions_count in zip(y.index, y):\n",
    "        b_xs.append(survival_time)\n",
    "        count -= reactions_count\n",
    "        b_ys.append(count / len(xs))\n",
    "\n",
    "    ax.plot(b_xs, b_ys, label=f\"{label} (n={len(xs):,})\")\n",
    "\n",
    "    visualized_range_ms = xs.max() - xs.min()\n",
    "\n",
    "    p_xs = []\n",
    "    p_ys = []\n",
    "    for x in np.linspace(0, visualized_range_ms, num=11):\n",
    "        pct_alive = np.sum(xs >= x) / len(xs)\n",
    "        p_xs.append(x)\n",
    "        p_ys.append(pct_alive)\n",
    "        #x_shift = 0\n",
    "        #ax.text(x + x_shift, pct_alive, f'{pct_alive:.1%}', va='bottom')\n",
    "    ax.scatter(p_xs, p_ys, color='black', marker='.', zorder=10)\n",
    "\n",
    "ax.set_xlabel(\"Time between journal and reaction (hours)\")\n",
    "ax.set_ylabel(\"Percent of reactions made at least this long after the journal\")\n",
    "ax.set_title(f\"Time between journal and reaction for reactions with time < 48 hours\")\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use only points from the first 90%\n",
    "valid_times = r_df[r_df.time_since_journal <= np.quantile(r_df.time_since_journal, 0.9)].time_since_journal\n",
    "valid_times.max() / 1000 / 60 / 60 # in hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_times = valid_times.to_numpy()\n",
    "valid_times.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng()\n",
    "%timeit rng.choice(valid_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the valid times as an array to be used to add random delay to the published_at date of original amps\n",
    "model_data_dir = '/home/lana/shared/caringbridge/data/projects/recsys-peer-match/model_data'\n",
    "valid_times_filepath = os.path.join(model_data_dir, 'reaction_ms_since_journal.npy')\n",
    "with open(valid_times_filepath, 'wb') as outfile:\n",
    "    np.save(outfile, valid_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_times_filepath = os.path.join(model_data_dir, 'reaction_ms_since_journal.npy')\n",
    "with open(valid_times_filepath, 'rb') as infile:\n",
    "    reaction_ms_since_journal = np.load(infile)\n",
    "assert np.all(reaction_ms_since_journal == valid_times)\n",
    "reaction_ms_since_journal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample code to add noise:\n",
    "#journal_df.loc[journal_df.amp_count == 1, 'created_at'] = journal_df.loc[journal_df.amp_count == 1, 'created_at'].map(lambda ca: ca + rng.choice(valid_times))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (shared-conda)",
   "language": "python",
   "name": "shared-conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
