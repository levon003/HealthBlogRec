{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pseudo-Control Comparison\n",
    "===\n",
    "\n",
    "Relevant Google Doc: https://docs.google.com/document/d/1_VjjJkdvUD_YsIjGMYGISpJg5CGC_mRzFgYpuBqKliA/edit?usp=sharing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.rcParams['figure.dpi'] = 120\n",
    "matplotlib.rcParams['font.family'] = \"serif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import bson\n",
    "from bson.codec_options import CodecOptions\n",
    "from bson.raw_bson import RawBSONDocument\n",
    "from bson import ObjectId\n",
    "import gzip\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from glob import glob\n",
    "\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import dateutil\n",
    "import pytz\n",
    "\n",
    "import scipy\n",
    "import scipy.stats\n",
    "\n",
    "import logging\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "git_root_dir = !git rev-parse --show-toplevel\n",
    "git_root_dir = Path(git_root_dir[0].strip())\n",
    "git_root_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "caringbridge_core_path = \"/home/lana/levon003/repos/caringbridge_core\"\n",
    "sys.path.append(caringbridge_core_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cbcore.data.paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert os.path.exists(cbcore.data.paths.raw_data_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caringbridge_core_path = \"/home/lana/levon003/repos/recsys-peer-match/src\"\n",
    "sys.path.append(caringbridge_core_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cbrec.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figures_dir = os.path.join(git_root_dir, 'figures')\n",
    "os.makedirs(figures_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading previous batch recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_data_dir = os.path.join(cbcore.data.paths.projects_data_dir, 'recsys-peer-match', 'participant')\n",
    "!wc -l {participant_data_dir}/*.ndjson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in recommendations from previous rounds\n",
    "d = []\n",
    "for batch_id in [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]:\n",
    "    participant_data_filepath = os.path.join(participant_data_dir, f'participant_rec_data_b{batch_id}.ndjson')\n",
    "    with open(participant_data_filepath, 'r') as infile:\n",
    "        for line in infile:\n",
    "            participant = json.loads(line)\n",
    "            del participant['site_scores']\n",
    "            participant['batch_id'] = batch_id\n",
    "            d.append(participant)\n",
    "len(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_df = pd.DataFrame(d)\n",
    "batch_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(batch_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_df.sse_site_list.iloc[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_recced_site_map = {}\n",
    "for participant_id, group in batch_df.groupby('participant_id'):\n",
    "    recced_site_ids = []\n",
    "    for sse_site_list in group.sse_site_list:\n",
    "        recced_site_ids.extend([site['site_id'] for site in sse_site_list])\n",
    "    assert len(recced_site_ids) == len(set(recced_site_ids)), \"Duplicate rec was given.\"\n",
    "    recced_site_ids = list(set(recced_site_ids))\n",
    "    participant_recced_site_map[participant_id] = recced_site_ids\n",
    "len(participant_recced_site_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recced_usps = [(row.participant_id, site['site_id']) for row in batch_df.itertuples() for site in row.sse_site_list]\n",
    "len(recced_usps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(set(recced_usps)) == len(recced_usps), \"Duplicate rec given.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create rec_df\n",
    "rec_df = []\n",
    "for row in batch_df.itertuples(index=False):\n",
    "    for i, site in enumerate(row.sse_site_list):\n",
    "        rec = row._asdict()\n",
    "        del rec['sse_site_list']\n",
    "        if 'journal_body' in site:\n",
    "            # some of the data were written with different key names for cleaned_journal_{body,title}\n",
    "            # this code normalizes the key names\n",
    "            site = dict(site)\n",
    "            site['cleaned_journal_body'] = site['journal_body']\n",
    "            del site['journal_body']\n",
    "            site['cleaned_journal_title'] = site['journal_title']\n",
    "            del site['journal_title']\n",
    "        rec.update(site)\n",
    "        rec['rank'] = i\n",
    "        rec_df.append(rec)\n",
    "rec_df = pd.DataFrame(rec_df)\n",
    "len(rec_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add alias for participant_id\n",
    "rec_df['user_id'] = rec_df['participant_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_df.sample(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Participant data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get participant data\n",
    "participant_id_filepath = os.path.join(git_root_dir, 'data/email/participant_ids.tsv')\n",
    "participant_df = pd.read_csv(participant_id_filepath, sep='\\t', header=0)\n",
    "print(len(participant_df))\n",
    "participant_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_batch_count_map = batch_df.groupby('participant_id').batch_id.nunique().to_dict()\n",
    "participant_df['n_total_recs'] = participant_df.user_id.map(lambda user_id: participant_batch_count_map[user_id] * 5 if user_id in participant_batch_count_map else 0)\n",
    "participant_df.n_total_recs.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_first_sse_map = batch_df.groupby('participant_id').sse_sent_timestamp.min()\n",
    "participant_df['first_sse_timestamp'] = participant_df.user_id.map(lambda user_id: participant_first_sse_map[user_id] if user_id in participant_first_sse_map else -1)\n",
    "participant_df.first_sse_timestamp.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_user_ids = set(participant_df[participant_df.n_total_recs > 0].user_id)\n",
    "print(f\"{len(set(participant_df.user_id))} participants were matched to an email\")\n",
    "print(f\"{len(set(participant_df[participant_df.n_total_recs > 0].user_id))} participants received 1+ recommendations\")\n",
    "len(participant_user_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Site, Profile, Journal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the site metadata dataframe\n",
    "# this is created in caringbridge_core from the new data\n",
    "site_metadata_working_dir = \"/home/lana/shared/caringbridge/data/derived/site_metadata\"\n",
    "s = datetime.now()\n",
    "site_metadata_filepath = os.path.join(site_metadata_working_dir, \"site_metadata.feather\")\n",
    "site_info_df = pd.read_feather(site_metadata_filepath)\n",
    "assert np.sum(site_info_df.site_id.value_counts() > 1) == 0, \"Site ids are not globally unique.\"\n",
    "print(datetime.now() - s)\n",
    "len(site_info_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the profile data\n",
    "profile_metadata_dir = '/home/lana/shared/caringbridge/data/derived/profile'\n",
    "s = datetime.now()\n",
    "profile_df = pd.read_feather(os.path.join(profile_metadata_dir, 'profile.feather'))\n",
    "print(f\"Loaded {len(profile_df)} rows in {datetime.now() - s}.\")\n",
    "profile_df.sample(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the journal metadata\n",
    "s = datetime.now()\n",
    "journal_metadata_dir = \"/home/lana/shared/caringbridge/data/derived/journal_metadata\"\n",
    "journal_metadata_filepath = os.path.join(journal_metadata_dir, \"journal_metadata.feather\")\n",
    "journal_df = pd.read_feather(journal_metadata_filepath)\n",
    "print(datetime.now() - s)\n",
    "len(journal_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "journal_df['usp'] = [(user_id, site_id) for user_id, site_id in zip(journal_df.user_id, journal_df.site_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interaction data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read interactions dataframe\n",
    "s = datetime.now()\n",
    "model_data_dir = '/home/lana/shared/caringbridge/data/projects/recsys-peer-match/model_data'\n",
    "ints_df = pd.read_feather(os.path.join(model_data_dir, 'ints_df.feather'))\n",
    "print(f\"Read {len(ints_df)} rows ({len(set(ints_df.user_id))} unique users) in {datetime.now() - s}.\")\n",
    "ints_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ints_df['usp'] = [(user_id, site_id) for user_id, site_id in zip(ints_df.user_id, ints_df.site_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visit data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the site profile diff\n",
    "# rows should be >= 37M+\n",
    "s = datetime.now()\n",
    "site_profile_diff_filepath = os.path.join(cbcore.data.paths.projects_data_dir, 'caringbridge_core', 'site_profile_diff', 'site_profile_diff.tsv')\n",
    "site_profile_diff_df = pd.read_csv(site_profile_diff_filepath, sep='\\t', header=0)\n",
    "print(f\"Read {len(site_profile_diff_df)} rows in {datetime.now() - s}.\")\n",
    "site_profile_diff_df['usp'] = [(row.user_id, row.site_id) for row in tqdm(site_profile_diff_df.itertuples(), total=len(site_profile_diff_df), desc=\"Creating USPs\")]\n",
    "site_profile_diff_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# also need to load the participant and non-participant site profile data\n",
    "\n",
    "nonparticipant_data_dir = os.path.join(cbcore.data.paths.projects_data_dir, 'recsys-peer-match', 'nonparticipant')\n",
    "with open(os.path.join(nonparticipant_data_dir, 'site_profile.pkl'), 'rb') as infile:\n",
    "    nonp_site_profiles = pickle.load(infile)\n",
    "print(len(nonp_site_profiles))\n",
    "\n",
    "with open(os.path.join(participant_data_dir, 'site_profile.pkl'), 'rb') as infile:\n",
    "    p_site_profiles = pickle.load(infile)\n",
    "print(len(p_site_profiles))\n",
    "\n",
    "site_profiles = nonp_site_profiles + p_site_profiles\n",
    "\n",
    "# create a dataframe from the site profile entires\n",
    "ds = []\n",
    "for sp in site_profiles:\n",
    "    user_id = int(sp['userId'])\n",
    "    site_id = int(sp['siteId']) if 'siteId' in sp else -1\n",
    "    # not capturing: nl\n",
    "    d = {\n",
    "        'user_id': user_id,\n",
    "        'site_id': site_id,\n",
    "        'is_creator': sp['isCreator'] if 'isCreator' in sp else None,\n",
    "        'is_primary': sp['isPrimary'] if 'isPrimary' in sp else None,\n",
    "        'role': sp['role'],\n",
    "        'is_profile_deleted': sp['isProfileDeleted'] if 'isProfileDeleted' in sp else None,\n",
    "        'is_site_deleted': sp['isSiteDeleted'] if 'isSiteDeleted' in sp else None,\n",
    "        'is_stub': sp['isStub'] if 'isStub' in sp else None,\n",
    "        'created_at': sp['createdAt'].timestamp() * 1000 if 'createdAt' in sp else 0,\n",
    "        'updated_at': sp['updatedAt'].timestamp() * 1000 if 'updatedAt' in sp else 0,\n",
    "        'n': dict(sp['n']) if 'n' in sp and sp['n'] is not None else {},\n",
    "    }\n",
    "    ds.append(d)\n",
    "\n",
    "ssite_profile_df = pd.DataFrame(ds)\n",
    "ssite_profile_df['is_participant'] = ssite_profile_df.user_id.isin(participant_user_ids)\n",
    "ssite_profile_df['usp'] = [(row.user_id, row.site_id) for row in ssite_profile_df.itertuples()]\n",
    "ssite_profile_df.sample(n=3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssite_profile_df.is_creator.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssite_profile_df.is_primary.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssite_profile_df['is_self_author'] = (ssite_profile_df.is_creator == 1)|(ssite_profile_df.is_primary == 1)|(ssite_profile_df.role == 'Organizer')\n",
    "ssite_profile_df.is_self_author.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sjournal_df = journal_df[journal_df.user_id.isin(set(ssite_profile_df.user_id))]\n",
    "len(sjournal_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "journal_usp_set = set([(row.user_id, row.site_id) for row in sjournal_df.itertuples()])\n",
    "len(journal_usp_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are a small number of USPs where this user has authored a journal on that site but is not marked as an author in the site_profile record\n",
    "pd.crosstab(ssite_profile_df.is_self_author, ssite_profile_df.usp.isin(journal_usp_set).rename(\"is_journal_author\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssite_profile_df.loc[ssite_profile_df.usp.isin(journal_usp_set), 'is_self_author'] = True\n",
    "ssite_profile_df.is_self_author.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the first_visit_df for others' sites only\n",
    "first_visit_df = ssite_profile_df[~ssite_profile_df.is_self_author]\n",
    "len(first_visit_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on journal authors and first visits, identify the set of author USPs (where the user_id is an author of site_id)\n",
    "author_usp_set = set(ssite_profile_df[ssite_profile_df.is_self_author].usp) | set(journal_df.usp)\n",
    "len(author_usp_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_user_id_set = set(ssite_profile_df[ssite_profile_df.is_self_author].user_id) | set(journal_df.user_id)\n",
    "len(author_user_id_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# author-to-author site visits\n",
    "# excludes all non-authors\n",
    "# excludes all self-visits\n",
    "site_visits = site_profile_diff_df[(site_profile_diff_df.key == 'updatedAt')&(site_profile_diff_df.user_id.isin(author_user_id_set)&(~site_profile_diff_df.usp.isin(author_usp_set)))]\n",
    "len(site_visits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_site_interactions = {\n",
    "    (row.user_id, row.site_id): [row.created_at,] for row in first_visit_df.itertuples()\n",
    "}\n",
    "len(user_site_interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOLERANCE = 1000 * 60 * 60 * 7  # 7 hours, chosen so that if there's a bug with UTC (5 hours) and DST (1 hour) we still have an hour to treat them as essentially the same time\n",
    "\n",
    "n_missing_site_profiles = 0\n",
    "n_potential_missed_visits = 0\n",
    "n_empty_curr_values = 0\n",
    "for row in tqdm(site_visits.itertuples(), total=len(site_visits)):\n",
    "    usp = (row.user_id, row.site_id)\n",
    "    if usp not in user_site_interactions:\n",
    "        # these are author interactions, but the author in question is not \"eligible\" i.e. not in the participant group or the pseudo-control group\n",
    "        # the assertion below works as expected, although it requires running cells out of order\n",
    "        # assert row.user_id not in target_user_ids\n",
    "        n_missing_site_profiles += 1\n",
    "        user_site_interactions[usp] = [float(row.old_value) * 1000,]\n",
    "    visit_list = user_site_interactions[usp]\n",
    "    last_visit = float(row.old_value) * 1000\n",
    "    curr_visit = float(row.new_value) * 1000\n",
    "    assert curr_visit > 0\n",
    "    if last_visit == 0:\n",
    "        n_empty_curr_values += 1\n",
    "    elif last_visit < visit_list[-1] - TOLERANCE:\n",
    "        logging.warning(\"updatedAt's old value was before the creation date of the site_profile or before the value from the previous snapshot.\")\n",
    "        break\n",
    "    elif last_visit > visit_list[-1] + 5000:\n",
    "        n_potential_missed_visits += 1\n",
    "        visit_list.append(last_visit)\n",
    "    assert curr_visit > last_visit\n",
    "    visit_list.append(curr_visit)\n",
    "n_missing_site_profiles, n_potential_missed_visits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visits_df = pd.DataFrame([{'usp': usp, 'visit_timestamp': visit_timestamp} for usp, visit_list in user_site_interactions.items() for visit_timestamp in visit_list])\n",
    "visits_df['user_id'] = visits_df.usp.map(lambda usp: usp[0])\n",
    "visits_df['site_id'] = visits_df.usp.map(lambda usp: usp[1])\n",
    "len(visits_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I believe this will result in bucketing by CENTRAL TIME dates\n",
    "visits_df['visit_date'] = visits_df.visit_timestamp.map(lambda ts: int(datetime.utcfromtimestamp(int(ts / 1000)).strftime('%Y%m%d')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 1.2))\n",
    "\n",
    "start_date = 20210701\n",
    "daily_visits = visits_df[visits_df.visit_date >= start_date].groupby('visit_date').usp.nunique()\n",
    "\n",
    "ax.plot(np.arange(len(daily_visits)), daily_visits)\n",
    "ax.set_title(\"Daily visits by authors to peer sites\", fontsize=10)\n",
    "def format_date(x, pos=None):\n",
    "    return f\"{(datetime.strptime(str(start_date), '%Y%m%d') + relativedelta(days=int(x))).strftime('%Y-%m-%d')}\"\n",
    "ax.xaxis.set_major_formatter(format_date)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "central_time = pytz.timezone('US/Central')\n",
    "banner_live_time = datetime.fromisoformat('2021-08-02 12:11:00').astimezone(central_time)\n",
    "banner_end_time = datetime.fromisoformat('2021-08-23 11:59:59').astimezone(central_time)\n",
    "print(f\"Banner live: {banner_live_time}\")\n",
    "print(f\"Banner end: {banner_end_time}\")\n",
    "\n",
    "first_sse_timestamp = batch_df.sse_sent_timestamp.min()\n",
    "first_sse_time = datetime.utcfromtimestamp(first_sse_timestamp / 1000)\n",
    "print(f\"First SSE sent: {first_sse_time}\")\n",
    "\n",
    "last_sse_timestamp = batch_df.sse_sent_timestamp.max()\n",
    "last_sse_time = datetime.utcfromtimestamp(last_sse_timestamp / 1000)\n",
    "print(f\"Last SSE sent: {last_sse_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-participant / pseudo-control data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the nonparticipant / pseudo-control user ids\n",
    "nonparticipant_user_ids = set()\n",
    "with open(os.path.join(cbcore.data.paths.projects_data_dir, 'recsys-peer-match', 'participant', 'nonparticipant_user_ids.txt'), 'r') as infile:\n",
    "    for line in infile:\n",
    "        if line.strip() == \"\":\n",
    "            continue\n",
    "        user_id = int(line.strip())\n",
    "        nonparticipant_user_ids.add(user_id)\n",
    "len(nonparticipant_user_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prestudy_journal_counts = journal_df[(journal_df.user_id.isin(nonparticipant_user_ids))&(journal_df.published_at <= first_sse_timestamp)].groupby('user_id').journal_id.nunique()\n",
    "print(f\"{np.sum(prestudy_journal_counts >= 3) / len(prestudy_journal_counts):.2%} meet eligibility criteria.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonparticipant_user_ids = nonparticipant_user_ids & set((prestudy_journal_counts[prestudy_journal_counts >= 3]).index)\n",
    "len(nonparticipant_user_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_user_ids = participant_user_ids | nonparticipant_user_ids\n",
    "len(target_user_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trim down the available profile data\n",
    "profile_df = profile_df[profile_df.user_id.isin(target_user_ids)].copy()\n",
    "account_creation_time_map = {row.user_id: row.createdAt for row in profile_df.itertuples()}\n",
    "len(profile_df), len(account_creation_time_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recced_usps = set([(row.participant_id, row.site_id) for row in rec_df.itertuples()])\n",
    "recced_sites = set(rec_df.site_id)\n",
    "len(recced_sites), len(recced_usps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sidebar: exploring profile_df and the account creation times\n",
    "\n",
    "Decision: the profile createdAt date is too unreliable to use as an account creation time; it's unknown which collection contains the actual initial signup info, but it's not the profile collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exploration of what is happening with the profile createdAt dates\n",
    "# we omit the ints_df, since those created_at times are unreliable (for amps)\n",
    "first_times = profile_df[['user_id', 'createdAt']].set_index('user_id').rename(columns={'createdAt': 'profile_creation'}).join([\n",
    "    journal_df[journal_df.user_id.isin(target_user_ids)][['user_id', 'published_at']].set_index('user_id').published_at.groupby('user_id').min().rename('first_journal'),\n",
    "    #ints_df[ints_df.user_id.isin(target_user_ids)][['user_id', 'created_at']].set_index('user_id').created_at.groupby('user_id').min().rename('first_int'),\n",
    "    ssite_profile_df[ssite_profile_df.user_id.isin(target_user_ids)][['user_id', 'created_at']].set_index('user_id').created_at.groupby('user_id').min().rename('first_visit')\n",
    "], how='outer')\n",
    "len(first_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_times.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(first_times == 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_times[first_times == 0] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_times.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = []\n",
    "for user_id, s in first_times.iterrows():\n",
    "    #sort = series.argsort()\n",
    "    #series[sort].index.tolist()\n",
    "    time_to_visit = s.first_visit - s.profile_creation\n",
    "    time_to_journal = s.first_journal - s.profile_creation\n",
    "    ds.append({\n",
    "        'user_id': user_id,\n",
    "        'time_to_visit': time_to_visit,\n",
    "        'time_to_journal': time_to_journal,\n",
    "        'first_time': s[s.argsort()].index.tolist()[0]\n",
    "    })\n",
    "time_df = pd.DataFrame(ds)\n",
    "time_df.first_time.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(10, 2))\n",
    "\n",
    "ax = axes[0]\n",
    "ax.hist(time_df.time_to_visit / 1000 / 60 / 60 / 24 / 365, bins=20, log=True)\n",
    "ax.set_title(\"site_profile\")\n",
    "ax.set_xlabel(\"first site_profile creation - profile creation (years)\")\n",
    "ax.set_ylabel(\"Number of target users\")\n",
    "\n",
    "ax = axes[1]\n",
    "ax.hist(time_df.time_to_journal / 1000 / 60 / 60 / 24 / 365, bins=20, log=True)\n",
    "ax.set_title(\"journal\")\n",
    "ax.set_xlabel(\"first journal creation - profile creation (years)\")\n",
    "ax.set_ylabel(\"Number of target users\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data modeling\n",
    "\n",
    "Useful docs: https://www.statsmodels.org/stable/api.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scratchpad cell\n",
    "one_day = 1000 * 60 * 60 * 24\n",
    "thirty_days = one_day * 30\n",
    "time_window = thirty_days\n",
    "\n",
    "end_timestamp = first_sse_timestamp\n",
    "start_timestamp = end_timestamp - time_window\n",
    "\n",
    "exclude_recommended_sites = False\n",
    "postfix=\"\"\n",
    "\n",
    "df = pd.DataFrame(index=pd.Series(sorted(target_user_ids)))\n",
    "\n",
    "#n_updates_total = journal_df[(journal_df.published_at <= end_timestamp)].groupby('user_id').journal_oid.nunique().rename(\"n_updates_total\" + postfix)\n",
    "n_updates = journal_df[(journal_df.published_at >= start_timestamp)&(journal_df.published_at <= end_timestamp)].groupby('user_id').journal_oid.nunique().rename(\"n_updates\" + postfix)\n",
    "\n",
    "sints_df = ints_df[(ints_df.created_at >= start_timestamp)&(ints_df.created_at <= end_timestamp)&(ints_df.user_id.isin(target_user_ids))]\n",
    "if exclude_recommended_sites:\n",
    "    sints_df = sints_df[sints_df.usp.isin(recced_usps)]\n",
    "is_self_interaction = sints_df.usp.isin(author_usp_set)\n",
    "n_interactionswith = sints_df[~is_self_interaction]\\\n",
    "    .groupby(['user_id', 'site_id']).interaction_oid.nunique()\n",
    "n_text_interactionswith = sints_df[(~is_self_interaction)&(~sints_df.interaction_type.str.startswith(\"amp\"))]\\\n",
    "    .groupby(['user_id', 'site_id']).interaction_oid.nunique()\n",
    "\n",
    "n_interactionswith_self = sints_df[is_self_interaction]\\\n",
    "    .groupby(['user_id', 'site_id']).interaction_oid.nunique()\n",
    "n_text_interactionswith_self = sints_df[(is_self_interaction)&(~sints_df.interaction_type.str.startswith(\"amp\"))]\\\n",
    "    .groupby(['user_id', 'site_id']).interaction_oid.nunique()\n",
    "\n",
    "n_interactions = n_interactionswith.groupby('user_id').sum().rename(\"n_interactions\" + postfix)\n",
    "n_sites_interactedwith = n_interactionswith.groupby('user_id').count().rename(\"n_sites_interactedwith\" + postfix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_window_features(start_timestamp, end_timestamp, target_user_ids, postfix, exclude_recommended_sites=False):\n",
    "    df = pd.DataFrame(index=pd.Series(sorted(target_user_ids)))\n",
    "        \n",
    "    #n_updates_total = journal_df[(journal_df.published_at <= end_timestamp)].groupby('user_id').journal_oid.nunique().rename(\"n_updates_total\" + postfix)\n",
    "    n_updates = journal_df[(journal_df.published_at >= start_timestamp)&(journal_df.published_at <= end_timestamp)].groupby('user_id').journal_oid.nunique().rename(\"n_updates\" + postfix)\n",
    "    \n",
    "    sints_df = ints_df[(ints_df.created_at >= start_timestamp)&(ints_df.created_at <= end_timestamp)&(ints_df.user_id.isin(target_user_ids))]\n",
    "    if exclude_recommended_sites:\n",
    "        sints_df = sints_df[~sints_df.usp.isin(recced_usps)]\n",
    "    is_self_interaction = sints_df.usp.isin(author_usp_set)\n",
    "    n_interactionswith = sints_df[~is_self_interaction]\\\n",
    "        .groupby(['user_id', 'site_id']).interaction_oid.nunique()\n",
    "    n_text_interactionswith = sints_df[(~is_self_interaction)&(~sints_df.interaction_type.str.startswith(\"amp\"))]\\\n",
    "        .groupby(['user_id', 'site_id']).interaction_oid.nunique()\n",
    "\n",
    "    n_interactionswith_self = sints_df[is_self_interaction]\\\n",
    "        .groupby(['user_id', 'site_id']).interaction_oid.nunique()\n",
    "    n_text_interactionswith_self = sints_df[(is_self_interaction)&(~sints_df.interaction_type.str.startswith(\"amp\"))]\\\n",
    "        .groupby(['user_id', 'site_id']).interaction_oid.nunique()\n",
    "        \n",
    "    # note: we can use sum() and count() here because this is a series; sum adds the number of interactions, count is the number of rows after removing the second level of the index (site_id)\n",
    "    n_interactions = n_interactionswith.groupby('user_id').sum().rename(\"n_interactions\" + postfix)\n",
    "    n_sites_interactedwith = n_interactionswith.groupby('user_id').count().rename(\"n_sites_interactedwith\" + postfix)    \n",
    "    n_text_interactions = n_text_interactionswith.groupby('user_id').sum().rename(\"n_text_interactions\" + postfix)\n",
    "    n_sites_interactedwith_text = n_text_interactionswith.groupby('user_id').count().rename(\"n_sites_interactedwith_text\" + postfix)\n",
    "    n_self_interactions = n_interactionswith_self.groupby('user_id').sum().rename(\"n_self_interactions\" + postfix)\n",
    "    n_self_sites_interactedwith = n_interactionswith_self.groupby('user_id').count().rename(\"n_self_sites_interactedwith\" + postfix)\n",
    "        \n",
    "    sfirst_visit_df = first_visit_df[(first_visit_df.created_at >= start_timestamp)&(first_visit_df.created_at <= end_timestamp)]\n",
    "    if exclude_recommended_sites:\n",
    "        sfirst_visit_df = sfirst_visit_df[~sfirst_visit_df.usp.isin(recced_usps)]\n",
    "    n_first_visits = sfirst_visit_df.groupby('user_id').created_at.count().rename(\"n_first_visits\" + postfix)\n",
    "    \n",
    "    svisits_df = visits_df[(visits_df.visit_timestamp >= start_timestamp)&(visits_df.visit_timestamp <= end_timestamp)&(visits_df.user_id.isin(target_user_ids))]\n",
    "    if exclude_recommended_sites:\n",
    "        svisits_df = svisits_df[~svisits_df.usp.isin(recced_usps)]\n",
    "    # how many days did each user visit another author's site?\n",
    "    # NOTE: n_days_visited and n_sites_repeat_visisted is only valid within certain date ranges, because it depends on the site_profile snapshots\n",
    "    n_days_visited = svisits_df.groupby('user_id').visit_date.nunique().rename(\"n_days_visited\" + postfix)\n",
    "    n_repeat_visits = svisits_df.groupby(['user_id', 'site_id']).visit_timestamp.count() - 1\n",
    "    n_sites_repeat_visited = n_repeat_visits[n_repeat_visits > 0].groupby('user_id').count().rename(\"n_sites_repeat_visited\" + postfix)\n",
    "    #n_sites_visited = svisits_df.groupby('user_id').site_id.nunique().rename(\"n_sites_visited\" + postfix)\n",
    "    # assert np.all(n_sites_visited == n_first_visits)\n",
    "    \n",
    "    \n",
    "    # compute prestudy specific features\n",
    "    first_journal_update_timestamps = journal_df.groupby('user_id').created_at.min()\n",
    "    time_since_first_journal_update = (end_timestamp - first_journal_update_timestamps).rename(\"time_since_first_journal_update\" + postfix) / 1000 / 60 / 60 / 24  # in days\n",
    "    if np.any(time_since_first_journal_update[time_since_first_journal_update.index.isin(target_user_ids)] < 0):\n",
    "        logging.warning(\"Some target_user_ids have a first journal update time that's after end_timestamp; is that expected?\")\n",
    "        \n",
    "    #signup_timestamps = df.index.map(lambda user_id: account_creation_time_map[user_id]).to_series(index=df.index, name=\"signup_timestamps\")\n",
    "    #time_since_signup = (end_timestamp - signup_timestamps).rename(\"time_since_signup\" + postfix) / 1000 / 60 / 60 / 24  # in days\n",
    "    \n",
    "    df = df.join([n_updates, \n",
    "                  n_sites_interactedwith, \n",
    "                  n_self_sites_interactedwith, \n",
    "                  n_sites_interactedwith_text, \n",
    "                  n_interactions, \n",
    "                  n_self_interactions,\n",
    "                  n_text_interactions,\n",
    "                  n_first_visits,\n",
    "                  n_days_visited,\n",
    "                  n_sites_repeat_visited,\n",
    "                  time_since_first_journal_update,\n",
    "    ])\n",
    "    \n",
    "    df = df.fillna(value=0)\n",
    "\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_timestamp = first_sse_timestamp\n",
    "start_timestamp = 0\n",
    "total_df = compute_window_features(start_timestamp, end_timestamp, target_user_ids, \"\")\n",
    "len(total_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df['average_daily_updates'] = total_df.n_updates / total_df.time_since_first_journal_update\n",
    "total_df['is_participant'] = total_df.index.isin(participant_user_ids).astype(int)\n",
    "total_df.is_participant.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df.groupby('is_participant').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df.groupby('is_participant').agg(['median', 'mean', 'std', 'min', 'max']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretty_name_map = {\n",
    "    'time_since_first_journal_update': \"Author tenure (days)\",\n",
    "    'n_updates': \"Journal updates\",\n",
    "    'n_first_visits': \"Peer site visits\",\n",
    "    'n_sites_interactedwith': \"Peer site initiations\", \n",
    "    'n_interactions': \"Peer site interactions\", \n",
    "}\n",
    "cols = pretty_name_map.keys()\n",
    "for col in cols:\n",
    "    t = total_df.loc[total_df.is_participant == 1, col]\n",
    "    c = total_df.loc[total_df.is_participant == 0, col]\n",
    "    \n",
    "    tstat, p = scipy.stats.ttest_ind(t, c, equal_var=False)\n",
    "    diff = t.mean() - c.mean()\n",
    "    #p *= len(cols)  # bonferroni correction\n",
    "    \n",
    "    ustat, up = scipy.stats.mannwhitneyu(t, c)\n",
    "    #up *= len(cols)\n",
    "    \n",
    "    threshold = 0.005\n",
    "    \n",
    "    print(f\"{pretty_name_map[col]:>25} & {t.median():.0f} & {t.mean():.1f} ({t.std():.1f}) & {c.median():.0f} & {c.mean():.1f} ({c.std():.1f}) & {diff:.1f}{'*' if p < threshold else ''} & {up:.0e}{'*' if up < threshold else ''} \\\\\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make little histograms\n",
    "# inspired from: https://github.com/levon003/icwsm-cancer-journeys/blob/master/identify_candidate_sites/ClassificationCandidateSites.ipynb\n",
    "\n",
    "cols = pretty_name_map.keys()\n",
    "for col in cols:\n",
    "    t = total_df.loc[total_df.is_participant == 1, col]\n",
    "    c = total_df.loc[total_df.is_participant == 0, col]\n",
    "    \n",
    "    d = t\n",
    "    fig, ax = plt.subplots(figsize=(1, 0.3), squeeze=True)\n",
    "    nunique = d[d < np.quantile(d, 0.9)].nunique()\n",
    "    if nunique < 30:\n",
    "        bins = np.arange(0, 30)\n",
    "        p = d\n",
    "    else:\n",
    "        bins=30\n",
    "        p = d[d < np.quantile(d, 0.9)]\n",
    "    _, bins, _ = ax.hist(p, bins=bins, align=\"left\", color=\"black\", density=True)\n",
    "    ax.hist(c, bins=bins, align=\"left\", color=\"gray\", density=True)\n",
    "    plt.tight_layout()\n",
    "    print(col, nunique)\n",
    "    \n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.margins(0,0)\n",
    "    plt.gca().xaxis.set_major_locator(plt.NullLocator())\n",
    "    plt.gca().yaxis.set_major_locator(plt.NullLocator())\n",
    "    \n",
    "    plt.tight_layout(pad=0)\n",
    "    plt.subplots_adjust(top = 0.4, bottom = 0, right = 1, left = 0, \n",
    "                hspace = 0, wspace = 0)\n",
    "\n",
    "    bbox = matplotlib.transforms.Bbox.from_bounds(0,0,1,0.2)\n",
    "    image_shortfilename = f\"{col}_hist_small.pdf\"\n",
    "    image_filename = os.path.join(figures_dir, image_shortfilename)\n",
    "    plt.savefig(image_filename, format='pdf', dpi=200, pad_inches=0, bbox_inches=bbox) #, transparent=True)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df[cols].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smf.logit(formula=\"is_participant ~ n_updates + n_first_visits + n_sites_interactedwith + n_interactions + np.log(time_since_first_journal_update)\", data=total_df)\n",
    "res = model.fit(disp=0)\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre- vs Post- modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_day = 1000 * 60 * 60 * 24\n",
    "thirty_days = one_day * 30\n",
    "ninety_days = one_day * 90\n",
    "time_window = ninety_days\n",
    "\n",
    "# pre-study window features\n",
    "end_timestamp = first_sse_timestamp\n",
    "start_timestamp = end_timestamp - time_window\n",
    "prestudy_df = compute_window_features(start_timestamp, end_timestamp, target_user_ids, \"_prestudy\")\n",
    "\n",
    "# post-study window features\n",
    "start_timestamp = last_sse_timestamp\n",
    "end_timestamp = start_timestamp + time_window\n",
    "poststudy_df = compute_window_features(start_timestamp, end_timestamp, target_user_ids, \"_poststudy\", exclude_recommended_sites=True)\n",
    "\n",
    "df = pd.merge(prestudy_df, poststudy_df, left_index=True, right_index=True)\n",
    "\n",
    "df['is_participant'] = df.index.isin(participant_user_ids).astype(int)\n",
    "\n",
    "print(len(df))\n",
    "df.sample(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('is_participant').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation matrix between variables\n",
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the correlation matrix\n",
    "corr = df.corr()\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(11, 10))\n",
    "ms = ax.matshow(corr)\n",
    "\n",
    "for i in range(corr.shape[0]):\n",
    "    for j in range(corr.shape[1]):\n",
    "        ax.text(i, j, f\"{corr.iloc[i, j]:.2f}\", ha='center', va='center', fontsize=8)\n",
    "\n",
    "plt.xticks(range(df.select_dtypes(['number']).shape[1]), df.select_dtypes(['number']).columns, fontsize=8, rotation=20, ha='left')\n",
    "plt.yticks(range(df.select_dtypes(['number']).shape[1]), df.select_dtypes(['number']).columns, fontsize=8)\n",
    "cb = fig.colorbar(ms, ax=ax, shrink=0.7)\n",
    "cb.ax.tick_params(labelsize=8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lots of zero-counts...\n",
    "(df == 0).mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stddev is larger than means for several variables, which suggests over-dispersion\n",
    "# https://stats.oarc.ucla.edu/r/dae/negative-binomial-regression/\n",
    "df.groupby('is_participant').agg(['mean', 'std'])  # 'min', 'max'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# participants have fewer post-study updates compared to pre-study updates\n",
    "sdf = df[df.is_participant == 1]\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "# could optionally add some jitter:\n",
    "# + (np.random.random(len(sdf)) / 10)\n",
    "#ax.scatter(sdf.n_updates_prestudy + 1, sdf.n_updates_poststudy + 1, alpha=0.2, color='black')\n",
    "#hb = ax.hexbin(sdf.n_updates_prestudy, sdf.n_updates_poststudy, gridsize=10, bins='log', mincnt=0, extent=(0, 10, 0, 10))\n",
    "#bins = np.arange()\n",
    "counts, hbins, vbins, hb = ax.hist2d(sdf.n_updates_prestudy, sdf.n_updates_poststudy, \n",
    "    bins=[np.arange(0, np.max(sdf.n_updates_prestudy)+1), np.arange(0, np.max(sdf.n_updates_poststudy)+1)],\n",
    "    cmin=1,  norm=matplotlib.colors.LogNorm(), alpha=0.4)\n",
    "steps = np.arange(0, min(np.max(sdf.n_updates_prestudy)+1, np.max(sdf.n_updates_poststudy)+1))\n",
    "plt.step(steps, steps, color='darkgray')\n",
    "plt.step(steps, steps - 1, color='darkgray')\n",
    "for i in range(counts.shape[0]):\n",
    "    for j in range(counts.shape[1]):\n",
    "        if counts[i, j] > 0:\n",
    "            ax.text(hbins[i] + ((hbins[1] - hbins[0]) / 2), vbins[j] + ((vbins[1] - vbins[0]) / 2), \n",
    "                    f\"{counts[i, j]:.0f}\", \n",
    "                    ha='center', va='center', fontsize=8)\n",
    "#fig.colorbar(hb, ax=ax)\n",
    "#ax.set_xscale('log')\n",
    "#ax.set_yscale('log')\n",
    "ax.set_xlabel(\"# pre-study updates\")\n",
    "ax.set_ylabel(\"# post-study updates\")\n",
    "ax.set_title(\"Participant pre- and post-study Journal update counts\", fontsize=8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# difference between pre- and post-study updates for authors who had at least 1 update in the measurement period\n",
    "# participants had fewer updates in 80% of cases... compared to only 70% among control authors\n",
    "sdf = df[(df.n_updates_prestudy > 0)|(df.n_updates_poststudy > 0)]\n",
    "pd.crosstab(\n",
    "    sdf.is_participant, \n",
    "    (sdf.n_updates_poststudy - sdf.n_updates_prestudy)\\\n",
    "        .map(lambda diff: 'fewer' if diff < 0 else 'equal' if diff == 0 else 'more')\\\n",
    "        .rename(\"post - pre n_updates\"),\n",
    "    margins=True,\n",
    "    normalize='index',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = \"\"\"\n",
    "n_updates_poststudy ~ n_updates_prestudy\n",
    "    + is_participant \n",
    "    + np.log(time_since_first_journal_update_prestudy)\n",
    "    + n_first_visits_prestudy\n",
    "    + n_sites_repeat_visited_prestudy\n",
    "    + n_sites_interactedwith_prestudy\n",
    "    + n_interactions_prestudy\n",
    "    + n_self_sites_interactedwith_prestudy\n",
    "    + n_self_interactions_prestudy\n",
    "    + n_days_visited_prestudy\n",
    "\n",
    "\"\"\"\n",
    "md = smf.ols(formula=formula, data=df)\n",
    "res = md.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stats.oarc.ucla.edu/r/dae/negative-binomial-regression/\n",
    "formula = \"\"\"\n",
    "n_updates_poststudy ~ n_updates_prestudy \n",
    "    + is_participant \n",
    "    + np.log(time_since_first_journal_update_prestudy)\n",
    "    + n_first_visits_prestudy\n",
    "    + n_sites_interactedwith_prestudy\n",
    "    + n_interactions_prestudy\n",
    "    + n_days_visited_prestudy\n",
    "    + n_sites_repeat_visited_prestudy\n",
    "\"\"\"\n",
    "md = smf.negativebinomial(formula=formula, data=df)\n",
    "res = md.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the negative binomial model, these are incidence rate ratios\n",
    "# 1 additional pre-study update is assocaited with a 19% increase in the number of post-study updates\n",
    "# being a participant (vs the control group) is associated with a 96% increase in the number of post-study updates...\n",
    "np.exp(res.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the design matrix is stored md.exog\n",
    "md.exog.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparing two OLS (linear regression) models\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "\n",
    "for use_interaction in [0, 1]:\n",
    "    if use_interaction == 1:\n",
    "        formula = 'n_updates_prestudy + is_participant + is_participant*n_updates_prestudy'\n",
    "    else:\n",
    "        formula = 'n_updates_prestudy + is_participant'\n",
    "    md = smf.ols(formula='n_updates_poststudy ~ ' + formula, data=df)\n",
    "    res = md.fit()\n",
    "    \n",
    "    for is_participant in [0, 1]:\n",
    "        xs = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "        ys = []\n",
    "        for nu in xs:\n",
    "            \n",
    "            # note: this approach correctly creates a design matrix from a formula, but is not necessary: res.predict() will do the appropriate transformations for you\n",
    "            #import patsy\n",
    "            #X = patsy.dmatrix(formula, pd.DataFrame([{'is_participant': is_participant, 'n_updates_prestudy': nu}]))\n",
    "            \n",
    "            # create a dataframe with the appropriate variables in order to do prediction\n",
    "            X = pd.DataFrame([{'is_participant': is_participant, 'n_updates_prestudy': nu}])\n",
    "            pred = res.predict(X).iloc[0]\n",
    "\n",
    "            ys.append(pred)\n",
    "            l1 = 'Control' if is_participant == 0 else 'Treatment'\n",
    "            l2 = 'NoInt' if use_interaction == 0 else 'Int'\n",
    "        plt.plot(xs, ys, label=l1 + \" \" + l2)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit_ip_f(df, use_I=False):\n",
    "    \"\"\"\n",
    "    Create the f(y|X) part of IP weights using logistic regression\n",
    "    \n",
    "    Adapted from https://github.com/jrfiedler/causal_inference_python_code/blob/master/chapter12.ipynb\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : Pandas DataFrame\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Numpy array of IP weights\n",
    "    \n",
    "    \"\"\"\n",
    "    formula = \"\"\"\n",
    "    is_participant ~ n_updates_prestudy  \n",
    "        + np.log(time_since_first_journal_update_prestudy)\n",
    "        + n_first_visits_prestudy\n",
    "        + n_sites_interactedwith_prestudy\n",
    "        + n_interactions_prestudy\n",
    "        + n_days_visited_prestudy\n",
    "        + n_sites_repeat_visited_prestudy\n",
    "        + n_self_sites_interactedwith_prestudy\n",
    "        + n_self_interactions_prestudy\n",
    "    \"\"\"\n",
    "    model = smf.logit(formula=formula, data=df)\n",
    "    res = model.fit(disp=0)\n",
    "    #print(res.summary().tables[1])\n",
    "    weights = np.zeros(len(df))\n",
    "    weights[df.is_participant == 1] = res.predict(df[df.is_participant == 1])\n",
    "    weights[df.is_participant == 0] = (1 - res.predict(df[df.is_participant == 0]))\n",
    "    return weights\n",
    "\n",
    "def produce_ci_estimates(df, outcome):\n",
    "    block2 = df.copy()\n",
    "    block2.is_participant = 0\n",
    "    block3 = df.copy()\n",
    "    block3.is_participant = 1\n",
    "    \n",
    "    formula = outcome + \"\"\"\n",
    "     ~ n_updates_prestudy \n",
    "        + is_participant \n",
    "        + np.log(time_since_first_journal_update_prestudy)\n",
    "        + n_first_visits_prestudy\n",
    "        + n_sites_interactedwith_prestudy\n",
    "        + n_interactions_prestudy\n",
    "        + n_days_visited_prestudy\n",
    "        + n_sites_repeat_visited_prestudy\n",
    "        + n_self_sites_interactedwith_prestudy\n",
    "        + n_self_interactions_prestudy\n",
    "    \"\"\"\n",
    "    \n",
    "    # basic regression estimates\n",
    "    # that \"adjust for\" confounders\n",
    "    # plus standardization\n",
    "    md = smf.ols(formula=formula, data=df)\n",
    "    res = md.fit(full_output=True)\n",
    "    \n",
    "    print(res.history.__dict__)\n",
    "    print(res.params.mle_retvals[\"converged\"])\n",
    "    modeled_observational_effect = res.params.is_participant\n",
    "    block2_pred = res.predict(block2)\n",
    "    block3_pred = res.predict(block3)\n",
    "    standardized_model_error = res.rsquared\n",
    "    standardized_effect = block3_pred.mean() - block2_pred.mean()\n",
    "    \n",
    "    # IP weighting and the Bang-Robins doubly robust (DR) estimator\n",
    "    weights = logit_ip_f(df)\n",
    "    weights = 1 / weights\n",
    "    wls = smf.wls(formula=f'{outcome} ~ is_participant', data=df, weights=weights)\n",
    "    res = wls.fit(disp=0)\n",
    "    ip_weighted_effect = res.params.is_participant\n",
    "    \n",
    "    block1 = df.copy()\n",
    "    block1['R'] = weights\n",
    "    block1.loc[block1.is_participant == 0, 'R'] *= -1\n",
    "    md = smf.ols(formula=formula + \"+ R\", data=block1)\n",
    "    res = md.fit()\n",
    "    block2 = block1.copy()\n",
    "    block2.is_participant = 0\n",
    "    block3 = block1.copy()\n",
    "    block3.is_participant = 1\n",
    "    block2_pred = res.predict(block2)\n",
    "    block3_pred = res.predict(block3)\n",
    "    dr_effect = block3_pred.mean() - block2_pred.mean()\n",
    "    \n",
    "    return {\n",
    "        'modeled_observational_diff': modeled_observational_effect,\n",
    "        'standardized_diff': standardized_effect,\n",
    "        'standardized_model_error': standardized_model_error,\n",
    "        'ip_weighted_diff': ip_weighted_effect,\n",
    "        'dr_diff': dr_effect,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "produce_ci_estimates(df, \"n_updates_poststudy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "produce_ci_estimates(df, \"n_sites_interactedwith_poststudy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "produce_ci_estimates(df, \"n_sites_repeat_visited_poststudy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "produce_ci_estimates(df, \"n_first_visits_poststudy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "produce_ci_estimates(df, \"n_interactions_poststudy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "produce_ci_estimates(df, \"n_days_visited_poststudy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_columns = [\n",
    "    'n_updates_poststudy', \n",
    "    'n_first_visits_poststudy', \n",
    "    'n_sites_repeat_visited_poststudy', \n",
    "    'n_sites_interactedwith_poststudy', \n",
    "    'n_interactions_poststudy', \n",
    "    'n_days_visited_poststudy',\n",
    "]\n",
    "true_diffs = []\n",
    "for col in outcome_columns:\n",
    "    try:\n",
    "        ests = produce_ci_estimates(df, col)\n",
    "    except:\n",
    "        continue\n",
    "    diff = {}\n",
    "    diff['outcome'] = col\n",
    "    diff['diff_raw'] = df.loc[df.is_participant==1, col].mean() - df.loc[df.is_participant==0, col].mean()\n",
    "    diff['diff_ols'] = ests['modeled_observational_diff']\n",
    "    diff['diff_dr'] = ests['dr_diff']\n",
    "    diff['ols_rsq'] = ests['standardized_model_error']\n",
    "    true_diffs.append(diff)\n",
    "true_diff_df = pd.DataFrame(true_diffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the bootstrapped estimates to make sure nothing absurd is happening\n",
    "fig, axes = plt.subplots(len(outcome_columns), 1, figsize=(5, 10))\n",
    "\n",
    "for i, col in enumerate(outcome_columns):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    diffs = diff_df[diff_df.outcome == col]\n",
    "    ds = diffs['diff_dr']\n",
    "    m = ds.median()\n",
    "    u = ds.quantile(upperq)\n",
    "    l = ds.quantile(lowerq)\n",
    "    \n",
    "    ax.hist(ds, bins=np.linspace(l, u))\n",
    "    print(f\"{col:>40} {m:.2f} [{l:.2f} , {u:.2f}]\")\n",
    "    \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretty_name_map = {\n",
    "    'n_updates_poststudy': \"Journal updates\",\n",
    "    'n_first_visits_poststudy': \"Peer site visits\",\n",
    "    'n_sites_repeat_visited_poststudy': \"Repeat peer site visits\",\n",
    "    'n_sites_interactedwith_poststudy': \"Peer site initiations\", \n",
    "    'n_interactions_poststudy': \"Peer site interactions\", \n",
    "    'n_days_visited_poststudy': \"# days visiting peers\",\n",
    "}\n",
    "outcome_columns = [\n",
    "    'n_updates_poststudy', \n",
    "    'n_first_visits_poststudy', \n",
    "#    'n_sites_repeat_visited_poststudy', \n",
    "#    'n_sites_interactedwith_poststudy', \n",
    "    'n_interactions_poststudy', \n",
    "    'n_days_visited_poststudy',\n",
    "]\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5.4, 2))\n",
    "\n",
    "lowerq = 0.025\n",
    "upperq = 0.975\n",
    "\n",
    "xticks = []\n",
    "xticklabels = []\n",
    "\n",
    "#ax.axhline(0, color='gray', alpha=0.5, zorder=-1, linestyle=\"--\")\n",
    "ax.axhline(0, color='black', alpha=1, zorder=-1, linestyle=\"-\", linewidth=0.75)\n",
    "\n",
    "i = 0\n",
    "for col in outcome_columns:\n",
    "    #if col == \"n_interactions_poststudy\" or col == \"n_days_visited_poststudy\":\n",
    "    #    continue\n",
    "    #xticks.append(i + 1)\n",
    "    #xticklabels.append(f\"{pretty_name_map[col]}\")\n",
    "    xticks.extend([i, i+1, i+2])\n",
    "    xticklabels.extend([\"Raw\", f\"OLS\\n{pretty_name_map[col]}\", \"DR\"])\n",
    "    \n",
    "    diffs = diff_df[diff_df.outcome == col]\n",
    "    for , diff_col in enumerate(['diff_raw', 'diff_ols', 'diff_dr']):\n",
    "        ds = diffs[diff_col]\n",
    "        estimate = true_diff_df.loc[true_diff_df.outcome == col, diff_col].iloc[0]\n",
    "        m = ds.median()\n",
    "        u = ds.quantile(upperq)\n",
    "        l = ds.quantile(lowerq)\n",
    "        uerr = np.abs(u - estimate)\n",
    "        lerr = np.abs(l - estimate)\n",
    "        print(f\"{col:>40} {diff_col} {i+j}, true={estimate:.2f}; bs={m:.2f} [{l:.2f},{u:.2f}], {uerr:.2f}, {lerr:.2f} {estimate - m:.3f}\")\n",
    "        ax.errorbar(i+j, estimate, yerr=[[uerr,],[lerr,]], color='darkgray', capsize=4, zorder=1)\n",
    "        \n",
    "        ax.scatter(i+j, estimate, color='black', zorder=2, marker='s', s=8)\n",
    "        ax.text(i+j+0.11, estimate, f\"{estimate:.1f}\", ha='left', va='center' if np.abs(estimate) > 0.1 else 'bottom', fontsize=7)\n",
    "    \n",
    "    i += 3.4\n",
    "    \n",
    "ax.set_xticks(xticks)\n",
    "ax.set_xticklabels(xticklabels)\n",
    "ax.tick_params(axis='both', which='major', labelsize=7)\n",
    "ax.set_yticks([-4, -2, 0, 2, 4, 6])\n",
    "ax.set_ylabel(\"Participation Effect\", fontsize=7)\n",
    "\n",
    "#plt.margins(0,0)\n",
    "#plt.gca().xaxis.set_major_locator(plt.NullLocator())\n",
    "#plt.gca().yaxis.set_major_locator(plt.NullLocator())\n",
    "\n",
    "plt.tight_layout(pad=0.5)\n",
    "#plt.subplots_adjust(top = 0.4, bottom = 0, right = 1, left = 0, hspace = 0, wspace = 0)\n",
    "\n",
    "#bbox = matplotlib.transforms.Bbox.from_bounds(0,0,1,0.2)\n",
    "image_shortfilename = f\"participant_outcome_estimates.pdf\"\n",
    "image_filename = os.path.join(figures_dir, image_shortfilename)\n",
    "plt.savefig(image_filename, format='pdf', dpi=200, pad_inches=0) #, bbox_inches=bbox) #, transparent=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(5.4, 2))\n",
    "\n",
    "diff_col = 'ols_rsq'\n",
    "xticks = []\n",
    "\n",
    "xticklabels = []\n",
    "i = 0\n",
    "for col in outcome_columns:\n",
    "    \n",
    "    xticks.extend([i])\n",
    "    xticklabels.extend([pretty_name_map[col]])\n",
    "    ds = diffs[diff_col]\n",
    "    estimate = true_diff_df.loc[true_diff_df.outcome == col, diff_col].iloc[0]\n",
    "    m = ds.median()\n",
    "    u = ds.quantile(upperq)\n",
    "    l = ds.quantile(lowerq)\n",
    "    uerr = np.abs(u - estimate)\n",
    "    lerr = np.abs(l - estimate)\n",
    "    print(f\"{col:>40} {diff_col} {i+j}, true={estimate:.2f}; bs={m:.2f} [{l:.2f},{u:.2f}], {uerr:.2f}, {lerr:.2f} {estimate - m:.3f}\")\n",
    "    ax.errorbar(i, estimate, yerr=[[uerr,],[lerr,]], color='darkgray', capsize=4, zorder=1)\n",
    "\n",
    "    ax.scatter(i, estimate, color='black', zorder=2, marker='s', s=8)\n",
    "    ax.text(i+0.11, estimate, f\"{estimate:.1f}\", ha='left', va='center' if np.abs(estimate) > 0.1 else 'bottom', fontsize=7)\n",
    "    i += 1\n",
    "ax.set_xticks(xticks)\n",
    "ax.set_xticklabels(xticklabels)\n",
    "ax.tick_params(axis='both', which='major', labelsize=7)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (shared-conda)",
   "language": "python",
   "name": "shared-conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
