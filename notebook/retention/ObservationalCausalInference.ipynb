{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observational Causal Inference:\n",
    "===\n",
    "\n",
    "IP weighting, stratification, and doubly robust estimators\n",
    "\n",
    "Links:\n",
    " - Book: https://www.hsph.harvard.edu/miguel-hernan/causal-inference-book/\n",
    " - Code (Python, statsmodels): https://github.com/jrfiedler/causal_inference_python_code\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.rcParams['figure.dpi'] = 100\n",
    "#matplotlib.rcParams['font.family'] = \"serif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_synthetic_data(\n",
    "    n_total=1800,\n",
    "    n_control=300,\n",
    "    n_treatment=100,\n",
    "):\n",
    "    \"\"\"\n",
    "    Hypothetical population of users who will enroll in a study.\n",
    "    \n",
    "    The outcome is a continuous count: y_post\n",
    "    Variables:\n",
    "     - y_pre : Previous level of the primary outcome pre-treatment\n",
    "     - cont1: Continuous variable\n",
    "     - b1: Binary variable\n",
    "     - cat1: Three-level categorical variable\n",
    "     - I: an unobserved variable representing *interest in enrolling*\n",
    "     - E: 1 if the user *chose to enroll* else 0\n",
    "     - T: 1 if the user was treated else 0\n",
    "    \"\"\"\n",
    "    n_enrolled = n_control + n_treatment\n",
    "    \n",
    "    I = np.random.beta(0.5, 2, size=n_total)\n",
    "    \n",
    "    # identify enrolled users\n",
    "    p = I + np.random.beta(0.5, 2, size=n_total) / 5\n",
    "    p = p / p.sum()\n",
    "    E_inds = np.random.choice(np.arange(n_total), size=n_enrolled, replace=False, p=p)\n",
    "    E = np.zeros(n_total)\n",
    "    E[E_inds] = 1\n",
    "    \n",
    "    T_inds = np.random.choice(E_inds, size=n_treatment, replace=False)\n",
    "    Tr = np.zeros(n_total)\n",
    "    Tr[T_inds] = 1\n",
    "    assert Tr.sum() == n_treatment\n",
    "    \n",
    "    #y_pre = np.random.poisson(lam=0.4, size=n_total)\n",
    "    #lam_post = ((y_pre + 0.1) / (y_pre.max() + 0.1)) * 0.4\n",
    "    #y_post = np.random.poisson(lam=lam_post, size=len(y_pre))\n",
    "    \n",
    "    y_pre = np.random.exponential(1, size=n_total) + np.random.normal(loc=I, scale=0.5, size=n_total)\n",
    "    y_pre = np.maximum(y_pre, 0).round()\n",
    "    \n",
    "    y_post = y_pre * 0.5\n",
    "    y_post += np.random.normal(loc=y_post, scale=0.5, size=n_total)\n",
    "    \n",
    "    #y_post = y_pre * 0.9 + 2 * np.random.normal(loc=-0.5, size=n_total)\n",
    "    true_effect = 1\n",
    "    y_post[Tr == 1] += np.random.normal(loc=true_effect, scale=0.1, size=n_treatment)\n",
    "    #interest_effect = 1\n",
    "    #y_post += 10 * np.random.normal(loc=I, scale=0.4, size=n_total)\n",
    "    y_post = np.maximum(y_post, 0).round()\n",
    "    \n",
    "    \n",
    "    df = pd.DataFrame.from_dict({\n",
    "        'E': E,\n",
    "        'I': I,\n",
    "        'p_enroll': p,\n",
    "        'y_pre': y_pre,\n",
    "        'y_post': y_post,\n",
    "        'Tr': Tr,\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = get_synthetic_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_synthetic_data(\n",
    "    n_total=1800,\n",
    "    n_control=300,\n",
    "    n_treatment=100,\n",
    "):\n",
    "    n_enrolled = n_control + n_treatment\n",
    "    \n",
    "    I = np.random.normal(size=n_total)\n",
    "    \n",
    "    # identify enrolled users\n",
    "    p = I + np.random.normal(loc=0, scale=0.1, size=n_total)\n",
    "    p = (p - p.min())\n",
    "    p = p / p.sum()\n",
    "    E_inds = np.random.choice(np.arange(n_total), size=n_enrolled, replace=False, p=p)\n",
    "    E = np.zeros(n_total)\n",
    "    E[E_inds] = 1\n",
    "    \n",
    "    # select treatment and control groups\n",
    "    T_inds = np.random.choice(E_inds, size=n_treatment, replace=False)\n",
    "    Tr = np.zeros(n_total)\n",
    "    Tr[T_inds] = 1\n",
    "    assert Tr.sum() == n_treatment\n",
    "        \n",
    "    y_pre = 2 * I + np.random.normal(loc=0, scale=2, size=n_total)\n",
    "    #y_pre = np.maximum(y_pre, 0).round()\n",
    "    \n",
    "    y_post = y_pre + np.random.normal(loc=-1, scale=0.5, size=n_total)\n",
    "    y_post += 0.1*I  # residual effect of interest on y_post\n",
    "    \n",
    "    true_effect = 2\n",
    "    y_post[Tr == 1] += np.random.normal(loc=true_effect, scale=0.01, size=n_treatment)\n",
    "    #y_post = np.maximum(y_post, 0).round()\n",
    "    \n",
    "    \n",
    "    df = pd.DataFrame.from_dict({\n",
    "        'E': E,\n",
    "        'I': I,\n",
    "        'p_enroll': p,\n",
    "        'y_pre': y_pre,\n",
    "        'y_post': y_post,\n",
    "        'Tr': Tr,\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = get_synthetic_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.agg(np.ptp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_effects = []\n",
    "naive_effects = []\n",
    "for i in tqdm(range(1000)):\n",
    "    df = get_synthetic_data()\n",
    "    true_effect = df[(df.E == 1)&(df.Tr == 1)].y_post.mean() - df[(df.E == 1)&(df.Tr == 0)].y_post.mean()\n",
    "    naive_effect = df[df.Tr == 1].y_post.mean() - df[df.Tr == 0].y_post.mean()\n",
    "    true_effects.append(true_effect)\n",
    "    naive_effects.append(naive_effect)\n",
    "true_effects = np.array(true_effects)\n",
    "naive_effects = np.array(naive_effects)\n",
    "    \n",
    "fig, axes = plt.subplots(1, 2)\n",
    "\n",
    "ax = axes[0]\n",
    "ax.hist(true_effects)\n",
    "ax.set_title(\"True effect\")\n",
    "\n",
    "ax = axes[1]\n",
    "ax.hist(naive_effects - true_effects)\n",
    "ax.set_title(\"Naive effect - True effect\")\n",
    "\n",
    "plt.show()\n",
    "true_effects.mean(), naive_effects.mean(), (naive_effects - true_effects).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the true effect, as discovered via randomized experiment\n",
    "# and the naive effect, not controlling for probability of enrollment\n",
    "df[(df.E == 1)&(df.Tr == 1)].y_post.mean() - df[(df.E == 1)&(df.Tr == 0)].y_post.mean(),\\\n",
    "df[df.Tr == 1].y_post.mean() - df[df.Tr == 0].y_post.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df.columns\n",
    "ncols = 3\n",
    "nrows = int(np.ceil(len(cols) / ncols))\n",
    "fig, axes = plt.subplots(nrows, ncols, figsize=(8, nrows*4))\n",
    "for ax, col in zip(axes.flatten(), cols):\n",
    "    nbins = min(df[col].nunique(), 100)\n",
    "    hist, _ = np.histogram(df[col], bins=nbins)\n",
    "    log = np.ptp(hist) > 1000  # three orders of magnitude...\n",
    "    ax.hist(df[col], bins=nbins, log=log)\n",
    "    ax.set_xlabel(col)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df.columns\n",
    "ncols = 3\n",
    "nrows = int(np.ceil(len(cols) / ncols))\n",
    "fig, axes = plt.subplots(nrows, ncols, figsize=(8, nrows*4))\n",
    "for ax, col in zip(axes.flatten(), cols):\n",
    "    nbins = min(df[col].nunique(), 30)\n",
    "    hist, _ = np.histogram(df[col], bins=nbins)\n",
    "    log = np.ptp(hist) > 1000  # three orders of magnitude...\n",
    "    ax.hist([df[df.Tr == 1][col], df[df.Tr == 0][col]], bins=nbins, log=log, density=True)\n",
    "    ax.set_xlabel(col)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, group in df.groupby('Tr'):\n",
    "    print(f\"Tr=={name} {group.y_pre.mean():.3f} {(group.y_post - group.y_pre).mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df.E == 1)&(df.Tr == 1)].y_post.mean() - df[(df.E == 1)&(df.Tr == 0)].y_post.mean(),\\\n",
    "df[df.Tr == 1].y_post.mean() - df[df.Tr == 0].y_post.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = smf.ols(formula='y_post ~ y_pre + Tr', data=df)\n",
    "res = md.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we got to observe I, we get closer to the true effect with an OLS model\n",
    "md = smf.ols(formula='y_post ~ y_pre + Tr + I', data=df)\n",
    "res = md.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also get close by including only enrolled authors\n",
    "# (still upwardly biased though)\n",
    "md = smf.ols(formula='y_post ~ y_pre + Tr', data=df[df.E == 1])\n",
    "res = md.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IP Weighting\n",
    "\n",
    "https://github.com/jrfiedler/causal_inference_python_code/blob/master/chapter12.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit_ip_f(df, use_I=False):\n",
    "    \"\"\"\n",
    "    Create the f(y|X) part of IP weights using logistic regression\n",
    "    \n",
    "    Adapted from https://github.com/jrfiedler/causal_inference_python_code/blob/master/chapter12.ipynb\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : Pandas DataFrame\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Numpy array of IP weights\n",
    "    \n",
    "    \"\"\"\n",
    "    formula = 'Tr ~ y_pre'\n",
    "    if use_I:\n",
    "        formula = 'Tr ~ y_pre + I'\n",
    "    model = smf.logit(formula=formula, data=df)\n",
    "    res = model.fit(disp=0)\n",
    "    #print(res.summary().tables[1])\n",
    "    weights = np.zeros(len(df))\n",
    "    weights[df.Tr == 1] = res.predict(df[df.Tr == 1])\n",
    "    weights[df.Tr == 0] = (1 - res.predict(df[df.Tr == 0]))\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = logit_ip_f(df)\n",
    "weights = 1 / weights\n",
    "plt.hist(weights, bins=50, log=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('IP weights')\n",
    "print('   min: {:>5.2f}   expected:  X'.format(weights.min()))\n",
    "print('   max: {:>5.2f}   expected: Y'.format(weights.max()))\n",
    "print('  mean: {:>5.2f}   expected:  Z'.format(weights.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wls = smf.wls(formula='y_post ~ Tr', data=df, weights=weights) \n",
    "res = wls.fit()\n",
    "res.summary().tables[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est = res.params.Tr\n",
    "conf_ints = res.conf_int(alpha=0.05, cols=None)\n",
    "lo, hi = conf_ints[0]['Tr'], conf_ints[1]['Tr']\n",
    "\n",
    "print('           estimate   95% C.I.')\n",
    "print(f'theta_1     {est:>6.2f}   ({lo:>0.1f}, {hi:>0.1f})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notably, this estimate appears not to be any better than the naive estimate\n",
    "df[df.Tr == 1].y_post.mean() - df[df.Tr == 0].y_post.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardization\n",
    "\n",
    "Chapter 13\n",
    "\n",
    "Code: https://github.com/jrfiedler/causal_inference_python_code/blob/master/chapter13.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = smf.ols(formula='y_post ~ y_pre + Tr', data=df)\n",
    "res = md.fit()\n",
    "res.summary().tables[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block2 = df.copy()\n",
    "block2.Tr = 0\n",
    "block2_pred = res.predict(block2)\n",
    "\n",
    "block3 = df.copy()\n",
    "block3.Tr = 1\n",
    "block3_pred = res.predict(block3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_mean = res.predict(df).mean()\n",
    "block2_mean = block2_pred.mean()\n",
    "block3_mean = block3_pred.mean()\n",
    "est_diff = block3_mean - block2_mean\n",
    "\n",
    "print('original mean prediction: {:>0.2f}'.format(orig_mean))\n",
    "print()\n",
    "print(' block 2 mean prediction: {:>0.2f}'.format(block2_mean))\n",
    "print(' block 3 mean prediction: {:>0.2f}'.format(block3_mean))\n",
    "print()\n",
    "print('  causal effect estimate: {:>0.2f}'.format(est_diff))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to report this?\n",
    "\n",
    "The standardized mean for our participants was X, while the standardized mean in the pseudo-control was Y; thus, our estimate of the mean causal impact of the recommender intervention on journaling is X-Y additional journals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"To obtain a doubly robust estimate of the average causal effect, first estimate the IP weight   = 1 (|)\n",
    "as described in the previous chapter. Then fit an outcome regression model like the one described in this chapter–a\n",
    "generalized linear model with a canonical link–for E[ | =   =  ] that adds the covariate , where  =   if\n",
    " = 1 and  = −  if  = 0. Finally, use the predicted values from the outcome model to obtain the standardized\n",
    "mean outcomes under  = 1 and  = 0. The difference of the standardized mean outcomes is now doubly robust.\n",
    "That is, under exchangeability and positivity given , this estimator consistently estimates the average causal effect if\n",
    "either the model for the treatment or the model for the outcome is correct, without knowing which of the two models\n",
    "is the correct one.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pg. 167, \"A doubly robust estimator\"\n",
    "# This is the Bang and Robins (2005) doubly robust estimator \n",
    "# \"for the average causal effect of a dichotomous treatment on an outcome\"\n",
    "\n",
    "# \"first estimate the IP weight\"\n",
    "weights = logit_ip_f(df)\n",
    "weights = 1 / weights\n",
    "\n",
    "# \"then fit an outcome regression model ... that adds the covariate R\"\n",
    "# R is W if Tr == 1 else -W\n",
    "block1 = df.copy()\n",
    "block1['R'] = weights\n",
    "block1.loc[block1.Tr == 0, 'R'] *= -1\n",
    "md = smf.ols(formula='y_post ~ y_pre + Tr + R', data=block1)\n",
    "res = md.fit()\n",
    "print(res.summary().tables[1])\n",
    "\n",
    "# \"Finally, use the predicted values from the outcome model to obtain the standardized mean outcomes\"\n",
    "block2 = block1.copy()\n",
    "block2.Tr = 0\n",
    "#block2.W = 0  # unsure if we're supposed to maintain the weights... but it doesn't seem to matter\n",
    "block3 = block1.copy()\n",
    "block3.Tr = 1\n",
    "#block3.W = 0\n",
    "block2_pred = res.predict(block2)\n",
    "block3_pred = res.predict(block3)\n",
    "block3_pred.mean() - block2_pred.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for i in tqdm(range(1000)):\n",
    "    df = get_synthetic_data()\n",
    "    \n",
    "    # blocks needed for standardization\n",
    "    block2 = df.copy()\n",
    "    block2.Tr = 0\n",
    "    block3 = df.copy()\n",
    "    block3.Tr = 1\n",
    "    \n",
    "    # basic regression estimates\n",
    "    # that \"adjust for\" confounders\n",
    "    # plus standardization\n",
    "    md = smf.ols(formula='y_post ~ y_pre + Tr', data=df)\n",
    "    res = md.fit()\n",
    "    modeled_observational_effect = res.params.Tr\n",
    "    block2_pred = res.predict(block2)\n",
    "    block3_pred = res.predict(block3)\n",
    "    standardized_effect = block3_pred.mean() - block2_pred.mean()\n",
    "    \n",
    "    # ... and with an interaction effect\n",
    "    md = smf.ols(formula='y_post ~ y_pre + Tr + y_pre*Tr', data=df)\n",
    "    res = md.fit()\n",
    "    modeled_observational_effect_int = res.params.Tr\n",
    "    block2_pred = res.predict(block2)\n",
    "    block3_pred = res.predict(block3)\n",
    "    standardized_effect_int = block3_pred.mean() - block2_pred.mean()\n",
    "    \n",
    "    # ... and with the I covariate\n",
    "    md = smf.ols(formula='y_post ~ y_pre + Tr + I', data=df)\n",
    "    res = md.fit()\n",
    "    modeled_observational_effect_I = res.params.Tr\n",
    "    #print(res.summary().tables[1])\n",
    "    block2_pred = res.predict(block2)\n",
    "    block3_pred = res.predict(block3)\n",
    "    standardized_effect_I = block3_pred.mean() - block2_pred.mean()\n",
    "    \n",
    "    # IP weighting and the Bang-Robins doubly robust (DR) estimator\n",
    "    weights = logit_ip_f(df)\n",
    "    weights = 1 / weights\n",
    "    wls = smf.wls(formula='y_post ~ Tr', data=df, weights=weights) \n",
    "    res = wls.fit(disp=0)\n",
    "    ip_weighted_effect = res.params.Tr\n",
    "    \n",
    "    block1 = df.copy()\n",
    "    block1['R'] = weights\n",
    "    block1.loc[block1.Tr == 0, 'R'] *= -1\n",
    "    md = smf.ols(formula='y_post ~ y_pre + Tr + R', data=block1)\n",
    "    res = md.fit()\n",
    "    block2 = block1.copy()\n",
    "    block2.Tr = 0\n",
    "    block3 = block1.copy()\n",
    "    block3.Tr = 1\n",
    "    block2_pred = res.predict(block2)\n",
    "    block3_pred = res.predict(block3)\n",
    "    dr_effect = block3_pred.mean() - block2_pred.mean()\n",
    "    \n",
    "    # ... and with the I covariate\n",
    "    weights = logit_ip_f(df, use_I=True)\n",
    "    weights = 1 / weights\n",
    "    wls = smf.wls(formula='y_post ~ Tr', data=df, weights=weights) \n",
    "    res = wls.fit(disp=0)\n",
    "    ip_weighted_effect_I = res.params.Tr\n",
    "    \n",
    "    block1 = df.copy()\n",
    "    block1['R'] = weights\n",
    "    block1.loc[block1.Tr == 0, 'R'] *= -1\n",
    "    md = smf.ols(formula='y_post ~ y_pre + Tr + I + R', data=block1)\n",
    "    res = md.fit()\n",
    "    block2 = block1.copy()\n",
    "    block2.Tr = 0\n",
    "    block3 = block1.copy()\n",
    "    block3.Tr = 1\n",
    "    block2_pred = res.predict(block2)\n",
    "    block3_pred = res.predict(block3)\n",
    "    dr_effect_I = block3_pred.mean() - block2_pred.mean()\n",
    "    \n",
    "    # stabilized IP weighting\n",
    "    weights = logit_ip_f(df)\n",
    "    weights = 1 / weights\n",
    "    pct_treated = df.Tr.mean()\n",
    "    weights[df.Tr == 1] = pct_treated * weights[df.Tr == 1]\n",
    "    weights[df.Tr == 0] = (1 - pct_treated) * weights[df.Tr == 0]\n",
    "    wls = smf.wls(formula='y_post ~ Tr', data=df, weights=weights) \n",
    "    res = wls.fit(disp=0)\n",
    "    sip_weighted_effect = res.params.Tr\n",
    "    \n",
    "    # ... and with the I covariate\n",
    "    weights = logit_ip_f(df, use_I=True)\n",
    "    weights = 1 / weights\n",
    "    pct_treated = df.Tr.mean()\n",
    "    weights[df.Tr == 1] = pct_treated * weights[df.Tr == 1]\n",
    "    weights[df.Tr == 0] = (1 - pct_treated) * weights[df.Tr == 0]\n",
    "    wls = smf.wls(formula='y_post ~ Tr', data=df, weights=weights) \n",
    "    res = wls.fit(disp=0)\n",
    "    sip_weighted_effect_I = res.params.Tr\n",
    "    \n",
    "    results.append({\n",
    "        'experimental_effect': df[(df.E == 1)&(df.Tr == 1)].y_post.mean() - df[(df.E == 1)&(df.Tr == 0)].y_post.mean(),\n",
    "        'naive_observational_effect': df[df.Tr == 1].y_post.mean() - df[df.Tr == 0].y_post.mean(),\n",
    "        'modeled_observational_effect': modeled_observational_effect,\n",
    "        'ip_weighted_effect': ip_weighted_effect,\n",
    "        'sip_weighted_effect': sip_weighted_effect,\n",
    "        'standardized_effect': standardized_effect,\n",
    "        'dr_effect': dr_effect,\n",
    "        'modeled_observational_effect_I': modeled_observational_effect_I,\n",
    "        'ip_weighted_effect_I': ip_weighted_effect_I,\n",
    "        'sip_weighted_effect_I': sip_weighted_effect_I,\n",
    "        'standardized_effect_I': standardized_effect_I,\n",
    "        'dr_effect_I': dr_effect_I,\n",
    "        'modeled_observational_effect_int': modeled_observational_effect_int,\n",
    "        'standardized_effect_int': standardized_effect_int,\n",
    "    })\n",
    "rdf = pd.DataFrame(results)\n",
    "rdf.sample(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf.agg(['mean', 'std']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Key observation: confounders need to be specified correctly! if they're not, then modeling won't help\n",
    "\n",
    "A few notes from simulations:\n",
    "\n",
    "If I -> Y_pre and Y_pre -> Y_post but NOT I -> Y_post, then we seem to be mostly fine?\n",
    "If I -> Y_pre and Y_pre -> Y_post but ALSO I -> Y_post, then we seem to be screwed... in fact, IP weighting just makes things worse\n",
    "\n",
    "The standardized effects are extremely similar to the modeled observational effect.\n",
    "\n",
    "The Doubly Robust estimates are, shockingly, actually much better, which is nice.\n",
    "\n",
    "\"\"\"\n",
    "for col in [\n",
    "    'naive_observational_effect', \n",
    "    'modeled_observational_effect', \n",
    "    'ip_weighted_effect', \n",
    "    'sip_weighted_effect', \n",
    "    'standardized_effect',\n",
    "    'dr_effect',\n",
    "    'modeled_observational_effect_I', \n",
    "    'ip_weighted_effect_I', \n",
    "    'sip_weighted_effect_I',\n",
    "    'standardized_effect_I',\n",
    "    'dr_effect_I',\n",
    "    'modeled_observational_effect_int',\n",
    "    'standardized_effect_int',\n",
    "]:\n",
    "    diff = rdf[col] - rdf.experimental_effect\n",
    "    print(f\"{col:>35} diff    {diff.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (shared-conda)",
   "language": "python",
   "name": "shared-conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
