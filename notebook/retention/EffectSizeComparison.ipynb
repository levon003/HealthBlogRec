{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Effect Size Comparison\n",
    "===\n",
    "\n",
    "Relevant Google Doc: https://docs.google.com/document/d/1_VjjJkdvUD_YsIjGMYGISpJg5CGC_mRzFgYpuBqKliA/edit?usp=sharing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.rcParams['figure.dpi'] = 120\n",
    "matplotlib.rcParams['font.family'] = \"serif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import bson\n",
    "from bson.codec_options import CodecOptions\n",
    "from bson.raw_bson import RawBSONDocument\n",
    "from bson import ObjectId\n",
    "import gzip\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from glob import glob\n",
    "\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import dateutil\n",
    "import pytz\n",
    "\n",
    "import scipy\n",
    "import scipy.stats\n",
    "\n",
    "import logging\n",
    "from pprint import pprint\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "git_root_dir = !git rev-parse --show-toplevel\n",
    "git_root_dir = Path(git_root_dir[0].strip())\n",
    "git_root_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "caringbridge_core_path = \"/home/lana/levon003/repos/caringbridge_core\"\n",
    "sys.path.append(caringbridge_core_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cbcore.data.paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert os.path.exists(cbcore.data.paths.raw_data_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caringbridge_core_path = \"/home/lana/levon003/repos/recsys-peer-match/src\"\n",
    "sys.path.append(caringbridge_core_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cbrec.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figures_dir = os.path.join(git_root_dir, 'figures')\n",
    "os.makedirs(figures_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading previous batch recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_data_dir = os.path.join(cbcore.data.paths.projects_data_dir, 'recsys-peer-match', 'participant')\n",
    "!wc -l {participant_data_dir}/*.ndjson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in recommendations from previous rounds\n",
    "d = []\n",
    "for batch_id in [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]:\n",
    "    participant_data_filepath = os.path.join(participant_data_dir, f'participant_rec_data_b{batch_id}.ndjson')\n",
    "    with open(participant_data_filepath, 'r') as infile:\n",
    "        for line in infile:\n",
    "            participant = json.loads(line)\n",
    "            del participant['site_scores']\n",
    "            participant['batch_id'] = batch_id\n",
    "            d.append(participant)\n",
    "len(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_df = pd.DataFrame(d)\n",
    "batch_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(batch_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_df.sse_site_list.iloc[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_recced_site_map = {}\n",
    "for participant_id, group in batch_df.groupby('participant_id'):\n",
    "    recced_site_ids = []\n",
    "    for sse_site_list in group.sse_site_list:\n",
    "        recced_site_ids.extend([site['site_id'] for site in sse_site_list])\n",
    "    assert len(recced_site_ids) == len(set(recced_site_ids)), \"Duplicate rec was given.\"\n",
    "    recced_site_ids = list(set(recced_site_ids))\n",
    "    participant_recced_site_map[participant_id] = recced_site_ids\n",
    "len(participant_recced_site_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recced_usps = [(row.participant_id, site['site_id']) for row in batch_df.itertuples() for site in row.sse_site_list]\n",
    "len(recced_usps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(set(recced_usps)) == len(recced_usps), \"Duplicate rec given.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create rec_df\n",
    "rec_df = []\n",
    "for row in batch_df.itertuples(index=False):\n",
    "    for i, site in enumerate(row.sse_site_list):\n",
    "        rec = row._asdict()\n",
    "        del rec['sse_site_list']\n",
    "        if 'journal_body' in site:\n",
    "            # some of the data were written with different key names for cleaned_journal_{body,title}\n",
    "            # this code normalizes the key names\n",
    "            site = dict(site)\n",
    "            site['cleaned_journal_body'] = site['journal_body']\n",
    "            del site['journal_body']\n",
    "            site['cleaned_journal_title'] = site['journal_title']\n",
    "            del site['journal_title']\n",
    "        rec.update(site)\n",
    "        rec['rank'] = i\n",
    "        rec_df.append(rec)\n",
    "rec_df = pd.DataFrame(rec_df)\n",
    "len(rec_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add alias for participant_id\n",
    "rec_df['user_id'] = rec_df['participant_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_df.sample(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Participant data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get participant data\n",
    "participant_id_filepath = os.path.join(git_root_dir, 'data/email/participant_ids.tsv')\n",
    "participant_df = pd.read_csv(participant_id_filepath, sep='\\t', header=0)\n",
    "print(len(participant_df))\n",
    "participant_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_batch_count_map = batch_df.groupby('participant_id').batch_id.nunique().to_dict()\n",
    "participant_df['n_total_recs'] = participant_df.user_id.map(lambda user_id: participant_batch_count_map[user_id] * 5 if user_id in participant_batch_count_map else 0)\n",
    "participant_df.n_total_recs.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_first_sse_map = batch_df.groupby('participant_id').sse_sent_timestamp.min()\n",
    "participant_df['first_sse_timestamp'] = participant_df.user_id.map(lambda user_id: participant_first_sse_map[user_id] if user_id in participant_first_sse_map else -1)\n",
    "participant_df.first_sse_timestamp.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_user_ids = set(participant_df[participant_df.n_total_recs > 0].user_id)\n",
    "print(f\"{len(set(participant_df.user_id))} participants were matched to an email\")\n",
    "print(f\"{len(set(participant_df[participant_df.n_total_recs > 0].user_id))} participants received 1+ recommendations\")\n",
    "len(participant_user_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b0_participant_user_ids = set(rec_df[rec_df.batch_id == 0].participant_id)\n",
    "len(b0_participant_user_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Site, Profile, Journal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the site metadata dataframe\n",
    "# this is created in caringbridge_core from the new data\n",
    "site_metadata_working_dir = \"/home/lana/shared/caringbridge/data/derived/site_metadata\"\n",
    "s = datetime.now()\n",
    "site_metadata_filepath = os.path.join(site_metadata_working_dir, \"site_metadata.feather\")\n",
    "site_info_df = pd.read_feather(site_metadata_filepath)\n",
    "assert np.sum(site_info_df.site_id.value_counts() > 1) == 0, \"Site ids are not globally unique.\"\n",
    "print(datetime.now() - s)\n",
    "len(site_info_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the profile data\n",
    "profile_metadata_dir = '/home/lana/shared/caringbridge/data/derived/profile'\n",
    "s = datetime.now()\n",
    "profile_df = pd.read_feather(os.path.join(profile_metadata_dir, 'profile.feather'))\n",
    "print(f\"Loaded {len(profile_df)} rows in {datetime.now() - s}.\")\n",
    "profile_df.sample(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the journal metadata\n",
    "s = datetime.now()\n",
    "journal_metadata_dir = \"/home/lana/shared/caringbridge/data/derived/journal_metadata\"\n",
    "journal_metadata_filepath = os.path.join(journal_metadata_dir, \"journal_metadata.feather\")\n",
    "journal_df = pd.read_feather(journal_metadata_filepath)\n",
    "print(datetime.now() - s)\n",
    "len(journal_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "journal_df.sample(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "journal_df['usp'] = [(user_id, site_id) for user_id, site_id in zip(journal_df.user_id, journal_df.site_id)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of Churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timezone\n",
    "\n",
    "print(datetime(2021, 8, 1).strftime(\"%B %d %Y\"))\n",
    "july2021 = datetime(2021, 7, 1)\n",
    "july2021 = july2021.replace(tzinfo=timezone.utc).timestamp() * 1000\n",
    "august2021 = datetime(2021, 8, 1)\n",
    "august2021 = august2021.replace(tzinfo=timezone.utc).timestamp() * 1000\n",
    "september2021 = datetime(2021, 9, 1)\n",
    "september2021 = september2021.replace(tzinfo=timezone.utc).timestamp() * 1000\n",
    "\n",
    "one_day = 1000 * 60 * 60 * 24\n",
    "thirtyone = one_day * 31\n",
    "\n",
    "#datetime.utcfromtimestamp(first_sse_timestamp / 1000)\n",
    "\n",
    "\n",
    "for dt in journal_df[(journal_df.published_at >= july2021)&(journal_df.published_at < august2021)].sample(n=2).published_at:\n",
    "    dt = dt / 1000\n",
    "    print(datetime.utcfromtimestamp(dt).strftime(\"%B %d %Y\"))\n",
    "july_journals = journal_df[(journal_df.published_at >= july2021)&(journal_df.published_at < august2021)].groupby(['user_id']).journal_oid.count().rename(\"july_journals\").to_frame()\n",
    "\n",
    "\n",
    "aug_journals = journal_df[(journal_df.published_at >= august2021)&(journal_df.published_at < september2021)].groupby(['user_id']).journal_oid.count().rename(\"aug_journals\").to_frame()\n",
    "\n",
    "churn_df = july_journals.merge(aug_journals, on='user_id', how='left')\n",
    "churn_df = churn_df.fillna(value=0)\n",
    "churn_journal_diff = (churn_df.july_journals - churn_df.aug_journals)\n",
    "print(churn_journal_diff.mean())\n",
    "print(churn_journal_diff.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interaction data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read interactions dataframe\n",
    "s = datetime.now()\n",
    "model_data_dir = '/home/lana/shared/caringbridge/data/projects/recsys-peer-match/model_data'\n",
    "ints_df = pd.read_feather(os.path.join(model_data_dir, 'ints_df.feather'))\n",
    "print(f\"Read {len(ints_df)} rows ({len(set(ints_df.user_id))} unique users) in {datetime.now() - s}.\")\n",
    "ints_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ints_df['usp'] = [(user_id, site_id) for user_id, site_id in zip(ints_df.user_id, ints_df.site_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visit data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the site profile diff\n",
    "# rows should be >= 37M+\n",
    "s = datetime.now()\n",
    "site_profile_diff_filepath = os.path.join(cbcore.data.paths.projects_data_dir, 'caringbridge_core', 'site_profile_diff', 'site_profile_diff.tsv')\n",
    "site_profile_diff_df = pd.read_csv(site_profile_diff_filepath, sep='\\t', header=0)\n",
    "print(f\"Read {len(site_profile_diff_df)} rows in {datetime.now() - s}.\")\n",
    "site_profile_diff_df['usp'] = [(row.user_id, row.site_id) for row in tqdm(site_profile_diff_df.itertuples(), total=len(site_profile_diff_df), desc=\"Creating USPs\")]\n",
    "site_profile_diff_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# also need to load the participant and non-participant site profile data\n",
    "\n",
    "nonparticipant_data_dir = os.path.join(cbcore.data.paths.projects_data_dir, 'recsys-peer-match', 'nonparticipant')\n",
    "with open(os.path.join(nonparticipant_data_dir, 'site_profile.pkl'), 'rb') as infile:\n",
    "    nonp_site_profiles = pickle.load(infile)\n",
    "print(len(nonp_site_profiles))\n",
    "\n",
    "with open(os.path.join(participant_data_dir, 'site_profile.pkl'), 'rb') as infile:\n",
    "    p_site_profiles = pickle.load(infile)\n",
    "print(len(p_site_profiles))\n",
    "\n",
    "site_profiles = nonp_site_profiles + p_site_profiles\n",
    "\n",
    "# create a dataframe from the site profile entires\n",
    "ds = []\n",
    "for sp in site_profiles:\n",
    "    user_id = int(sp['userId'])\n",
    "    site_id = int(sp['siteId']) if 'siteId' in sp else -1\n",
    "    # not capturing: nl\n",
    "    d = {\n",
    "        'user_id': user_id,\n",
    "        'site_id': site_id,\n",
    "        'is_creator': sp['isCreator'] if 'isCreator' in sp else None,\n",
    "        'is_primary': sp['isPrimary'] if 'isPrimary' in sp else None,\n",
    "        'role': sp['role'],\n",
    "        'is_profile_deleted': sp['isProfileDeleted'] if 'isProfileDeleted' in sp else None,\n",
    "        'is_site_deleted': sp['isSiteDeleted'] if 'isSiteDeleted' in sp else None,\n",
    "        'is_stub': sp['isStub'] if 'isStub' in sp else None,\n",
    "        'created_at': sp['createdAt'].timestamp() * 1000 if 'createdAt' in sp else 0,\n",
    "        'updated_at': sp['updatedAt'].timestamp() * 1000 if 'updatedAt' in sp else 0,\n",
    "        'n': dict(sp['n']) if 'n' in sp and sp['n'] is not None else {},\n",
    "    }\n",
    "    ds.append(d)\n",
    "\n",
    "ssite_profile_df = pd.DataFrame(ds)\n",
    "ssite_profile_df['is_participant'] = ssite_profile_df.user_id.isin(participant_user_ids)\n",
    "ssite_profile_df['usp'] = [(row.user_id, row.site_id) for row in ssite_profile_df.itertuples()]\n",
    "ssite_profile_df.sample(n=3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssite_profile_df.is_creator.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssite_profile_df.is_primary.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssite_profile_df['is_self_author'] = (ssite_profile_df.is_creator == 1)|(ssite_profile_df.is_primary == 1)|(ssite_profile_df.role == 'Organizer')\n",
    "ssite_profile_df.is_self_author.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sjournal_df = journal_df[journal_df.user_id.isin(set(ssite_profile_df.user_id))]\n",
    "len(sjournal_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "journal_usp_set = set([(row.user_id, row.site_id) for row in sjournal_df.itertuples()])\n",
    "len(journal_usp_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are a small number of USPs where this user has authored a journal on that site but is not marked as an author in the site_profile record\n",
    "pd.crosstab(ssite_profile_df.is_self_author, ssite_profile_df.usp.isin(journal_usp_set).rename(\"is_journal_author\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssite_profile_df.loc[ssite_profile_df.usp.isin(journal_usp_set), 'is_self_author'] = True\n",
    "ssite_profile_df.is_self_author.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the first_visit_df for others' sites only\n",
    "first_visit_df = ssite_profile_df[~ssite_profile_df.is_self_author]\n",
    "len(first_visit_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on journal authors and first visits, identify the set of author USPs (where the user_id is an author of site_id)\n",
    "author_usp_set = set(ssite_profile_df[ssite_profile_df.is_self_author].usp) | set(journal_df.usp)\n",
    "len(author_usp_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_user_id_set = set(ssite_profile_df[ssite_profile_df.is_self_author].user_id) | set(journal_df.user_id)\n",
    "len(author_user_id_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# author-to-author site visits\n",
    "# excludes all non-authors\n",
    "# excludes all self-visits\n",
    "site_visits = site_profile_diff_df[(site_profile_diff_df.key == 'updatedAt')&(site_profile_diff_df.user_id.isin(author_user_id_set)&(~site_profile_diff_df.usp.isin(author_usp_set)))]\n",
    "len(site_visits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_site_interactions = {\n",
    "    (row.user_id, row.site_id): [row.created_at,] for row in first_visit_df.itertuples()\n",
    "}\n",
    "len(user_site_interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOLERANCE = 1000 * 60 * 60 * 7  # 7 hours, chosen so that if there's a bug with UTC (5 hours) and DST (1 hour) we still have an hour to treat them as essentially the same time\n",
    "\n",
    "n_missing_site_profiles = 0\n",
    "n_potential_missed_visits = 0\n",
    "n_empty_curr_values = 0\n",
    "for row in tqdm(site_visits.itertuples(), total=len(site_visits)):\n",
    "    usp = (row.user_id, row.site_id)\n",
    "    if usp not in user_site_interactions:\n",
    "        # these are author interactions, but the author in question is not \"eligible\" i.e. not in the participant group or the pseudo-control group\n",
    "        # the assertion below works as expected, although it requires running cells out of order\n",
    "        # assert row.user_id not in target_user_ids\n",
    "        n_missing_site_profiles += 1\n",
    "        user_site_interactions[usp] = [float(row.old_value) * 1000,]\n",
    "    visit_list = user_site_interactions[usp]\n",
    "    last_visit = float(row.old_value) * 1000\n",
    "    curr_visit = float(row.new_value) * 1000\n",
    "    assert curr_visit > 0\n",
    "    if last_visit == 0:\n",
    "        n_empty_curr_values += 1\n",
    "    elif last_visit < visit_list[-1] - TOLERANCE:\n",
    "        logging.warning(\"updatedAt's old value was before the creation date of the site_profile or before the value from the previous snapshot.\")\n",
    "        break\n",
    "    elif last_visit > visit_list[-1] + 5000:\n",
    "        n_potential_missed_visits += 1\n",
    "        visit_list.append(last_visit)\n",
    "    assert curr_visit > last_visit\n",
    "    visit_list.append(curr_visit)\n",
    "n_missing_site_profiles, n_potential_missed_visits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visits_df = pd.DataFrame([{'usp': usp, 'visit_timestamp': visit_timestamp} for usp, visit_list in user_site_interactions.items() for visit_timestamp in visit_list])\n",
    "visits_df['user_id'] = visits_df.usp.map(lambda usp: usp[0])\n",
    "visits_df['site_id'] = visits_df.usp.map(lambda usp: usp[1])\n",
    "len(visits_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I believe this will result in bucketing by CENTRAL TIME dates\n",
    "visits_df['visit_date'] = visits_df.visit_timestamp.map(lambda ts: int(datetime.utcfromtimestamp(int(ts / 1000)).strftime('%Y%m%d')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 1.2))\n",
    "\n",
    "start_date = 20210701\n",
    "daily_visits = visits_df[visits_df.visit_date >= start_date].groupby('visit_date').usp.nunique()\n",
    "\n",
    "ax.plot(np.arange(len(daily_visits)), daily_visits)\n",
    "ax.set_title(\"Daily visits by authors to peer sites\", fontsize=10)\n",
    "def format_date(x, pos=None):\n",
    "    return f\"{(datetime.strptime(str(start_date), '%Y%m%d') + relativedelta(days=int(x))).strftime('%Y-%m-%d')}\"\n",
    "ax.xaxis.set_major_formatter(format_date)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "central_time = pytz.timezone('US/Central')\n",
    "banner_live_time = datetime.fromisoformat('2021-08-02 12:11:00').astimezone(central_time)\n",
    "banner_end_time = datetime.fromisoformat('2021-08-23 11:59:59').astimezone(central_time)\n",
    "print(f\"Banner live: {banner_live_time}\")\n",
    "print(f\"Banner end: {banner_end_time}\")\n",
    "\n",
    "first_sse_timestamp = batch_df.sse_sent_timestamp.min()\n",
    "first_sse_time = datetime.utcfromtimestamp(first_sse_timestamp / 1000)\n",
    "print(f\"First SSE sent: {first_sse_time}\")\n",
    "\n",
    "last_sse_timestamp = batch_df.sse_sent_timestamp.max()\n",
    "last_sse_time = datetime.utcfromtimestamp(last_sse_timestamp / 1000)\n",
    "print(f\"Last SSE sent: {last_sse_time}\")\n",
    "\n",
    "last_b0_sse_timestamp = batch_df[batch_df.batch_id == 0].sse_sent_timestamp.max()\n",
    "last_b0_sse_time = datetime.utcfromtimestamp(last_b0_sse_timestamp / 1000)\n",
    "print(f\"Lastb0  SSE sent: {last_b0_sse_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-participant / pseudo-control data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the nonparticipant / pseudo-control user ids\n",
    "nonparticipant_user_ids = set()\n",
    "with open(os.path.join(cbcore.data.paths.projects_data_dir, 'recsys-peer-match', 'participant', 'nonparticipant_user_ids.txt'), 'r') as infile:\n",
    "    for line in infile:\n",
    "        if line.strip() == \"\":\n",
    "            continue\n",
    "        user_id = int(line.strip())\n",
    "        nonparticipant_user_ids.add(user_id)\n",
    "len(nonparticipant_user_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prestudy_journal_counts = journal_df[(journal_df.user_id.isin(nonparticipant_user_ids))&(journal_df.published_at <= first_sse_timestamp)].groupby('user_id').journal_id.nunique()\n",
    "print(f\"{np.sum(prestudy_journal_counts >= 3) / len(prestudy_journal_counts):.2%} meet eligibility criteria.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(prestudy_journal_counts), np.sum(prestudy_journal_counts >= 1), np.sum(prestudy_journal_counts >= 2), np.sum(prestudy_journal_counts >= 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonparticipant_user_ids = nonparticipant_user_ids & set((prestudy_journal_counts[prestudy_journal_counts >= 3]).index)\n",
    "len(nonparticipant_user_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Click Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the rec_df with associated click data\n",
    "participant_data_dir = '/home/lana/shared/caringbridge/data/projects/recsys-peer-match/participant'\n",
    "click_rec_df = pd.read_feather(os.path.join(participant_data_dir, 'click_rec_df.feather'))\n",
    "len(click_rec_df), click_rec_df.was_clicked.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#click_rec_df = click_rec_df[[\"participant_id\", \"site_id\", \"batch_id\", \"first_click_timestamp\", \"was_clicked\"]]\n",
    "click_rec_df['was_clicked'] = click_rec_df['was_clicked'].astype(int)\n",
    "click_rec_df[click_rec_df.was_clicked == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clicked_timestamps_df = click_rec_df[click_rec_df.was_clicked == 1].groupby('batch_id').first_click_timestamp.unique()\n",
    "clicked_timestamps_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by site_id, was_clicked and first_click_timestamp = max(min(first_click_timestamp where was_clicked == 1), min(first_click_timestamp))\n",
    "click_rec_sites_df = click_rec_df.groupby('site_id').apply(lambda x: pd.Series({'batch_id': min(x.batch_id),\\\n",
    "                                                                               'first_click_timestamp': max([x.first_click_timestamp.min(), x[x.was_clicked == 1].first_click_timestamp.min()]),\\\n",
    "                                                                               'was_clicked': x.was_clicked.max()}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed(1)\n",
    "#click_rec_df[~click_rec_df.was_clicked].first_click_timestamp = random.choice(clicked_timestamps_df[click_rec_df.batch_id])\n",
    "click_rec_sites_df.first_click_timestamp = click_rec_sites_df[['batch_id','first_click_timestamp']].apply(lambda x: x.first_click_timestamp if x.first_click_timestamp != -1000 else random.choice(clicked_timestamps_df[x.batch_id]), axis = 1)\n",
    "click_rec_sites_df.sort_values(by=['batch_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_participant_ids = participant_user_ids #| nonparticipant_user_ids\n",
    "len(target_participant_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_b0_participant_ids = b0_participant_user_ids\n",
    "len(target_b0_participant_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(nonparticipant_user_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_user_ids = participant_user_ids | nonparticipant_user_ids\n",
    "len(target_user_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_b0_user_ids = b0_participant_user_ids | nonparticipant_user_ids\n",
    "len(target_b0_user_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trim down the available profile data\n",
    "profile_df = profile_df[profile_df.user_id.isin(target_user_ids)].copy()\n",
    "account_creation_time_map = {row.user_id: row.createdAt for row in profile_df.itertuples()}\n",
    "len(profile_df), len(account_creation_time_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recced_usps = set([(row.participant_id, row.site_id) for row in rec_df.itertuples()])\n",
    "recced_sites = set(rec_df.site_id)\n",
    "len(recced_sites), len(recced_usps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b0_recced_usps = set([(row.participant_id, row.site_id) for row in rec_df[rec_df.batch_id == 0].itertuples()])\n",
    "b0_recced_sites = set(rec_df[rec_df.batch_id == 0].site_id)\n",
    "len(b0_recced_sites), len(b0_recced_usps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data modeling\n",
    "\n",
    "Useful docs: https://www.statsmodels.org/stable/api.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (P) Reading behavior: summarize in terms of repeat-visit effect size\n",
    "repeat-visits per participant (given the treatment of 11 rec emails with 5 sites each): compute mean and stddev\n",
    "\n",
    "What is the effect size? compute with formula\n",
    "\n",
    "Compute needed sample size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visits_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lest = last_sse_time - first_sse_time\n",
    "lest.days / 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scratchpad cell\n",
    "one_day = 1000 * 60 * 60 * 24\n",
    "threefive_days = one_day * 35\n",
    "time_window = threefive_days\n",
    "\n",
    "start_timestamp = first_sse_timestamp\n",
    "end_timestamp = last_sse_timestamp + time_window\n",
    "\n",
    "#df = pd.DataFrame(index=pd.Series(sorted(target_user_ids)))\n",
    "all = True\n",
    "\n",
    "svisits_df = visits_df[(visits_df.user_id.isin(target_user_ids))]\n",
    "if not all:\n",
    "    svisits_df = svisits_df[svisits_df.usp.isin(recced_usps)]\n",
    "first_visit = svisits_df.groupby(['user_id', 'site_id']).visit_timestamp.min().reset_index()\n",
    "print(first_visit)\n",
    "first_visit = first_visit[(first_visit.visit_timestamp >= start_timestamp)&(first_visit.visit_timestamp <= end_timestamp)]\n",
    "                  \n",
    "valid_visit_usps = set([(row.user_id, row.site_id) for row in first_visit.itertuples()])\n",
    "\n",
    "svisits_df = svisits_df[(svisits_df.visit_timestamp >= start_timestamp)&(svisits_df.visit_timestamp <= end_timestamp)&(svisits_df.usp.isin(valid_visit_usps))]\n",
    "n_repeat_visits = svisits_df.groupby(['user_id', 'site_id']).visit_timestamp.count() - 1\n",
    "n_second_visits = n_repeat_visits[n_repeat_visits > 0].groupby('user_id').count().rename(\"n_second_visits\")\n",
    "print(n_second_visits)\n",
    "\n",
    "\n",
    "svisits_df = visits_df[(visits_df.visit_timestamp >= start_timestamp)&(visits_df.visit_timestamp <= end_timestamp)&(visits_df.user_id.isin(target_user_ids))]\n",
    "if not all:\n",
    "    svisits_df = svisits_df[svisits_df.usp.isin(recced_usps)]\n",
    "n_repeat_visits = svisits_df.groupby(['user_id', 'site_id']).visit_timestamp.count() - 1\n",
    "n_second_visits = n_repeat_visits[n_repeat_visits > 0].groupby('user_id').count().rename(\"n_second_visits\")\n",
    "print(n_second_visits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_window_effects(start_timestamp, end_timestamp, target_user_ids, all=False):\n",
    "    df = pd.DataFrame(index=pd.Series(sorted(target_user_ids)))\n",
    "    \n",
    "    svisits_df = visits_df[(visits_df.user_id.isin(target_user_ids))]\n",
    "    if not all:\n",
    "        svisits_df = svisits_df[svisits_df.usp.isin(recced_usps)]\n",
    "    first_visit = svisits_df.groupby(['user_id', 'site_id']).visit_timestamp.min().reset_index()\n",
    "    first_visit = first_visit[(first_visit.visit_timestamp >= start_timestamp)&(first_visit.visit_timestamp <= end_timestamp)]\n",
    "\n",
    "    valid_visit_usps = set([(row.user_id, row.site_id) for row in first_visit.itertuples()])\n",
    "\n",
    "    svisits_df = svisits_df[(svisits_df.visit_timestamp >= start_timestamp)&(svisits_df.visit_timestamp <= end_timestamp)&(svisits_df.usp.isin(valid_visit_usps))]\n",
    "    n_repeat_visits = svisits_df.groupby(['user_id', 'site_id']).visit_timestamp.count() - 1\n",
    "    n_second_visits = n_repeat_visits[n_repeat_visits > 0].groupby('user_id').count().rename(\"n_second_visits\")\n",
    "    \n",
    "    sints_df = ints_df[(ints_df.created_at >= start_timestamp)&(ints_df.created_at <= end_timestamp)&(ints_df.user_id.isin(target_user_ids))]\n",
    "    if not all:\n",
    "        sints_df = sints_df[sints_df.usp.isin(recced_usps)]\n",
    "    is_self_interaction = sints_df.usp.isin(author_usp_set)\n",
    "    n_interactionswith = sints_df[~is_self_interaction]\\\n",
    "        .groupby(['user_id', 'site_id']).interaction_oid.nunique()\n",
    "    n_interactions = n_interactionswith.groupby('user_id').sum().rename(\"n_interactions\")\n",
    "    \n",
    "    df = df.join([n_second_visits,\n",
    "                  n_interactions\n",
    "    ])\n",
    "    \n",
    "    if all == False:\n",
    "        df['n_relationships'] = 0\n",
    "        df.at[864719, 'n_relationships'] = 1\n",
    "    \n",
    "    df = df.fillna(value=0)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_window_effects_b0(start_timestamp, end_timestamp, target_user_ids, all=False):\n",
    "    df = pd.DataFrame(index=pd.Series(sorted(target_user_ids)))\n",
    "        \n",
    "    svisits_df = visits_df[(visits_df.user_id.isin(target_user_ids))]\n",
    "    if not all:\n",
    "        svisits_df = svisits_df[(svisits_df.usp.isin(b0_recced_usps))&(~svisits_df.usp.isin(recced_usps - b0_recced_usps))]\n",
    "    else:\n",
    "        svisits_df = svisits_df[~svisits_df.usp.isin(recced_usps - b0_recced_usps)]\n",
    "    first_visit = svisits_df.groupby(['user_id', 'site_id']).visit_timestamp.min().reset_index()\n",
    "    first_visit = first_visit[(first_visit.visit_timestamp >= start_timestamp)&(first_visit.visit_timestamp <= end_timestamp)]\n",
    "\n",
    "    valid_visit_usps = set([(row.user_id, row.site_id) for row in first_visit.itertuples()])\n",
    "\n",
    "    svisits_df = svisits_df[(svisits_df.visit_timestamp >= start_timestamp)&(svisits_df.visit_timestamp <= end_timestamp)&(svisits_df.usp.isin(valid_visit_usps))]\n",
    "    n_repeat_visits = svisits_df.groupby(['user_id', 'site_id']).visit_timestamp.count() - 1\n",
    "    n_second_visits = n_repeat_visits[n_repeat_visits > 0].groupby('user_id').count().rename(\"n_second_visits\")\n",
    "    \n",
    "    sints_df = ints_df[(ints_df.created_at >= start_timestamp)&(ints_df.created_at <= end_timestamp)&(ints_df.user_id.isin(target_user_ids))]\n",
    "    if not all:\n",
    "        sints_df = sints_df[(sints_df.usp.isin(b0_recced_usps))&(~sints_df.usp.isin(recced_usps - b0_recced_usps))]\n",
    "    else:\n",
    "        sints_df = sints_df[~sints_df.usp.isin(recced_usps - b0_recced_usps)]\n",
    "        \n",
    "    is_self_interaction = sints_df.usp.isin(author_usp_set)\n",
    "    n_interactionswith = sints_df[~is_self_interaction]\\\n",
    "        .groupby(['user_id', 'site_id']).interaction_oid.nunique()\n",
    "    n_interactions = n_interactionswith.groupby('user_id').sum().rename(\"n_interactions\")\n",
    "    \n",
    "    df = df.join([n_second_visits,\n",
    "                  n_interactions\n",
    "    ])\n",
    "    \n",
    "    df = df.fillna(value=0)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.power import tt_ind_solve_power\n",
    "\n",
    "pretty_name_map = {\n",
    "    'n_second_visits': \"Second visits\",\n",
    "    'n_interactions': \"Interactions\", \n",
    "    'n_relationships': \"Relationships\", \n",
    "}\n",
    "\n",
    "cols = ['n_second_visits', 'n_interactions']\n",
    "one_day = 1000 * 60 * 60 * 24\n",
    "seven_days = one_day * 7\n",
    "time_windows = [one_day * 35]\n",
    "time_windows_names = [35]\n",
    "\n",
    "study_duration = (last_sse_time - first_sse_time).days #days\n",
    "\n",
    "raw = True\n",
    "\n",
    "#if not raw:\n",
    "    #print(f\"\\\\textbf{{Participants (Rec)}} & & & (n={len(df)}) & (n={len(df)}) & & & (n={len(b0_df)}) & (n={len(b0_df)}) \\\\\\\\\")\n",
    "    \n",
    "for i, time_window in enumerate(time_windows):\n",
    "    start_timestamp = first_sse_timestamp\n",
    "    end_timestamp = last_sse_timestamp + time_window\n",
    "    b0_end_timestamp = first_sse_timestamp + time_window\n",
    "    \n",
    "    df = compute_window_effects(start_timestamp, end_timestamp, target_participant_ids) / (study_duration + time_windows_names[i]) * 7\n",
    "    b0_df = compute_window_effects_b0(start_timestamp, b0_end_timestamp, target_b0_participant_ids) / time_windows_names[i] * 7\n",
    "    means = df.mean()\n",
    "    varis = df.var()\n",
    "    stds = df.std()\n",
    "    b0_means = b0_df.mean()\n",
    "    b0_varis = b0_df.var()\n",
    "    for df_i, (mean, var, b0_mean, b0_var, std) in enumerate(zip(means, varis, b0_means, b0_varis, stds)):\n",
    "        s = math.sqrt(((79 - 1) * 0 + (79 - 1) * var) / (79 + 79 - 2))\n",
    "        b0_s = math.sqrt(((73 - 1) * 0 + (73 - 1) * b0_var) / (73 + 73 - 2))\n",
    "        effect_size = (mean)/(s)\n",
    "        effect_size2 = (mean)/(std)\n",
    "        b0_effect_size = (b0_mean)/(b0_s)\n",
    "        n = tt_ind_solve_power(effect_size=effect_size, alpha=0.05, power=0.8, ratio=1, alternative='two-sided')\n",
    "        b0_n = tt_ind_solve_power(effect_size=b0_effect_size, alpha=0.05, power=0.8, ratio=1, alternative='two-sided')\n",
    "        if raw:\n",
    "            print(f\"{pretty_name_map[cols[df_i]]:>25} & {effect_size} & {n} & {mean} & 0 & {s} & {b0_effect_size} & {b0_n} & {b0_mean} & 0 & {b0_s} \\\\\\\\\")\n",
    "        else:\n",
    "            print(f\"\\\\quad {pretty_name_map[cols[df_i]]} & {effect_size:.2f} & {n:.0f} & {mean:.2f} ({var:.2f}) & 0 (0) & {b0_effect_size:.2f} & {b0_n:.0f} & {b0_mean:.2f} ({b0_var:.2f}) & 0 (0) \\\\\\\\\")\n",
    "            print(f\"{effect_size2:.2f}\")\n",
    "            #print(f\"& & & ({var:.2f}) & (0) & & ({b0_var:.2f}) & (0) & \\\\\\\\\")\n",
    "            \n",
    "            #print(f\"{pretty_name_map[df.columns[df_i]]:>25} & {effect_size:.2f} & {n:.0f} & {mean:.2f} & 0 & {s:.2f} & {b0_effect_size:.2f} & {b0_n:.0f} & {b0_mean:.2f} & 0 & {b0_s:.2f} \\\\\\\\\")\n",
    "    \n",
    "    s = math.sqrt(((79 - 1) * 0 + (79 - 1) * varis['n_relationships']) / (79 + 79 - 2))\n",
    "    effect_size = (means['n_relationships'])/(s)\n",
    "    mean_rel = means['n_relationships'] / time_windows_names[i]\n",
    "    s = s / time_windows_names[i]\n",
    "    n = tt_ind_solve_power(effect_size=effect_size, alpha=0.05, power=0.8, ratio=1, alternative='two-sided')\n",
    "    print()\n",
    "    if raw:\n",
    "        print(f\"{'Relationships':>25} & {effect_size} & {n} & {mean_rel} & 0 & {s} & & & & &  \\\\\\\\\")\n",
    "    else:\n",
    "        print(f\"{'Relationships':>25} & {effect_size:.2f} & {n:.0f} & {mean_rel:.2f} & 0 & {s:.2f} & & & & &  \\\\\\\\\")\n",
    "\n",
    "print(f\"All: n={len(df)}\")\n",
    "print(f\"b0: n={len(b0_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.power import tt_ind_solve_power\n",
    "\n",
    "pretty_name_map = {\n",
    "    'n_second_visits': \"Second visits\",\n",
    "    'n_interactions': \"Interactions\", \n",
    "    'n_relationships': \"Relationships\", \n",
    "}\n",
    "\n",
    "cols = ['n_second_visits', 'n_interactions']\n",
    "one_day = 1000 * 60 * 60 * 24\n",
    "seven_days = one_day * 7\n",
    "time_windows = [one_day * 35]\n",
    "time_windows_names = [35]\n",
    "\n",
    "study_duration = (last_sse_time - first_sse_time).days #days\n",
    "\n",
    "raw = True\n",
    "if not raw:\n",
    "    print(f\"\\\\textbf{{Participants(All)}} & & & (n={p_n}) & (n={pc_n}) & & & (n={p_b0_n}) & (n={pc_b0_n}) \\\\\\\\\")\n",
    "\n",
    "for i, time_window in enumerate(time_windows):\n",
    "    start_timestamp = first_sse_timestamp\n",
    "    end_timestamp = last_sse_timestamp + time_window\n",
    "    b0_end_timestamp = first_sse_timestamp + time_window\n",
    "    \n",
    "    df_pre = compute_window_effects(start_timestamp - time_window, start_timestamp, target_user_ids, all=True) / time_windows_names[i] * 7\n",
    "    df_pre['is_participant'] = df_pre.index.isin(target_participant_ids).astype(int)\n",
    "    df_post = compute_window_effects(start_timestamp, end_timestamp, target_user_ids, all=True) / (study_duration + time_windows_names[i]) * 7\n",
    "    df_post['is_participant'] = df_post.index.isin(target_participant_ids).astype(int)\n",
    "    \n",
    "    b0_df_pre = compute_window_effects_b0(start_timestamp - time_window, start_timestamp, target_b0_user_ids, all=True) / time_windows_names[i] * 7\n",
    "    b0_df_pre['is_participant'] = b0_df_pre.index.isin(target_b0_participant_ids).astype(int)\n",
    "    b0_df_post = compute_window_effects_b0(start_timestamp, b0_end_timestamp, target_b0_user_ids, all=True) / time_windows_names[i] * 7\n",
    "    b0_df_post['is_participant'] = b0_df_post.index.isin(target_b0_participant_ids).astype(int)\n",
    "    \n",
    "    p_n = len(df_pre[df_pre.is_participant == 1])\n",
    "    pc_n = len(df_pre[df_pre.is_participant == 0])\n",
    "    \n",
    "    p_b0_n = len(b0_df_pre[b0_df_pre.is_participant == 1])\n",
    "    pc_b0_n = len(b0_df_pre[b0_df_pre.is_participant == 0])\n",
    "    \n",
    "    p_means = (df_pre[df_pre.is_participant == 1] - df_post[df_post.is_participant == 1]).mean()[cols] \n",
    "    pc_means = (df_pre[df_pre.is_participant == 0] - df_post[df_post.is_participant == 0]).mean()[cols]\n",
    "    p_varis = (df_pre[df_pre.is_participant == 1] - df_post[df_post.is_participant == 1]).var()[cols]\n",
    "    pc_varis = (df_pre[df_pre.is_participant == 0] - df_post[df_post.is_participant == 0]).var()[cols]\n",
    "    \n",
    "    p_b0_means = (b0_df_pre[b0_df_pre.is_participant == 1] - b0_df_post[b0_df_post.is_participant == 1]).mean()[cols]\n",
    "    pc_b0_means = (b0_df_pre[b0_df_pre.is_participant == 0] - b0_df_post[b0_df_post.is_participant == 0]).mean()[cols]\n",
    "    p_b0_varis = (b0_df_pre[b0_df_pre.is_participant == 1] - b0_df_post[b0_df_post.is_participant == 1]).var()[cols]\n",
    "    pc_b0_varis = (b0_df_pre[b0_df_pre.is_participant == 0] - b0_df_post[b0_df_post.is_participant == 0]).var()[cols]\n",
    "    \n",
    "    for df_i, (p_mean, p_var, pc_mean, pc_var, p_b0_mean, p_b0_var, pc_b0_mean, pc_b0_var) in enumerate(zip(p_means, p_varis, pc_means, pc_varis, p_b0_means, p_b0_varis, pc_b0_means, pc_b0_varis)):\n",
    "        s = math.sqrt(((p_n - 1) * p_var + (pc_n - 1) * pc_var) / (p_n + pc_n - 2))\n",
    "        b0_s = math.sqrt(((p_b0_n - 1) * p_b0_var + (pc_b0_n - 1) * pc_b0_var) / (p_b0_n + pc_b0_n - 2))\n",
    "        effect_size = (pc_mean - p_mean)/(s)\n",
    "        b0_effect_size = (pc_b0_mean - p_b0_mean)/(b0_s)\n",
    "        n = tt_ind_solve_power(effect_size=effect_size, alpha=0.05, power=0.8, ratio=1, alternative='two-sided')\n",
    "        b0_n = tt_ind_solve_power(effect_size=b0_effect_size, alpha=0.05, power=0.8, ratio=1, alternative='two-sided')\n",
    "        \n",
    "#         p_mean = p_mean / time_windows_names[i]\n",
    "#         pc_mean = p_mean / time_windows_names[i]\n",
    "#         p_b0_mean = p_mean / time_windows_names[i]\n",
    "#         pc_b0_mean = p_mean / time_windows_names[i]\n",
    "#         s = s / time_windows_names[i]\n",
    "#         b0_s = b0_s / time_windows_names[i]\n",
    "        if raw:\n",
    "            print(f\"{pretty_name_map[cols[df_i]]} & {effect_size} & {n} & {p_mean} & {pc_mean} & {s} & {b0_effect_size} & {b0_n} & {p_b0_mean} & {pc_b0_mean} & {b0_s} \\\\\\\\\")\n",
    "        else:            \n",
    "            print(f\"\\\\quad {pretty_name_map[cols[df_i]]} & {effect_size:.2f} & {n:.0f} & {p_mean:.2f} ({p_var:.2f}) & {pc_mean:.2f} ({pc_var:.2f}) & {b0_effect_size:.2f} & {b0_n:.0f} & {p_b0_mean:.2f} ({p_b0_var:.2f}) & {pc_b0_mean:.2f} ({pc_b0_var:.2f}) \\\\\\\\\")\n",
    "            #print(f\"& & & ({p_var:.2f}) & ({pc_var:.2f}) & & ({p_b0_var:.2f}) & ({pc_b0_var:.2f}) & \\\\\\\\\")\n",
    "\n",
    "print(f\"All: {p_n}/{pc_n}\")\n",
    "print(f\"b0: {p_b0_n}/{pc_b0_n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (R) Journaling effects on recommended sites: summarize in Journal updates\n",
    "\n",
    "Post-study Journal updates / clicked site\n",
    "\n",
    "Post-study Journal updates / non-clicked sites\n",
    "\n",
    "click_rec_sites_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scratchpad cell\n",
    "one_day = 1000 * 60 * 60 * 24\n",
    "thirty_five_days = one_day * 35\n",
    "\n",
    "back_window = thirty_five_days\n",
    "front_window = thirty_five_days\n",
    "\n",
    "df = click_rec_sites_df[['first_click_timestamp', 'was_clicked']]\n",
    "\n",
    "sjournal_df = df.merge(journal_df[['site_id','published_at','user_id','journal_oid']], how='left', on='site_id')\n",
    "\n",
    "sjournal_df_pre = sjournal_df[(sjournal_df.first_click_timestamp - sjournal_df.published_at >= 0)&(sjournal_df.first_click_timestamp - sjournal_df.published_at <= back_window)]\n",
    "sjournal_df_post = sjournal_df[(sjournal_df.published_at - sjournal_df.first_click_timestamp >= 0)&(sjournal_df.published_at - sjournal_df.first_click_timestamp <= front_window)]\n",
    "\n",
    "n_updates_pre = sjournal_df_pre.groupby('site_id').journal_oid.nunique().rename(\"n_updates_pre\")\n",
    "n_updates_post = sjournal_df_post.groupby('site_id').journal_oid.nunique().rename(\"n_updates_post\")\n",
    "\n",
    "df = df.join([n_updates_pre, \n",
    "              n_updates_post\n",
    "])\n",
    "\n",
    "\n",
    "df = df.fillna(value=0)\n",
    "\n",
    "clicked_diff = df[df.was_clicked == 1].n_updates_pre - df[df.was_clicked == 1].n_updates_post \n",
    "not_clicked_diff = df[df.was_clicked == 0].n_updates_pre - df[df.was_clicked == 0].n_updates_post \n",
    "print(df)\n",
    "print(f\"Clicked Difference - Mean:{clicked_diff.mean()}, Std:{clicked_diff.std()}, n={len(clicked_diff)}\")\n",
    "print(f\"Not Clicked Difference - Mean:{not_clicked_diff.mean()}, Std:{not_clicked_diff.std()}, n={len(not_clicked_diff)}\")\n",
    "# print(f\"Standard Deviation:{df.std()}\")\n",
    "# #m2 - m1 / sdpool\n",
    "# #sdpool = root((sd1^2 + sd2^2)/2)\n",
    "\n",
    "# #print(\n",
    "# print(f\"Effect size:{(df.mean())/(0 + math.sqrt((df.std() ** 2)/2))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_window_rec_effects(back_window, front_window, df):    \n",
    "    sjournal_df = df.merge(journal_df[['site_id','published_at','user_id','journal_oid']], how='left', on='site_id')\n",
    "\n",
    "    sjournal_df_pre = sjournal_df[(sjournal_df.first_click_timestamp - sjournal_df.published_at >= 0)&(sjournal_df.first_click_timestamp - sjournal_df.published_at <= back_window)]\n",
    "    sjournal_df_post = sjournal_df[(sjournal_df.published_at - sjournal_df.first_click_timestamp >= 0)&(sjournal_df.published_at - sjournal_df.first_click_timestamp <= front_window)]\n",
    "\n",
    "    n_updates_pre = sjournal_df_pre.groupby('site_id').journal_oid.nunique().rename(\"n_updates_pre\")\n",
    "    n_updates_post = sjournal_df_post.groupby('site_id').journal_oid.nunique().rename(\"n_updates_post\")\n",
    "\n",
    "    df = df.join([n_updates_pre, \n",
    "                  n_updates_post\n",
    "    ])\n",
    "\n",
    "\n",
    "    df = df.fillna(value=0)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.power import tt_ind_solve_power\n",
    "\n",
    "one_day = 1000 * 60 * 60 * 24\n",
    "thirty_five_days = one_day * 35\n",
    "\n",
    "b0_click_rec_sites_df = click_rec_sites_df[click_rec_sites_df.batch_id == 0]\n",
    "\n",
    "time_windows = [one_day * 35]\n",
    "time_windows_names = [35]\n",
    "backslash_char = \"\\\\\"\n",
    "\n",
    "raw = True\n",
    "#print(f\"\\\\multicolumn{{3}}{{l}}{{\\\\textbf{{Recommended Site}}}} & (n={len(clicked_diff)}) & (n={len(not_clicked_diff)}) & & & (n={len(b0_clicked_diff)}) & (n={len(b0_not_clicked_diff)}) \\\\\\\\\")\n",
    "for i, time_window in enumerate(time_windows):\n",
    "    back_window = time_window\n",
    "    front_window = time_window\n",
    "    \n",
    "    df = compute_window_rec_effects(back_window, front_window, click_rec_sites_df[['first_click_timestamp', 'was_clicked']]) \n",
    "    b0_df = compute_window_rec_effects(back_window, front_window, b0_click_rec_sites_df[['first_click_timestamp', 'was_clicked']])\n",
    "    \n",
    "    \n",
    "    clicked_diff = (df[df.was_clicked == 1].n_updates_pre / time_windows_names[i] * 7 ) - (df[df.was_clicked == 1].n_updates_post / time_windows_names[i] * 7)\n",
    "    not_clicked_diff = (df[df.was_clicked == 0].n_updates_pre / time_windows_names[i] * 7) - (df[df.was_clicked == 0].n_updates_post / time_windows_names[i] * 7)\n",
    "    \n",
    "    b0_clicked_diff = (b0_df[b0_df.was_clicked == 1].n_updates_pre / time_windows_names[i] * 7) - (b0_df[b0_df.was_clicked == 1].n_updates_post / time_windows_names[i] * 7)\n",
    "    b0_not_clicked_diff = (b0_df[b0_df.was_clicked == 0].n_updates_pre / time_windows_names[i] * 7)- (b0_df[b0_df.was_clicked == 0].n_updates_post / time_windows_names[i] * 7)\n",
    "    \n",
    "    c_mean = clicked_diff.mean()\n",
    "    c_var = clicked_diff.var()\n",
    "    nc_mean = not_clicked_diff.mean()\n",
    "    nc_var = not_clicked_diff.var()\n",
    "    \n",
    "    b0_c_mean = b0_clicked_diff.mean()\n",
    "    b0_c_var = b0_clicked_diff.var()\n",
    "    b0_nc_mean = b0_not_clicked_diff.mean()\n",
    "    b0_nc_var = b0_not_clicked_diff.var()\n",
    "    \n",
    "    s = math.sqrt(((len(not_clicked_diff) - 1) * nc_var + (len(clicked_diff) - 1) * c_var) / (len(clicked_diff) + len(not_clicked_diff) - 2))\n",
    "    b0_s = math.sqrt(((len(b0_not_clicked_diff) - 1) * b0_nc_var + (len(b0_clicked_diff) - 1) * b0_c_var) / (len(b0_clicked_diff) + len(b0_not_clicked_diff) - 2))\n",
    "    effect_size = (nc_mean - c_mean)/(s)\n",
    "    b0_effect_size = (b0_nc_mean - b0_c_mean)/(b0_s)\n",
    "    \n",
    "    n = tt_ind_solve_power(effect_size=effect_size, alpha=0.05, power=0.8, alternative='two-sided')\n",
    "    b0_n = tt_ind_solve_power(effect_size=b0_effect_size, alpha=0.05, power=0.8, alternative='two-sided')\n",
    "    \n",
    "    c_mean = c_mean / time_windows_names[i]\n",
    "    nc_mean = nc_mean / time_windows_names[i]\n",
    "    b0_c_mean = b0_c_mean / time_windows_names[i]\n",
    "    b0_nc_mean = b0_nc_mean / time_windows_names[i]\n",
    "    s = s / time_windows_names[i]\n",
    "    b0_s = b0_s / time_windows_names[i]\n",
    "    \n",
    "    if raw:\n",
    "        print(f\"\\\\quad Updates & {effect_size} & {n} & {c_mean} & {nc_mean} & {s} & {b0_effect_size} & {b0_n} & {b0_c_mean} & {b0_nc_mean} & {b0_s} \\\\\\\\\")\n",
    "    else:\n",
    "        print(f\"\\\\quad Updates & {effect_size:.2f} & {n:.0f} & {c_mean:.2f} ({c_var:.2f}) & {nc_mean:.2f} ({nc_var:.2f}) & {b0_effect_size:.2f} & {b0_n:.0f} & {b0_c_mean:.2f} ({b0_c_var:.2f}) & {b0_nc_mean:.2f} ({b0_nc_var:.2f}) \\\\\\\\\")\n",
    "        print(f\"& & & ({c_var:.2f}) & ({nc_var:.2f}) & & ({b0_c_var:.2f}) & ({b0_nc_var:.2f}) & \\\\\\\\\")\n",
    "\n",
    "print(f\"All: {len(clicked_diff)}/{len(not_clicked_diff)}\")\n",
    "print(f\"b0: {len(b0_clicked_diff)}/{len(b0_not_clicked_diff)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b0_click_rec_sites_df = click_rec_sites_df[click_rec_sites_df.batch_id == 0]\n",
    "set_b0 = set(b0_click_rec_sites_df.reset_index()['site_id'])\n",
    "len(set_b0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "click_rec_sites_df[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_window_features(start_timestamp, end_timestamp, target_user_ids, postfix, exclude_recommended_sites=False):\n",
    "    df = pd.DataFrame(index=pd.Series(sorted(target_user_ids)))\n",
    "        \n",
    "    #n_updates_total = journal_df[(journal_df.published_at <= end_timestamp)].groupby('user_id').journal_oid.nunique().rename(\"n_updates_total\" + postfix)\n",
    "    n_updates = journal_df[(journal_df.published_at >= start_timestamp)&(journal_df.published_at <= end_timestamp)].groupby('user_id').journal_oid.nunique().rename(\"n_updates\" + postfix)\n",
    "    \n",
    "    sints_df = ints_df[(ints_df.created_at >= start_timestamp)&(ints_df.created_at <= end_timestamp)&(ints_df.user_id.isin(target_user_ids))]\n",
    "    if exclude_recommended_sites:\n",
    "        sints_df = sints_df[~sints_df.usp.isin(recced_usps)]\n",
    "    is_self_interaction = sints_df.usp.isin(author_usp_set)\n",
    "    n_interactionswith = sints_df[~is_self_interaction]\\\n",
    "        .groupby(['user_id', 'site_id']).interaction_oid.nunique()\n",
    "    n_text_interactionswith = sints_df[(~is_self_interaction)&(~sints_df.interaction_type.str.startswith(\"amp\"))]\\\n",
    "        .groupby(['user_id', 'site_id']).interaction_oid.nunique()\n",
    "\n",
    "    n_interactionswith_self = sints_df[is_self_interaction]\\\n",
    "        .groupby(['user_id', 'site_id']).interaction_oid.nunique()\n",
    "    n_text_interactionswith_self = sints_df[(is_self_interaction)&(~sints_df.interaction_type.str.startswith(\"amp\"))]\\\n",
    "        .groupby(['user_id', 'site_id']).interaction_oid.nunique()\n",
    "        \n",
    "    # note: we can use sum() and count() here because this is a series; sum adds the number of interactions, count is the number of rows after removing the second level of the index (site_id)\n",
    "    n_interactions = n_interactionswith.groupby('user_id').sum().rename(\"n_interactions\" + postfix)\n",
    "    n_sites_interactedwith = n_interactionswith.groupby('user_id').count().rename(\"n_sites_interactedwith\" + postfix)    \n",
    "    n_text_interactions = n_text_interactionswith.groupby('user_id').sum().rename(\"n_text_interactions\" + postfix)\n",
    "    n_sites_interactedwith_text = n_text_interactionswith.groupby('user_id').count().rename(\"n_sites_interactedwith_text\" + postfix)\n",
    "    n_self_interactions = n_interactionswith_self.groupby('user_id').sum().rename(\"n_self_interactions\" + postfix)\n",
    "    n_self_sites_interactedwith = n_interactionswith_self.groupby('user_id').count().rename(\"n_self_sites_interactedwith\" + postfix)\n",
    "        \n",
    "    sfirst_visit_df = first_visit_df[(first_visit_df.created_at >= start_timestamp)&(first_visit_df.created_at <= end_timestamp)]\n",
    "    if exclude_recommended_sites:\n",
    "        sfirst_visit_df = sfirst_visit_df[~sfirst_visit_df.usp.isin(recced_usps)]\n",
    "    n_first_visits = sfirst_visit_df.groupby('user_id').created_at.count().rename(\"n_first_visits\" + postfix)\n",
    "    \n",
    "    svisits_df = visits_df[(visits_df.visit_timestamp >= start_timestamp)&(visits_df.visit_timestamp <= end_timestamp)&(visits_df.user_id.isin(target_user_ids))]\n",
    "    if exclude_recommended_sites:\n",
    "        svisits_df = svisits_df[~svisits_df.usp.isin(recced_usps)]\n",
    "    # how many days did each user visit another author's site?\n",
    "    # NOTE: n_days_visited and n_sites_repeat_visisted is only valid within certain date ranges, because it depends on the site_profile snapshots\n",
    "    n_days_visited = svisits_df.groupby('user_id').visit_date.nunique().rename(\"n_days_visited\" + postfix)\n",
    "    n_repeat_visits = svisits_df.groupby(['user_id', 'site_id']).visit_timestamp.count() - 1\n",
    "    n_sites_repeat_visited = n_repeat_visits[n_repeat_visits > 0].groupby('user_id').count().rename(\"n_sites_repeat_visited\" + postfix)\n",
    "    #n_sites_visited = svisits_df.groupby('user_id').site_id.nunique().rename(\"n_sites_visited\" + postfix)\n",
    "    # assert np.all(n_sites_visited == n_first_visits)\n",
    "    \n",
    "    \n",
    "    # compute prestudy specific features\n",
    "    first_journal_update_timestamps = journal_df.groupby('user_id').created_at.min()\n",
    "    time_since_first_journal_update = (end_timestamp - first_journal_update_timestamps).rename(\"time_since_first_journal_update\" + postfix) / 1000 / 60 / 60 / 24  # in days\n",
    "    if np.any(time_since_first_journal_update[time_since_first_journal_update.index.isin(target_user_ids)] < 0):\n",
    "        logging.warning(\"Some target_user_ids have a first journal update time that's after end_timestamp; is that expected?\")\n",
    "        \n",
    "    #signup_timestamps = df.index.map(lambda user_id: account_creation_time_map[user_id]).to_series(index=df.index, name=\"signup_timestamps\")\n",
    "    #time_since_signup = (end_timestamp - signup_timestamps).rename(\"time_since_signup\" + postfix) / 1000 / 60 / 60 / 24  # in days\n",
    "    \n",
    "    df = df.join([n_updates, \n",
    "                  n_sites_interactedwith, \n",
    "                  n_self_sites_interactedwith, \n",
    "                  n_sites_interactedwith_text, \n",
    "                  n_interactions, \n",
    "                  n_self_interactions,\n",
    "                  n_text_interactions,\n",
    "                  n_first_visits,\n",
    "                  n_days_visited,\n",
    "                  n_sites_repeat_visited,\n",
    "                  time_since_first_journal_update,\n",
    "    ])\n",
    "    \n",
    "    df = df.fillna(value=0)\n",
    "\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_timestamp = first_sse_timestamp\n",
    "start_timestamp = 0\n",
    "total_df = compute_window_features(start_timestamp, end_timestamp, target_user_ids, \"\")\n",
    "len(total_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df['average_daily_updates'] = total_df.n_updates / total_df.time_since_first_journal_update\n",
    "total_df['is_participant'] = total_df.index.isin(participant_user_ids).astype(int)\n",
    "total_df.is_participant.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df.groupby('is_participant').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df.groupby('is_participant').agg(['median', 'mean', 'std', 'min', 'max']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretty_name_map = {\n",
    "    'time_since_first_journal_update': \"Author tenure (days)\",\n",
    "    'n_updates': \"Journal updates\",\n",
    "    'n_first_visits': \"Peer site visits\",\n",
    "    'n_sites_interactedwith': \"Peer site initiations\", \n",
    "    'n_interactions': \"Peer site interactions\", \n",
    "}\n",
    "cols = pretty_name_map.keys()\n",
    "for col in cols:\n",
    "    t = total_df.loc[total_df.is_participant == 1, col]\n",
    "    c = total_df.loc[total_df.is_participant == 0, col]\n",
    "    \n",
    "    tstat, p = scipy.stats.ttest_ind(t, c, equal_var=False)\n",
    "    diff = t.mean() - c.mean()\n",
    "    #p *= len(cols)  # bonferroni correction\n",
    "    \n",
    "    ustat, up = scipy.stats.mannwhitneyu(t, c)\n",
    "    #up *= len(cols)\n",
    "    \n",
    "    threshold = 0.005\n",
    "    \n",
    "    print(f\"{pretty_name_map[col]:>25} & {t.median():.0f} & {t.mean():.1f} ({t.std():.1f}) & {c.median():.0f} & {c.mean():.1f} ({c.std():.1f}) & {diff:.1f}{'*' if p < threshold else ''} & {ustat / (len(t)*len(c)) * 100:.1f}\\\\%{'*' if up < threshold else ''} \\\\\\\\\")\n",
    "    print(\"\\\\includegraphics[width=0.8in]{figures/\" + col + \"_hist_small.pdf} & & & & & & \\\\\\\\\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make little histograms\n",
    "# inspired from: https://github.com/levon003/icwsm-cancer-journeys/blob/master/identify_candidate_sites/ClassificationCandidateSites.ipynb\n",
    "\n",
    "cols = pretty_name_map.keys()\n",
    "for col in cols:\n",
    "    t = total_df.loc[total_df.is_participant == 1, col]\n",
    "    c = total_df.loc[total_df.is_participant == 0, col]\n",
    "    \n",
    "    d = t\n",
    "    fig, ax = plt.subplots(figsize=(1, 0.3), squeeze=True)\n",
    "    nunique = d[d < np.quantile(d, 0.9)].nunique()\n",
    "    if nunique < 30:\n",
    "        bins = np.arange(0, 30)\n",
    "        p = d\n",
    "    else:\n",
    "        bins=30\n",
    "        p = d[d < np.quantile(d, 0.9)]\n",
    "    _, bins, _ = ax.hist(p, bins=bins, align=\"left\", color=\"black\", density=True)\n",
    "    ax.hist(c, bins=bins, align=\"left\", color=\"gray\", density=True)\n",
    "    plt.tight_layout()\n",
    "    print(col, nunique)\n",
    "    \n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.margins(0,0)\n",
    "    plt.gca().xaxis.set_major_locator(plt.NullLocator())\n",
    "    plt.gca().yaxis.set_major_locator(plt.NullLocator())\n",
    "    \n",
    "    plt.tight_layout(pad=0)\n",
    "    plt.subplots_adjust(top = 0.4, bottom = 0, right = 1, left = 0, \n",
    "                hspace = 0, wspace = 0)\n",
    "\n",
    "    bbox = matplotlib.transforms.Bbox.from_bounds(0,0,1,0.2)\n",
    "    image_shortfilename = f\"{col}_hist_small.pdf\"\n",
    "    image_filename = os.path.join(figures_dir, image_shortfilename)\n",
    "    plt.savefig(image_filename, format='pdf', dpi=200, pad_inches=0, bbox_inches=bbox) #, transparent=True)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df[cols].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axes = pd.plotting.scatter_matrix(total_df[cols], alpha=0.3)\n",
    "#for ax in axes.flatten():\n",
    "#    ax.set_yscale('log')\n",
    "#    break\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smf.logit(formula=\"is_participant ~ n_updates + n_first_visits + n_sites_interactedwith + n_interactions + np.log(time_since_first_journal_update)\", data=total_df)\n",
    "res = model.fit(disp=0)\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smf.logit(formula=\"is_participant ~ np.log(time_since_first_journal_update) + n_updates\", data=total_df)\n",
    "res = model.fit(disp=0)\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre- vs Post- modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_day = 1000 * 60 * 60 * 24\n",
    "thirty_days = one_day * 30\n",
    "ninety_days = one_day * 90\n",
    "time_window = ninety_days\n",
    "\n",
    "# pre-study window features\n",
    "end_timestamp = first_sse_timestamp\n",
    "start_timestamp = end_timestamp - time_window\n",
    "prestudy_df = compute_window_features(start_timestamp, end_timestamp, target_user_ids, \"_prestudy\")\n",
    "\n",
    "# post-study window features\n",
    "start_timestamp = last_sse_timestamp\n",
    "end_timestamp = start_timestamp + time_window\n",
    "poststudy_df = compute_window_features(start_timestamp, end_timestamp, target_user_ids, \"_poststudy\", exclude_recommended_sites=True)\n",
    "\n",
    "df = pd.merge(prestudy_df, poststudy_df, left_index=True, right_index=True)\n",
    "\n",
    "df['is_participant'] = df.index.isin(participant_user_ids).astype(int)\n",
    "\n",
    "print(len(df))\n",
    "df.sample(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('is_participant').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the correlation matrix\n",
    "corr = df.corr()\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(11, 10))\n",
    "ms = ax.matshow(corr)\n",
    "\n",
    "for i in range(corr.shape[0]):\n",
    "    for j in range(corr.shape[1]):\n",
    "        ax.text(i, j, f\"{corr.iloc[i, j]:.2f}\", ha='center', va='center', fontsize=8)\n",
    "\n",
    "plt.xticks(range(df.select_dtypes(['number']).shape[1]), df.select_dtypes(['number']).columns, fontsize=8, rotation=20, ha='left')\n",
    "plt.yticks(range(df.select_dtypes(['number']).shape[1]), df.select_dtypes(['number']).columns, fontsize=8)\n",
    "cb = fig.colorbar(ms, ax=ax, shrink=0.7)\n",
    "cb.ax.tick_params(labelsize=8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ranges of the variables are generally small, which by Sandberg's \"log rule\" suggests log transforms are unlikely to be helpful\n",
    "# ptp = \"peak to peak\"\n",
    "df.agg(np.ptp).round(1).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lots of zero-counts...\n",
    "(df == 0).mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stddev is larger than means for several variables, which suggests over-dispersion\n",
    "# https://stats.oarc.ucla.edu/r/dae/negative-binomial-regression/\n",
    "df.groupby('is_participant').agg(['mean', 'std'])  # 'min', 'max'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# participants have fewer post-study updates compared to pre-study updates\n",
    "sdf = df[df.is_participant == 1]\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "# could optionally add some jitter:\n",
    "# + (np.random.random(len(sdf)) / 10)\n",
    "#ax.scatter(sdf.n_updates_prestudy + 1, sdf.n_updates_poststudy + 1, alpha=0.2, color='black')\n",
    "#hb = ax.hexbin(sdf.n_updates_prestudy, sdf.n_updates_poststudy, gridsize=10, bins='log', mincnt=0, extent=(0, 10, 0, 10))\n",
    "#bins = np.arange()\n",
    "counts, hbins, vbins, hb = ax.hist2d(sdf.n_updates_prestudy, sdf.n_updates_poststudy, \n",
    "    bins=[np.arange(0, np.max(sdf.n_updates_prestudy)+1), np.arange(0, np.max(sdf.n_updates_poststudy)+1)],\n",
    "    cmin=1,  norm=matplotlib.colors.LogNorm(), alpha=0.4)\n",
    "steps = np.arange(0, min(np.max(sdf.n_updates_prestudy)+1, np.max(sdf.n_updates_poststudy)+1))\n",
    "plt.step(steps, steps, color='darkgray')\n",
    "plt.step(steps, steps - 1, color='darkgray')\n",
    "for i in range(counts.shape[0]):\n",
    "    for j in range(counts.shape[1]):\n",
    "        if counts[i, j] > 0:\n",
    "            ax.text(hbins[i] + ((hbins[1] - hbins[0]) / 2), vbins[j] + ((vbins[1] - vbins[0]) / 2), \n",
    "                    f\"{counts[i, j]:.0f}\", \n",
    "                    ha='center', va='center', fontsize=8)\n",
    "#fig.colorbar(hb, ax=ax)\n",
    "#ax.set_xscale('log')\n",
    "#ax.set_yscale('log')\n",
    "ax.set_xlabel(\"# pre-study updates\")\n",
    "ax.set_ylabel(\"# post-study updates\")\n",
    "ax.set_title(\"Participant pre- and post-study Journal update counts\", fontsize=8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# difference between pre- and post-study updates for authors who had at least 1 update in the measurement period\n",
    "# participants had fewer updates in 80% of cases... compared to only 70% among control authors\n",
    "sdf = df[(df.n_updates_prestudy > 0)|(df.n_updates_poststudy > 0)]\n",
    "pd.crosstab(\n",
    "    sdf.is_participant, \n",
    "    (sdf.n_updates_poststudy - sdf.n_updates_prestudy)\\\n",
    "        .map(lambda diff: 'fewer' if diff < 0 else 'equal' if diff == 0 else 'more')\\\n",
    "        .rename(\"post - pre n_updates\"),\n",
    "    margins=True,\n",
    "    normalize='index',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = \"\"\"\n",
    "n_updates_poststudy ~ n_updates_prestudy\n",
    "    + is_participant \n",
    "    + np.log(time_since_first_journal_update_prestudy)\n",
    "    + n_first_visits_prestudy\n",
    "    + n_sites_repeat_visited_prestudy\n",
    "    + n_sites_interactedwith_prestudy\n",
    "    + n_interactions_prestudy\n",
    "    + n_self_sites_interactedwith_prestudy\n",
    "    + n_self_interactions_prestudy\n",
    "    + n_days_visited_prestudy\n",
    "\n",
    "\"\"\"\n",
    "md = smf.ols(formula=formula, data=df)\n",
    "res = md.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stats.oarc.ucla.edu/r/dae/negative-binomial-regression/\n",
    "formula = \"\"\"\n",
    "n_updates_poststudy ~ n_updates_prestudy \n",
    "    + is_participant \n",
    "    + np.log(time_since_first_journal_update_prestudy)\n",
    "    + n_first_visits_prestudy\n",
    "    + n_sites_interactedwith_prestudy\n",
    "    + n_interactions_prestudy\n",
    "    + n_days_visited_prestudy\n",
    "    + n_sites_repeat_visited_prestudy\n",
    "\"\"\"\n",
    "md = smf.poisson(formula=formula, data=df)\n",
    "res = md.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the hc0 sandwich covariance estimator\n",
    "# (at least I think it is)\n",
    "# not sure if the exog matrix needs whitening?\n",
    "wexog = md.exog #np.dot(cholsigmainv, res.exog)  # no weighting, so no whitening required?\n",
    "pinv_wexog = np.linalg.pinv(wexog)\n",
    "het_scale = res.resid.to_numpy()**2\n",
    "H = np.dot(pinv_wexog, het_scale[:,None]*pinv_wexog.T)\n",
    "cov_hc0 = H\n",
    "hc0_se = np.sqrt(np.diag(cov_hc0))\n",
    "hc0_se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_standard = 2 * scipy.stats.norm.sf(np.abs(res.params / res.bse))\n",
    "ps_robust = 2 * scipy.stats.norm.sf(np.abs(res.params / hc0_se))\n",
    "for col, param, se, rse, p_standard, p_robust in zip(res.params.index, res.params, res.bse, hc0_se, ps_standard, ps_robust):\n",
    "    l = param - 1.96 * se\n",
    "    u = param + 1.96 * se\n",
    "    rl = param - 1.96 * rse\n",
    "    ru = param + 1.96 * rse\n",
    "    print(f\"{col:>50} {(np.exp(param) - 1) * 100:.2f}% {param:7.3f} | {se:.3f} ({p_standard:.3f}) [{l:6.3f} , {u:6.3f}] | {rse:.3f} ({p_robust:.3f}) [{rl:6.3f} , {ru:6.3f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can varify that the model converged\n",
    "res.mle_retvals['converged']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md.hessian(res.params).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the negative binomial (or poisson?) model, these are incidence rate ratios\n",
    "# 1 additional pre-study update is assocaited with a 19% increase in the number of post-study updates\n",
    "# being a participant (vs the control group) is associated with a 96% increase in the number of post-study updates...\n",
    "np.exp(res.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the design matrix is stored md.exog\n",
    "md.exog.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import statsmodels.family\n",
    "md = smf.glm(formula=formula, data=df, family=statsmodels.genmod.families.family.Poisson())\n",
    "\n",
    "res = md.fit()\n",
    "print(\"default\")\n",
    "print(res.summary().tables[1])\n",
    "\n",
    "res = md.fit(cov_type='HC0')\n",
    "print(\"hc0\")\n",
    "print(res.summary().tables[1])\n",
    "\n",
    "res = md.fit(cov_type='HC1')\n",
    "print(\"hc1\")\n",
    "print(res.summary().tables[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = smf.glm(formula=formula, data=df, family=statsmodels.genmod.families.family.Poisson())\n",
    "res = md.fit(cov_type='HC0')\n",
    "for line in res.summary().tables[0].as_csv().split(\"\\n\"):\n",
    "    if \"Pearson chi2\" in line:\n",
    "        chi2 = float(line.split(\",\")[-1])\n",
    "        print(chi2)\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I think this might be the appropriate p-value? Or not?\n",
    "scipy.stats.chi2(1829).sf(7900.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = smf.glm(formula=formula, data=df, family=statsmodels.genmod.families.family.Poisson())\n",
    "res = md.fit(cov_type='HC0')\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#res.bse\n",
    "list(res.conf_int().loc['is_participant'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparing two OLS (linear regression) models\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "\n",
    "for use_interaction in [0, 1]:\n",
    "    if use_interaction == 1:\n",
    "        formula = 'n_updates_prestudy + is_participant + is_participant*n_updates_prestudy'\n",
    "    else:\n",
    "        formula = 'n_updates_prestudy + is_participant'\n",
    "    md = smf.ols(formula='n_updates_poststudy ~ ' + formula, data=df)\n",
    "    res = md.fit()\n",
    "    \n",
    "    for is_participant in [0, 1]:\n",
    "        xs = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "        ys = []\n",
    "        for nu in xs:\n",
    "            \n",
    "            # note: this approach correctly creates a design matrix from a formula, but is not necessary: res.predict() will do the appropriate transformations for you\n",
    "            #import patsy\n",
    "            #X = patsy.dmatrix(formula, pd.DataFrame([{'is_participant': is_participant, 'n_updates_prestudy': nu}]))\n",
    "            \n",
    "            # create a dataframe with the appropriate variables in order to do prediction\n",
    "            X = pd.DataFrame([{'is_participant': is_participant, 'n_updates_prestudy': nu}])\n",
    "            pred = res.predict(X).iloc[0]\n",
    "\n",
    "            ys.append(pred)\n",
    "            l1 = 'Control' if is_participant == 0 else 'Treatment'\n",
    "            l2 = 'NoInt' if use_interaction == 0 else 'Int'\n",
    "        plt.plot(xs, ys, label=l1 + \" \" + l2)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit_ip_f(df, use_I=False):\n",
    "    \"\"\"\n",
    "    Create the f(y|X) part of IP weights using logistic regression\n",
    "    \n",
    "    Adapted from https://github.com/jrfiedler/causal_inference_python_code/blob/master/chapter12.ipynb\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : Pandas DataFrame\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Numpy array of IP weights\n",
    "    \n",
    "    \"\"\"\n",
    "    formula = \"\"\"\n",
    "    is_participant ~ n_updates_prestudy  \n",
    "        + np.log(time_since_first_journal_update_prestudy)\n",
    "        + n_first_visits_prestudy\n",
    "        + n_sites_interactedwith_prestudy\n",
    "        + n_interactions_prestudy\n",
    "        + n_days_visited_prestudy\n",
    "        + n_sites_repeat_visited_prestudy\n",
    "        + n_self_sites_interactedwith_prestudy\n",
    "        + n_self_interactions_prestudy\n",
    "    \"\"\"\n",
    "    model = smf.logit(formula=formula, data=df)\n",
    "    res = model.fit(disp=0)\n",
    "    #print(res.summary().tables[1])\n",
    "    weights = np.zeros(len(df))\n",
    "    weights[df.is_participant == 1] = res.predict(df[df.is_participant == 1])\n",
    "    weights[df.is_participant == 0] = (1 - res.predict(df[df.is_participant == 0]))\n",
    "    return weights\n",
    "\n",
    "def produce_ci_estimates(df, outcome):\n",
    "    block2 = df.copy()\n",
    "    block2.is_participant = 0\n",
    "    block3 = df.copy()\n",
    "    block3.is_participant = 1\n",
    "    \n",
    "    formula = outcome + \"\"\"\n",
    "     ~ n_updates_prestudy \n",
    "        + is_participant \n",
    "        + np.log(time_since_first_journal_update_prestudy)\n",
    "        + n_first_visits_prestudy\n",
    "        + n_sites_interactedwith_prestudy\n",
    "        + n_interactions_prestudy\n",
    "        + n_days_visited_prestudy\n",
    "        + n_sites_repeat_visited_prestudy\n",
    "        + n_self_sites_interactedwith_prestudy\n",
    "        + n_self_interactions_prestudy\n",
    "    \"\"\"\n",
    "    \n",
    "    # basic regression estimates\n",
    "    # that \"adjust for\" confounders\n",
    "    # plus standardization\n",
    "    md = smf.ols(formula=formula, data=df)\n",
    "    res = md.fit()\n",
    "    modeled_observational_effect = res.params.is_participant\n",
    "    block2_pred = res.predict(block2)\n",
    "    block3_pred = res.predict(block3)\n",
    "    standardized_effect = block3_pred.mean() - block2_pred.mean()\n",
    "    \n",
    "    # IP weighting and the Bang-Robins doubly robust (DR) estimator\n",
    "    weights = logit_ip_f(df)\n",
    "    weights = 1 / weights\n",
    "    wls = smf.wls(formula=f'{outcome} ~ is_participant', data=df, weights=weights)\n",
    "    res = wls.fit(disp=0)\n",
    "    ip_weighted_effect = res.params.is_participant\n",
    "    \n",
    "    block1 = df.copy()\n",
    "    block1['R'] = weights\n",
    "    block1.loc[block1.is_participant == 0, 'R'] *= -1\n",
    "    md = smf.ols(formula=formula + \"+ R\", data=block1)\n",
    "    res = md.fit()\n",
    "    block2 = block1.copy()\n",
    "    block2.is_participant = 0\n",
    "    block3 = block1.copy()\n",
    "    block3.is_participant = 1\n",
    "    block2_pred = res.predict(block2)\n",
    "    block3_pred = res.predict(block3)\n",
    "    dr_effect = block3_pred.mean() - block2_pred.mean()\n",
    "    \n",
    "    return {\n",
    "        'modeled_observational_diff': modeled_observational_effect,\n",
    "        'standardized_diff': standardized_effect,\n",
    "        'ip_weighted_diff': ip_weighted_effect,\n",
    "        'dr_diff': dr_effect,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "produce_ci_estimates(df, \"n_updates_poststudy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "produce_ci_estimates(df, \"n_sites_interactedwith_poststudy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "produce_ci_estimates(df, \"n_sites_repeat_visited_poststudy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "produce_ci_estimates(df, \"n_first_visits_poststudy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "produce_ci_estimates(df, \"n_interactions_poststudy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "produce_ci_estimates(df, \"n_days_visited_poststudy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_columns = [\n",
    "    'n_updates_poststudy', \n",
    "    'n_first_visits_poststudy', \n",
    "    'n_sites_repeat_visited_poststudy', \n",
    "    'n_sites_interactedwith_poststudy', \n",
    "    'n_interactions_poststudy', \n",
    "    'n_days_visited_poststudy',\n",
    "]\n",
    "diffs = []\n",
    "for i in tqdm(range(1000)):\n",
    "    sdf = df.sample(frac=1, replace=True)\n",
    "    for col in outcome_columns:\n",
    "        try:\n",
    "            ests = produce_ci_estimates(sdf, col)\n",
    "        except:\n",
    "            continue\n",
    "        diff = {}\n",
    "        diff['outcome'] = col\n",
    "        diff['diff_raw'] = sdf.loc[sdf.is_participant==1, col].mean() - sdf.loc[sdf.is_participant==0, col].mean()\n",
    "        diff['diff_ols'] = ests['modeled_observational_diff']\n",
    "        diff['diff_dr'] = ests['dr_diff']\n",
    "        diffs.append(diff)\n",
    "diff_df = pd.DataFrame(diffs)\n",
    "len(diff_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_diffs = []\n",
    "for col in outcome_columns:\n",
    "    try:\n",
    "        ests = produce_ci_estimates(df, col)\n",
    "    except:\n",
    "        continue\n",
    "    diff = {}\n",
    "    diff['outcome'] = col\n",
    "    diff['diff_raw'] = df.loc[df.is_participant==1, col].mean() - df.loc[df.is_participant==0, col].mean()\n",
    "    diff['diff_ols'] = ests['modeled_observational_diff']\n",
    "    diff['diff_dr'] = ests['dr_diff']\n",
    "    true_diffs.append(diff)\n",
    "true_diff_df = pd.DataFrame(true_diffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the bootstrapped estimates to make sure nothing absurd is happening\n",
    "fig, axes = plt.subplots(len(outcome_columns), 1, figsize=(5, 10))\n",
    "\n",
    "for i, col in enumerate(outcome_columns):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    diffs = diff_df[diff_df.outcome == col]\n",
    "    ds = diffs['diff_dr']\n",
    "    m = ds.median()\n",
    "    u = ds.quantile(upperq)\n",
    "    l = ds.quantile(lowerq)\n",
    "    \n",
    "    ax.hist(ds, bins=np.linspace(l, u))\n",
    "    print(f\"{col:>40} {m:.2f} [{l:.2f} , {u:.2f}]\")\n",
    "    \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretty_name_map = {\n",
    "    'n_updates_poststudy': \"Journal updates\",\n",
    "    'n_first_visits_poststudy': \"Peer site visits\",\n",
    "    'n_sites_repeat_visited_poststudy': \"Repeat peer site visits\",\n",
    "    'n_sites_interactedwith_poststudy': \"Peer site initiations\", \n",
    "    'n_interactions_poststudy': \"Peer site interactions\", \n",
    "    'n_days_visited_poststudy': \"# days visiting peers\",\n",
    "}\n",
    "outcome_columns = [\n",
    "    'n_updates_poststudy', \n",
    "    'n_first_visits_poststudy', \n",
    "#    'n_sites_repeat_visited_poststudy', \n",
    "#    'n_sites_interactedwith_poststudy', \n",
    "    'n_interactions_poststudy', \n",
    "    'n_days_visited_poststudy',\n",
    "]\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5.4, 2))\n",
    "\n",
    "lowerq = 0.025\n",
    "upperq = 0.975\n",
    "\n",
    "xticks = []\n",
    "xticklabels = []\n",
    "\n",
    "#ax.axhline(0, color='gray', alpha=0.5, zorder=-1, linestyle=\"--\")\n",
    "ax.axhline(0, color='black', alpha=1, zorder=-1, linestyle=\"-\", linewidth=0.75)\n",
    "\n",
    "i = 0\n",
    "for col in outcome_columns:\n",
    "    #if col == \"n_interactions_poststudy\" or col == \"n_days_visited_poststudy\":\n",
    "    #    continue\n",
    "    #xticks.append(i + 1)\n",
    "    #xticklabels.append(f\"{pretty_name_map[col]}\")\n",
    "    xticks.extend([i, i+1, i+2])\n",
    "    xticklabels.extend([\"Raw\", f\"OLS\\n{pretty_name_map[col]}\", \"DR\"])\n",
    "    \n",
    "    diffs = diff_df[diff_df.outcome == col]\n",
    "    for j, diff_col in enumerate(['diff_raw', 'diff_ols', 'diff_dr']):\n",
    "        ds = diffs[diff_col]\n",
    "        estimate = true_diff_df.loc[true_diff_df.outcome == col, diff_col].iloc[0]\n",
    "        m = ds.median()\n",
    "        u = ds.quantile(upperq)\n",
    "        l = ds.quantile(lowerq)\n",
    "        uerr = np.abs(u - estimate)\n",
    "        lerr = np.abs(l - estimate)\n",
    "        print(f\"{col:>40} {diff_col} {i+j}, true={estimate:.2f}; bs={m:.2f} [{l:.2f},{u:.2f}], {uerr:.2f}, {lerr:.2f} {estimate - m:.3f}\")\n",
    "        ax.errorbar(i+j, estimate, yerr=[[uerr,],[lerr,]], color='darkgray', capsize=4, zorder=1)\n",
    "        \n",
    "        ax.scatter(i+j, estimate, color='black', zorder=2, marker='s', s=8)\n",
    "        ax.text(i+j+0.11, estimate, f\"{estimate:.1f}\", ha='left', va='center' if np.abs(estimate) > 0.1 else 'bottom', fontsize=7)\n",
    "    \n",
    "    i += 3.4\n",
    "    \n",
    "ax.set_xticks(xticks)\n",
    "ax.set_xticklabels(xticklabels)\n",
    "ax.tick_params(axis='both', which='major', labelsize=7)\n",
    "ax.set_yticks([-4, -2, 0, 2, 4, 6])\n",
    "ax.set_ylabel(\"Participation Effect\", fontsize=7)\n",
    "\n",
    "#plt.margins(0,0)\n",
    "#plt.gca().xaxis.set_major_locator(plt.NullLocator())\n",
    "#plt.gca().yaxis.set_major_locator(plt.NullLocator())\n",
    "\n",
    "plt.tight_layout(pad=0.5)\n",
    "#plt.subplots_adjust(top = 0.4, bottom = 0, right = 1, left = 0, hspace = 0, wspace = 0)\n",
    "\n",
    "#bbox = matplotlib.transforms.Bbox.from_bounds(0,0,1,0.2)\n",
    "image_shortfilename = f\"participant_outcome_estimates.pdf\"\n",
    "image_filename = os.path.join(figures_dir, image_shortfilename)\n",
    "plt.savefig(image_filename, format='pdf', dpi=200, pad_inches=0) #, bbox_inches=bbox) #, transparent=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time window sensitivity analysis: Putting it all together\n",
    "\n",
    "From the first SSE on August 2nd, can go at most 35 days (5 weeks) back and still have the diff features.\n",
    "\n",
    "Can go until Feb 23rd \"forward\" i.e. 91 days (13 weeks) from the last SSE timestamp (on Nov 24th).\n",
    "\n",
    "Time interval from first to last study interval is 82 days:\n",
    "\n",
    "    >datetime.utcfromtimestamp(last_sse_timestamp / 1000) - datetime.utcfromtimestamp(first_sse_timestamp / 1000)\n",
    "    datetime.timedelta(days=82, seconds=79186, microseconds=174000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_day = 1000 * 60 * 60 * 24\n",
    "seven_days = one_day * 7\n",
    "ninety_days = one_day * 90\n",
    "time_window = ninety_days\n",
    "np.arange(0, 35 + 1, 7), np.arange(0, 91 + 1, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_study_dataframes():\n",
    "    one_day = 1000 * 60 * 60 * 24\n",
    "    for time_window_days in tqdm(np.arange(7, 91 + 1, 7), desc='Weekly frame data'):\n",
    "        if time_window_days > 35:\n",
    "            continue\n",
    "        back_window_days = 35 # min(time_window_days, 35)\n",
    "        front_window_days = time_window_days\n",
    "\n",
    "        # pre-study window features\n",
    "        end_timestamp = first_sse_timestamp\n",
    "        start_timestamp = end_timestamp - (back_window_days * one_day)\n",
    "        prestudy_df = compute_window_features(start_timestamp, end_timestamp, target_user_ids, \"_prestudy\")\n",
    "\n",
    "        # during-study window features\n",
    "        start_timestamp = first_sse_timestamp\n",
    "        end_timestamp = start_timestamp + (front_window_days * one_day)\n",
    "        study_df = compute_window_features(start_timestamp, end_timestamp, target_user_ids, \"_poststudy\", exclude_recommended_sites=True)\n",
    "\n",
    "        # post-study window features\n",
    "        start_timestamp = last_sse_timestamp\n",
    "        end_timestamp = start_timestamp + (front_window_days * one_day)\n",
    "        poststudy_df = compute_window_features(start_timestamp, end_timestamp, target_user_ids, \"_poststudy\", exclude_recommended_sites=True)\n",
    "\n",
    "        study_df = pd.merge(prestudy_df, study_df, left_index=True, right_index=True)\n",
    "        poststudy_df = pd.merge(prestudy_df, poststudy_df, left_index=True, right_index=True)\n",
    "        for df in [study_df, poststudy_df]:\n",
    "            df['is_participant'] = df.index.isin(participant_user_ids).astype(int)\n",
    "            \n",
    "        metadata = {\n",
    "            'back_window_days': back_window_days,\n",
    "            'front_window_days': front_window_days,\n",
    "        }\n",
    "        yield study_df, poststudy_df, metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(7, 91 + 1, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit_ip_f(df):\n",
    "    formula = \"\"\"\n",
    "     is_participant ~ n_updates_prestudy \n",
    "        + np.log(time_since_first_journal_update_prestudy)\n",
    "        + n_first_visits_prestudy\n",
    "        + n_sites_interactedwith_prestudy\n",
    "        + n_interactions_prestudy\n",
    "        + n_days_visited_prestudy\n",
    "        + n_sites_repeat_visited_prestudy\n",
    "        + n_self_sites_interactedwith_prestudy\n",
    "        + n_self_interactions_prestudy\n",
    "    \"\"\"\n",
    "    model = smf.logit(formula=formula, data=df)\n",
    "    res = model.fit(disp=0)\n",
    "    weights = np.zeros(len(df))\n",
    "    weights[df.is_participant == 1] = res.predict(df[df.is_participant == 1])\n",
    "    weights[df.is_participant == 0] = (1 - res.predict(df[df.is_participant == 0]))\n",
    "    return weights\n",
    "\n",
    "def produce_ci_estimates(df, outcome):\n",
    "    formula = outcome + \"\"\"\n",
    "     ~ n_updates_prestudy \n",
    "        + is_participant \n",
    "        + np.log(time_since_first_journal_update_prestudy)\n",
    "        + n_first_visits_prestudy\n",
    "        + n_sites_interactedwith_prestudy\n",
    "        + n_interactions_prestudy\n",
    "        + n_days_visited_prestudy\n",
    "        + n_sites_repeat_visited_prestudy\n",
    "        + n_self_sites_interactedwith_prestudy\n",
    "        + n_self_interactions_prestudy\n",
    "    \"\"\"\n",
    "    raw_effect = df.loc[df.is_participant==1, outcome].mean() - df.loc[df.is_participant==0, outcome].mean()\n",
    "    \n",
    "    poisson_effect = -1\n",
    "    poisson_ci = [-1, -1]\n",
    "    if False:\n",
    "        try:\n",
    "            md = smf.glm(formula=formula, data=df, family=statsmodels.genmod.families.family.Poisson())\n",
    "            res = md.fit(cov_type='HC0')\n",
    "            if not res.mle_retvals['converged']:\n",
    "                raise ValueError(\"Poisson model failed to converge.\")\n",
    "            poisson_effect = res.params.is_participant\n",
    "            poisson_ci = list(res.conf_int().loc['is_participant'])\n",
    "        except:\n",
    "            poisson_effect = -1\n",
    "            poisson_ci = [-1, -1]\n",
    "    \n",
    "    # basic regression estimates\n",
    "    # that \"adjust for\" confounders\n",
    "    # plus standardization\n",
    "    md = smf.ols(formula=formula, data=df)\n",
    "    res = md.fit()\n",
    "    modeled_observational_effect = res.params.is_participant\n",
    "    modeled_observational_ci = list(res.conf_int().loc['is_participant'])\n",
    "    block2 = df.copy()\n",
    "    block2.is_participant = 0\n",
    "    block3 = df.copy()\n",
    "    block3.is_participant = 1\n",
    "    block2_pred = res.predict(block2)\n",
    "    block3_pred = res.predict(block3)\n",
    "    standardized_effect = block3_pred.mean() - block2_pred.mean()\n",
    "    \n",
    "    # IP weighting and the Bang-Robins doubly robust (DR) estimator\n",
    "    weights = logit_ip_f(df)\n",
    "    weights = 1 / weights\n",
    "    wls = smf.wls(formula=f'{outcome} ~ is_participant', data=df, weights=weights)\n",
    "    res = wls.fit(disp=0)\n",
    "    ip_weighted_effect = res.params.is_participant\n",
    "    \n",
    "    block1 = df.copy()\n",
    "    block1['R'] = weights\n",
    "    block1.loc[block1.is_participant == 0, 'R'] *= -1\n",
    "    md = smf.ols(formula=formula + \"+ R\", data=block1)\n",
    "    res = md.fit()\n",
    "    block2 = block1.copy()\n",
    "    block2.is_participant = 0\n",
    "    block3 = block1.copy()\n",
    "    block3.is_participant = 1\n",
    "    block2_pred = res.predict(block2)\n",
    "    block3_pred = res.predict(block3)\n",
    "    dr_effect = block3_pred.mean() - block2_pred.mean()\n",
    "    \n",
    "    return {\n",
    "        'raw_diff': raw_effect,\n",
    "        'poisson_diff': poisson_effect,\n",
    "        'poisson_ci': poisson_ci,\n",
    "        'modeled_observational_diff': modeled_observational_effect,\n",
    "        'modeled_observational_ci': modeled_observational_ci,\n",
    "        'standardized_diff': standardized_effect,\n",
    "        'ip_weighted_diff': ip_weighted_effect,\n",
    "        'dr_diff': dr_effect,\n",
    "    }\n",
    "\n",
    "def compute_diff(df, outcome, bootstrap_iters=1000):\n",
    "    ests = produce_ci_estimates(df, outcome)\n",
    "    diff = {\n",
    "        'outcome': outcome,\n",
    "        'diff_raw': ests['raw_diff'],\n",
    "        'diff_ols': ests['modeled_observational_diff'],\n",
    "        'diff_ols_lower': ests['modeled_observational_ci'][0],\n",
    "        'diff_ols_upper': ests['modeled_observational_ci'][1],\n",
    "        'diff_poisson': ests['poisson_diff'],\n",
    "        'diff_poisson_lower': ests['poisson_ci'][0],\n",
    "        'diff_poisson_upper': ests['poisson_ci'][1],\n",
    "        'diff_dr': ests['dr_diff'],\n",
    "    }\n",
    "\n",
    "    # bootstrapping\n",
    "    bs_diffs = []\n",
    "    for i in tqdm(range(bootstrap_iters), desc=f'Bootstrapping {outcome}', disable=True):\n",
    "        sdf = df.sample(frac=1, replace=True)\n",
    "        # TODO move this try/catch block into bsdiff, so that e.g. the raw and the OLS samples can still be computed\n",
    "        try:\n",
    "            ests = produce_ci_estimates(sdf, outcome)\n",
    "        except:\n",
    "            continue\n",
    "        bsdiff = {\n",
    "            'diff_raw': ests['raw_diff'],\n",
    "            'diff_ols': ests['modeled_observational_diff'],\n",
    "            'diff_poisson': ests['poisson_diff'],\n",
    "            'diff_dr': ests['dr_diff'],\n",
    "        }\n",
    "        bs_diffs.append(bsdiff)\n",
    "    bsdiff_df = pd.DataFrame(bs_diffs)\n",
    "    diff['n_bootstraps'] = len(bsdiff_df)\n",
    "    for diff_col in ['diff_raw', 'diff_ols', 'diff_poisson', 'diff_dr']:\n",
    "        means = bsdiff_df[diff_col]\n",
    "        lower = means.quantile(0.025)\n",
    "        upper = means.quantile(0.975)\n",
    "        diff[diff_col + \"_lower\"] = lower\n",
    "        diff[diff_col + \"_upper\"] = upper\n",
    "        diff[diff_col + \"_bs_means\"] = list(means)\n",
    "    return diff\n",
    "    \n",
    "\n",
    "def compute_effects():\n",
    "    outcomes = [\n",
    "        'n_updates_poststudy', \n",
    "        'n_first_visits_poststudy', \n",
    "        'n_sites_repeat_visited_poststudy', \n",
    "        'n_sites_interactedwith_poststudy', \n",
    "        'n_interactions_poststudy', \n",
    "        'n_days_visited_poststudy',\n",
    "    ]\n",
    "    diffs = []\n",
    "    for study_df, poststudy_df, metadata in generate_study_dataframes():\n",
    "        for time_period, df in (('study', study_df), ('poststudy', poststudy_df)):\n",
    "            for outcome in tqdm(outcomes, desc='Outcomes'):\n",
    "                diff = compute_diff(df, outcome)\n",
    "                diff['time_period'] = time_period\n",
    "                diff.update(metadata)\n",
    "                diffs.append(diff)\n",
    "    diff_df = pd.DataFrame(diffs)\n",
    "    return diff_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initially, with 13 weeks x {poststudy, study} x 6 outcomes: 5hr30m runtime\n",
    "diff_df = compute_effects()\n",
    "len(diff_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes = [\n",
    "    'n_updates_poststudy', \n",
    "    'n_first_visits_poststudy', \n",
    "    'n_sites_repeat_visited_poststudy', \n",
    "    'n_sites_interactedwith_poststudy', \n",
    "    'n_interactions_poststudy', \n",
    "    'n_days_visited_poststudy',\n",
    "]\n",
    "pretty_name_map = {\n",
    "    'n_updates_poststudy': \"Journal updates\",\n",
    "    'n_first_visits_poststudy': \"Peer site visits\",\n",
    "    'n_sites_repeat_visited_poststudy': \"Repeat peer site visits\",\n",
    "    'n_sites_interactedwith_poststudy': \"Peer site initiations\", \n",
    "    'n_interactions_poststudy': \"Peer site interactions\", \n",
    "    'n_days_visited_poststudy': \"# days visiting peers\",\n",
    "}\n",
    "fig, axes = plt.subplots(len(outcomes), 2, figsize=(10, 22))\n",
    "\n",
    "for time_period, col in zip(['study', 'poststudy'], [0, 1]):\n",
    "    for row, outcome in enumerate(outcomes):\n",
    "        ax = axes[row, col]\n",
    "        sdf = diff_df[(diff_df.outcome == outcome)&(diff_df.time_period==time_period)]\n",
    "\n",
    "        ax.axhline(0.0, color='black', linestyle='--')\n",
    "        ax.axvline(5, color='gray', linestyle='-', alpha=0.5)\n",
    "        if time_period == 'study':\n",
    "            ax.axvline(82 / 7, color='darkgray', linestyle=':', alpha=0.5, label='End of study')\n",
    "\n",
    "        fill_alpha = 0.05\n",
    "        ax.plot(sdf.front_window_days / 7, sdf.diff_raw / sdf.front_window_days * 7, marker='.', label='Raw', color='blue')\n",
    "        ax.fill_between(sdf.front_window_days / 7, sdf.diff_raw_lower / sdf.front_window_days * 7, sdf.diff_raw_upper / sdf.front_window_days * 7, color='blue', alpha=fill_alpha)\n",
    "\n",
    "        ax.plot(sdf.front_window_days / 7, sdf.diff_ols / sdf.front_window_days * 7, marker='.', label='OLS', color='orange')\n",
    "        ax.fill_between(sdf.front_window_days / 7, sdf.diff_ols_lower / sdf.front_window_days * 7, sdf.diff_ols_upper / sdf.front_window_days * 7, color='orange', alpha=fill_alpha)\n",
    "\n",
    "        ax.plot(sdf.front_window_days / 7, sdf.diff_dr / sdf.front_window_days * 7, marker='.', label='DR', color='green')\n",
    "        ax.fill_between(sdf.front_window_days / 7, sdf.diff_dr_lower / sdf.front_window_days * 7, sdf.diff_dr_upper / sdf.front_window_days * 7, color='green', alpha=fill_alpha)\n",
    "\n",
    "        ax.set_xlabel(f\"Time since {'end' if time_period == 'poststudy' else 'start'} of study (weeks)\")\n",
    "        ax.set_ylabel(\"Excess weekly actions\")\n",
    "        ax.set_title(f\"{pretty_name_map[outcome]} {'after the study' if time_period == 'poststudy' else 'during the study'} \")\n",
    "        ax.legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "sdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes = [\n",
    "    'n_updates_poststudy', \n",
    "    'n_first_visits_poststudy', \n",
    "    'n_sites_repeat_visited_poststudy', \n",
    "    'n_sites_interactedwith_poststudy', \n",
    "    'n_interactions_poststudy', \n",
    "    'n_days_visited_poststudy',\n",
    "]\n",
    "pretty_name_map = {\n",
    "    'n_updates_poststudy': \"Journal updates\",\n",
    "    'n_first_visits_poststudy': \"Peer site visits\",\n",
    "    'n_sites_repeat_visited_poststudy': \"Repeat peer site visits\",\n",
    "    'n_sites_interactedwith_poststudy': \"Peer site initiations\", \n",
    "    'n_interactions_poststudy': \"Peer site interactions\", \n",
    "    'n_days_visited_poststudy': \"# days visiting peers\",\n",
    "}\n",
    "fig, axes = plt.subplots(len(outcomes), 2, figsize=(10, 22))\n",
    "\n",
    "for time_period, col in zip(['study', 'poststudy'], [0, 1]):\n",
    "    for row, outcome in enumerate(outcomes):\n",
    "        ax = axes[row, col]\n",
    "        sdf = diff_df[(diff_df.outcome == outcome)&(diff_df.time_period==time_period)]\n",
    "\n",
    "        ax.axhline(0.0, color='black', linestyle='--')\n",
    "        ax.axvline(5, color='gray', linestyle='-', alpha=0.5)\n",
    "        if time_period == 'study':\n",
    "            ax.axvline(82 / 7, color='darkgray', linestyle=':', alpha=0.5, label='End of study')\n",
    "\n",
    "        fill_alpha = 0.05\n",
    "        ax.plot(sdf.front_window_days / 7, sdf.diff_raw / sdf.front_window_days * 7, marker='.', label='Raw', color='blue')\n",
    "        ax.fill_between(sdf.front_window_days / 7, sdf.diff_raw_lower / sdf.front_window_days * 7, sdf.diff_raw_upper / sdf.front_window_days * 7, color='blue', alpha=fill_alpha)\n",
    "\n",
    "        ax.plot(sdf.front_window_days / 7, sdf.diff_ols / sdf.front_window_days * 7, marker='.', label='OLS', color='orange')\n",
    "        ax.fill_between(sdf.front_window_days / 7, sdf.diff_ols_lower / sdf.front_window_days * 7, sdf.diff_ols_upper / sdf.front_window_days * 7, color='orange', alpha=fill_alpha)\n",
    "\n",
    "        ax.plot(sdf.front_window_days / 7, sdf.diff_dr / sdf.front_window_days * 7, marker='.', label='DR', color='green')\n",
    "        ax.fill_between(sdf.front_window_days / 7, sdf.diff_dr_lower / sdf.front_window_days * 7, sdf.diff_dr_upper / sdf.front_window_days * 7, color='green', alpha=fill_alpha)\n",
    "\n",
    "        ax.set_xlabel(f\"Time since {'end' if time_period == 'poststudy' else 'start'} of study (weeks)\")\n",
    "        ax.set_ylabel(\"Excess weekly actions\")\n",
    "        ax.set_title(f\"{pretty_name_map[outcome]} {'after the study' if time_period == 'poststudy' else 'during the study'} \")\n",
    "        ax.legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "sdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the first version, with 13 weeks and equal matching \n",
    "diff_df.to_feather(\"diff_df_20220521.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is only the first 5 weeks, with full back_window_days (i.e. 35)\n",
    "diff_df.to_feather(\"diff_df_20220522.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_df1 = pd.read_feather(\"diff_df_20220521.feather\")\n",
    "diff_df2 = pd.read_feather(\"diff_df_20220522.feather\")\n",
    "len(diff_df1), len(diff_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_df = pd.concat([diff_df1[(diff_df1.back_window_days>=35)&(diff_df1.front_window_days > 35)], diff_df2], axis=0,ignore_index=True)\\\n",
    "    .sort_values(by=['outcome', 'time_period', 'front_window_days'])\n",
    "print(len(diff_df))\n",
    "diff_df.groupby(['outcome', 'time_period', 'back_window_days', 'front_window_days']).diff_raw.count().sort_values(ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes = [\n",
    "    'n_updates_poststudy', \n",
    "    'n_first_visits_poststudy', \n",
    "    'n_sites_repeat_visited_poststudy', \n",
    "    'n_sites_interactedwith_poststudy', \n",
    "    'n_interactions_poststudy', \n",
    "    'n_days_visited_poststudy',\n",
    "]\n",
    "pretty_name_map = {\n",
    "    'n_updates_poststudy': \"Journal updates\",\n",
    "    'n_first_visits_poststudy': \"Peer site visits\",\n",
    "    'n_sites_repeat_visited_poststudy': \"Repeat peer site visits\",\n",
    "    'n_sites_interactedwith_poststudy': \"Peer site initiations\", \n",
    "    'n_interactions_poststudy': \"Peer site interactions\", \n",
    "    'n_days_visited_poststudy': \"# days visiting peers\",\n",
    "}\n",
    "fig, axes = plt.subplots(len(outcomes), 2, figsize=(5.6, 7))\n",
    "cm = matplotlib.cm.tab10\n",
    "\n",
    "for time_period, col in zip(['study', 'poststudy'], [0, 1]):\n",
    "    for row, outcome in enumerate(outcomes):\n",
    "        ax = axes[row, col]\n",
    "        sdf = diff_df[(diff_df.outcome == outcome)&(diff_df.time_period==time_period)]\n",
    "\n",
    "        ax.axhline(0.0, color='black', linestyle='--')\n",
    "        if time_period == 'study':\n",
    "            ax.axvline(82 / 7, color='darkgray', linestyle=':', alpha=0.5, label='End of study')\n",
    "\n",
    "        fill_alpha = 0.07\n",
    "        ax.plot(sdf.front_window_days / 7, sdf.diff_raw / sdf.front_window_days * 7, marker='.', label='Raw', color=cm(0))\n",
    "        ax.fill_between(sdf.front_window_days / 7, sdf.diff_raw_lower / sdf.front_window_days * 7, sdf.diff_raw_upper / sdf.front_window_days * 7, color=cm(0), alpha=fill_alpha)\n",
    "\n",
    "        ax.plot(sdf.front_window_days / 7, sdf.diff_ols / sdf.front_window_days * 7, marker='.', label='OLS', color=cm(1), linestyle='--')\n",
    "        ax.fill_between(sdf.front_window_days / 7, sdf.diff_ols_lower / sdf.front_window_days * 7, sdf.diff_ols_upper / sdf.front_window_days * 7, color=cm(1), alpha=fill_alpha)\n",
    "\n",
    "        ax.plot(sdf.front_window_days / 7, sdf.diff_dr / sdf.front_window_days * 7, marker='.', label='DR', color=cm(2), linestyle=':')\n",
    "        ax.fill_between(sdf.front_window_days / 7, sdf.diff_dr_lower / sdf.front_window_days * 7, sdf.diff_dr_upper / sdf.front_window_days * 7, color=cm(2), alpha=fill_alpha)\n",
    "\n",
    "        ax.tick_params(axis='both', which='major', labelsize=8)\n",
    "        if row == len(outcomes) - 1:\n",
    "            ax.set_xlabel(f\"Weeks since {'end' if time_period == 'poststudy' else 'start'} of study\", fontsize=8)\n",
    "            ax.set_xticks(np.arange(1, 14))\n",
    "        else:\n",
    "            ax.set_xticks([])\n",
    "            #ax.set_yticks([])\n",
    "            #plt.axis('off')\n",
    "\n",
    "            ax.margins(0,0)\n",
    "            ax.xaxis.set_major_locator(plt.NullLocator())\n",
    "        if col == 0:\n",
    "            ax.set_ylabel(f\"Excess weekly\\n{pretty_name_map[outcome]}\", fontsize=7)\n",
    "        #ax.set_title(f\"{pretty_name_map[outcome]} {'after the study' if time_period == 'poststudy' else 'during the study'}\", fontsize=8)\n",
    "        #ax.legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(wspace=0.2, hspace=0.05)\n",
    "\n",
    "bbox = matplotlib.transforms.Bbox.from_bounds(0,0,5.4,7)\n",
    "image_shortfilename = f\"participant_retention_outcomes_all.pdf\"\n",
    "image_filename = os.path.join(figures_dir, image_shortfilename)\n",
    "fig.savefig(image_filename, format='pdf', dpi=200, pad_inches=0, bbox_inches='tight') #, transparent=True)\n",
    "plt.show()\n",
    "sdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Click data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the rec_df with associated click data\n",
    "participant_data_dir = '/home/lana/shared/caringbridge/data/projects/recsys-peer-match/participant'\n",
    "click_rec_df = pd.read_feather(os.path.join(participant_data_dir, 'click_rec_df.feather'))\n",
    "len(click_rec_df), click_rec_df.was_clicked.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "click_rec_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_click_times_map = {}\n",
    "for batch_id, group in click_rec_df[click_rec_df.was_clicked].groupby('batch_id'):\n",
    "    click_times = group.first_click_timestamp\n",
    "    batch_click_times_map[batch_id] = np.array(click_times)\n",
    "len(batch_click_times_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "click_times = []\n",
    "for row in click_rec_df.itertuples():\n",
    "    click_time = row.first_click_timestamp\n",
    "    if click_time < 0:\n",
    "        click_time = np.random.choice(batch_click_times_map[row.batch_id])\n",
    "    click_times.append(click_time)\n",
    "click_rec_df['first_click_timestamp_spoofed'] = click_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirming that the distributions are similar\n",
    "# the only reason there are any differences is that the clicked and non-clicked recs are unevenly distributed over the batches\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "first_sse_timestamp = click_rec_df.sse_sent_timestamp.min()\n",
    "sdf1 = (click_rec_df[click_rec_df.was_clicked].first_click_timestamp_spoofed - first_sse_timestamp) / 1000 / 60 / 60 / 24\n",
    "sdf2 = (click_rec_df[~click_rec_df.was_clicked].first_click_timestamp_spoofed - first_sse_timestamp) / 1000 / 60 / 60 / 24\n",
    "ax.hist([sdf1, sdf2], bins=np.arange(0, 91), density=True, label=['Clicked', 'Non-clicked'])\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"Days since first sent timestamp\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (shared-conda)",
   "language": "python",
   "name": "shared-conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
